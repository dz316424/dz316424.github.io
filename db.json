{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/material-flow-yu/source/style.less","path":"style.less","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/fonts/icomoon.eot","path":"fonts/icomoon.eot","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/fonts/icomoon.svg","path":"fonts/icomoon.svg","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/fonts/icomoon.ttf","path":"fonts/icomoon.ttf","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/fonts/icomoon.woff","path":"fonts/icomoon.woff","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/fonts/selection.json","path":"fonts/selection.json","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/js/app.js","path":"js/app.js","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/material-flow-yu/source/js/jquery.fitvids.js","path":"js/jquery.fitvids.js","modified":0,"renderable":1}],"Cache":[{"_id":"themes/material-flow-yu/LICENSE","hash":"44409ab0bcd7853e2ac93faad84e57299711e6bf","modified":1520109936138},{"_id":"themes/material-flow-yu/README.md","hash":"2f14b9c1e7ad23e03da0599a9f348d61c79c474f","modified":1520109936138},{"_id":"themes/material-flow-yu/_config.yml","hash":"fc2e764f56c0f643df1f712892f4da04c0f74afc","modified":1520111455974},{"_id":"source/_drafts/Building-Automatic-Vector-Tile-Preseeding-Service-on-Cloud.md","hash":"95302cb978f37e56f23f0f8ddf647d063fe7b5ef","modified":1520109936102},{"_id":"source/_drafts/Using-RxJS-with-PostgreSQL.md","hash":"a81b3abd5dfeaf65abf41911825a70ac38824328","modified":1520109936122},{"_id":"source/_posts/AWS-ECS-auto-deployment-with-Travis-CI.md","hash":"a696352c35c2f2ed86d82fecc0d911ededa59816","modified":1521906174028},{"_id":"source/_drafts/note.md","hash":"c9c0c7c0ddc245d9a5490e962a47fac5e2a9e006","modified":1520109936102},{"_id":"source/_posts/Adding-GeoJSON-layers-in-your-Leaflet-project-in-TypeScript.md","hash":"af6b01f26bb012a73da61624098408cdfd345fa0","modified":1520109936102},{"_id":"source/_posts/ArcMap-Raster-Edit-Suite.md","hash":"c649b466a945024ea26209a85ed92e12183318c1","modified":1520109936102},{"_id":"source/_posts/Boundary-Now-a-simple-tool-to-extract-OSM-place-boundaries.md","hash":"043477b06fae6fc6cd851c35f0fcbf288f9f9213","modified":1520109936102},{"_id":"source/_posts/Celebrating-the-1-000-data-portals-at-OpenDataDiscovery-org.md","hash":"ebbe8e0055dfa3a450eb5d1122c84d918cf55b75","modified":1520109936110},{"_id":"source/_posts/Comparison-of-different-sampling-rules-in-SVM-classification.md","hash":"eb78ebe4ad8bcd0baf4717548c9a2bcf20e9036d","modified":1520109936114},{"_id":"source/_posts/Converting-C-Data-Value-to-ArcObject-Raster-Pixel-Value.md","hash":"efc736de405c652cc4f37031458d56ec54a93006","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks.md","hash":"c930a61fbde27b36e31b5318c22e62a868fbef9e","modified":1520109936114},{"_id":"source/_posts/Generating-masks-from-Landsat-8-image-in-ArcMap.md","hash":"585854e028d4dd2a3f98064af438f09970b98f2c","modified":1520109936118},{"_id":"source/_posts/Making-A-Map-with-Leaflet-in-TypeScript.md","hash":"689619ec9077bded26574bf166539abddbca16e0","modified":1520109936118},{"_id":"source/_posts/Lazy-man-s-package-of-U-S-boundaries.md","hash":"319613ce7e232832fe7762a8609100eb184316fe","modified":1520109936118},{"_id":"source/_posts/Making-masks-from-Quality-Control-bits-of-MODIS-land-products-in-Python-Update.md","hash":"c92d60d8bad96c517203a981afa61c2c3b45377b","modified":1520109936118},{"_id":"source/_posts/Making-masks-with-Landsat-8-Quality-Assessment-band-using-Python.md","hash":"ac6721160852d62cc7a9e95b8b04de65dcde3140","modified":1520109936118},{"_id":"source/_posts/Pymasker.md","hash":"c6222fb00087701274ce2dda4cb2135b8c2638cf","modified":1520109936118},{"_id":"source/_posts/The-Launch-of-OpenDataDiscovery.org.md","hash":"91a70c79d690156eca7eed62eb755ddfb9df57eb","modified":1520109936118},{"_id":"source/_posts/The-unofficial-documentation-for-ArcGIS-Open-Data-dataset-search-API.md","hash":"64354003db9149930299301525457560fdc6a885","modified":1520109936122},{"_id":"source/_posts/Using-an-untyped-Leaflet-plugin-in-your-TypeSccript-project.md","hash":"6dc495cd2b6d3cd0ff48937ff698989620e6a7e3","modified":1520109936122},{"_id":"source/_posts/Work-Life-2016.md","hash":"085bd8bb3156b9e629e391f33ec37031541bdcfc","modified":1520109936122},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it.md","hash":"7e0f5e4bef1d3969bce4183c39a7c372846fbbd3","modified":1520109936134},{"_id":"source/_posts/geojson-multiply-a-simple-library-to-pack-single-type-geojson-features.md","hash":"968a5e79036a047d02e91351b6df8c89aa20be4d","modified":1520109936138},{"_id":"source/_posts/gtran-a-promised-consistent-user-friendly-GeoJson-conversion-package.md","hash":"26f75a2fff88ae5e80a01603b2289133bbd142ce","modified":1520109936138},{"_id":"source/all-archives/index.md","hash":"ab35b4654c9949b8ab9c63d4efe270d6f63ad005","modified":1520109936138},{"_id":"source/all-categories/index.md","hash":"23aef7c7c3cafc0dadb9914df5d3c7a2a4bedaa0","modified":1520109936138},{"_id":"source/all-tags/index.md","hash":"2844fe1bccfa76e65a561daf7346335f7ce164f1","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/archive.ejs","hash":"735e6c0b1f8f837617b3a4119ac321a84f4ec5f7","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/category.ejs","hash":"c97be36b33bb44957778587f00c978f2d28016f8","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/index.ejs","hash":"c97be36b33bb44957778587f00c978f2d28016f8","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/layout.ejs","hash":"c137d708da9c5339dbcdf2e45c4851c08899a457","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/tag.ejs","hash":"c97be36b33bb44957778587f00c978f2d28016f8","modified":1520109936138},{"_id":"themes/material-flow-yu/source/style.less","hash":"ad50444f75534f36001872d4c90e1d839614402b","modified":1520109936146},{"_id":"source/_posts/AWS-ECS-auto-deployment-with-Travis-CI/travis-deploy.png","hash":"370c46b4bd290dfc837e5d87c2fd54cb1ecde1eb","modified":1521905580874},{"_id":"source/_posts/AWS-ECS-auto-deployment-with-Travis-CI/travis-env.png","hash":"0b6d46d9b988c624d10c048d7e49d66666ad0005","modified":1521905060940},{"_id":"source/_posts/Comparison-of-different-sampling-rules-in-SVM-classification/accuracyfigure.png","hash":"d65f8e1aaf4c9a523948a7de51cdd8dde57dd4f7","modified":1520109936114},{"_id":"source/_posts/Comparison-of-different-sampling-rules-in-SVM-classification/accuracytable.png","hash":"7d060171484e7986eb10238b844e26ad12d78a53","modified":1520109936114},{"_id":"source/_posts/Comparison-of-different-sampling-rules-in-SVM-classification/featurespace.png","hash":"02522796f21f16b4965fd5d1fb51670d4efcb54d","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/edit_tool.png","hash":"64d5f5bab9ac33413acef8b28efdc19fcf02eafa","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/edit_pixels.png","hash":"896e42abf071b7aae32f1daef195133730385ad7","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/eidtor_toolbar.png","hash":"ba49a4ff82ad9b8bc42766c8ef223ea422460eec","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/gotopixel_tool.png","hash":"14778d43e9c66523e0d05143a66a2b8800b84c01","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/identify_tool.png","hash":"5c644f2d083deb019cfd0c4a3d941133fcaf8649","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/finish_editing.png","hash":"614b8bb29652590a4164374e7e012e7cc9290eb7","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/install_wizard.png","hash":"f3bcda2152026cd6e39da31316fedea391943a5b","modified":1520109936114},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/unzipped_folder.png","hash":"4341c059bf0fa6ff7011e0ed1777a638a593c4e1","modified":1520109936118},{"_id":"source/_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks/select_pixels.png","hash":"b18e42acf98e6a232895a9a439d06a2d656f9f05","modified":1520109936118},{"_id":"source/_posts/Generating-masks-from-Landsat-8-image-in-ArcMap/Masking_from_Landsat_8.png","hash":"e8ce1f521d81043786a2cdfa44d3a22fd63acf4e","modified":1520109936118},{"_id":"source/_posts/Generating-masks-from-Landsat-8-image-in-ArcMap/Masking_from_Quality_Assessment_Bits.png","hash":"6de1519a102900f10dc243b783771ae4f0c2bd32","modified":1520109936118},{"_id":"source/_posts/Making-masks-from-Quality-Control-bits-of-MODIS-land-products-in-Python-Update/bitstructure.png","hash":"a08114820a55f6fdcad146519fe1557aa79b56aa","modified":1520109936118},{"_id":"source/_posts/Making-masks-from-Quality-Control-bits-of-MODIS-land-products-in-Python-Update/bitsample.png","hash":"7d363d2c46c8e15a6c1e19a2d863ab33162fe69e","modified":1520109936118},{"_id":"source/_posts/Making-masks-from-Quality-Control-bits-of-MODIS-land-products-in-Python-Update/bittable.png","hash":"8d6867221c2623d6b872df486a626f55540f5025","modified":1520109936118},{"_id":"source/_posts/Work-Life-2016/github-commits.png","hash":"541f5e830d71439b9973ca5ae12210cbff5c3834","modified":1520109936126},{"_id":"source/_posts/Work-Life-2016/odd-commits.png","hash":"c90aca664947abe9636cef6726e763ca65001441","modified":1520109936126},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/AddValues.png","hash":"695a53896135059049bfdd40f63e71831e5d402e","modified":1520109936134},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/Erase.png","hash":"793b3c2707794a4dba9670345353f55c3f1fa724","modified":1520109936138},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/EraseTool.png","hash":"e49223fac46bde239e04b42162d0fe93c162fe45","modified":1520109936138},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/FreehandPaintTool.png","hash":"9b4e007a0c2fea0f08bf7e0f4067a0f745d9a35d","modified":1520109936138},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/Painting.png","hash":"b8322829bb712ece2e2f03bf3fb91ddfb36c47cd","modified":1520109936138},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/RasterPainter.png","hash":"a48393fe3375e8f09a174d00caa8c4b64d7d032e","modified":1520109936138},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/StartPainting.png","hash":"96d9799ced86891aa46058c1fb1a047d59728f8c","modified":1520109936138},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/WinPaint.png","hash":"278fea1d6ca5c420b3d818cdc2fe4066b1776e69","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/archive.ejs","hash":"7d811a088748b758c0664645629adbebdd8d1c3f","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/article.ejs","hash":"b704e39a37391b8017d1c3ebddcb0e56262c4819","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/categories.ejs","hash":"761fda43c385e81324b628dfab6377b82bfdf82a","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/footer.ejs","hash":"cd058b093f17d8fb3b82124322c97728693e1898","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/head.ejs","hash":"e7e1f1b4d9830cf0a91efe6fcbabdbbd405567d0","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/loading.ejs","hash":"9c5721d5a5cff00860f2775b12dd73fe62375201","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/header.ejs","hash":"7ee2448ebb96c206e449ea6641d5ba5cc1a6c9d2","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/post.ejs","hash":"16d695e09c9d73e3e01b78f8b5385690d45d98a1","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/scripts.ejs","hash":"456c65e7c1f93c66511e0976ea88a744d3e6b7de","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_partial/side.ejs","hash":"fe78dea06ac3a4ce2efcfd6171aea8fb3f64ebe7","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_widget/about.ejs","hash":"391668e42cd9e3c38246a5cea12be21b6c58337b","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_widget/categories.ejs","hash":"2be2c85e4c5275d08e524fabdb38f046054b874a","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_widget/links.ejs","hash":"2d6c7fc92b0330a7a79b8b680cf9f4286fdf0291","modified":1520109936138},{"_id":"themes/material-flow-yu/layout/_widget/tagcloud.ejs","hash":"914698bcc4210b5f984e12166eca3c86de631968","modified":1520109936138},{"_id":"themes/material-flow-yu/source/fonts/icomoon.eot","hash":"931a892fd6307c0cfcbb71511ad4a38b3dd20edf","modified":1520109936146},{"_id":"themes/material-flow-yu/source/fonts/icomoon.svg","hash":"37a9d40dfcd7d156cf452db75c425e797351e2b5","modified":1520109936146},{"_id":"themes/material-flow-yu/source/fonts/icomoon.ttf","hash":"6192fb2b38c94f77d1fed08c1969fab5ffe9a30c","modified":1520109936146},{"_id":"themes/material-flow-yu/source/fonts/icomoon.woff","hash":"0356e9be814a04187c641371fd95a7a8d9111200","modified":1520109936146},{"_id":"themes/material-flow-yu/source/fonts/selection.json","hash":"498b5ba0cafb2eb5fa20f9034527eb912fa41827","modified":1520109936146},{"_id":"themes/material-flow-yu/source/js/app.js","hash":"17aca227d841b932ac33af4c9e02a192832fdc85","modified":1520109936146},{"_id":"themes/material-flow-yu/source/js/search.js","hash":"632ce023094442d350dcd2895ca5f948364746cb","modified":1520109936146},{"_id":"themes/material-flow-yu/source/js/jquery.fitvids.js","hash":"57946a22c79654014eb00fb548f727d302221873","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_article.less","hash":"37d645669b564df960c02680c0ee6532361b4d7b","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_archive.less","hash":"0b15989a0d19ce550cf5d0021376c5ad1d4790b9","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_base.less","hash":"828efc946f54ce2bfd5970e1d8d7b08f8f515786","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_defines.less","hash":"6b8ffd4e1b478e046722487bae15a500f3fd3092","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_fonts.less","hash":"d9e56fa5affcdee1c530ee5d5268a7e07644c05a","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_footer.less","hash":"973b1f9c62159f345833db5c30db03c351c66c5c","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_header.less","hash":"36f32479c42be1ed503903e1cb88daca5b7792ca","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_main.less","hash":"6e2c43e15d1e05bcddbccc1d4830b4687261f1eb","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_normalize.less","hash":"02fe53286d071637534d5aa2c57c76c168c0d521","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_pagination.less","hash":"165e2c369faf70858b731bb6d483d8991259887e","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_search.less","hash":"ab1e3d8fdd489adde30723c40726e5e8187a8b6c","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_side.less","hash":"210ffc4e3fc41a5202618e17fc744a8b2b6bc54e","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_toc.less","hash":"76729eb95cf89eb17436e13610847102d4795a63","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_tog.less","hash":"bff0ab3b06e14a3c171ccd53061f8ccddb1e2fc2","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_typo.less","hash":"8635fe95a08614f22833c6c159ebf6cf3d731e12","modified":1520109936146},{"_id":"themes/material-flow-yu/source/less/_widget.less","hash":"a6fc757f2daf58089490eefe0701b9889a8bd4bd","modified":1520109936146},{"_id":"themes/material-flow-yu/snapshots/phone.png","hash":"8e78f25ee179e3ff27fff101050792184935d319","modified":1520109936146},{"_id":"source/_posts/Making-masks-from-Quality-Control-bits-of-MODIS-land-products-in-Python-Update/hqmask.png","hash":"5fded205c65170387bd291949607f2d01fd4a7f0","modified":1520109936118},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/ArcPaint.png","hash":"056874f2064c9e932355fa0577d36e8546ff168b","modified":1520109936134},{"_id":"source/_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it/Save.png","hash":"e390de0c21bf3a723c4537f5491f63b424a40145","modified":1520109936138},{"_id":"themes/material-flow-yu/snapshots/article.png","hash":"3f1aff6057a807b55edd2435421b59a1f4e82c40","modified":1520109936142},{"_id":"source/_posts/Comparison-of-different-sampling-rules-in-SVM-classification/testSample.png","hash":"c19e03871ebeca801395e183a4fc980a55383844","modified":1520109936114},{"_id":"source/_posts/Comparison-of-different-sampling-rules-in-SVM-classification/trainsample.png","hash":"dafbf89e7f837ed8b63074bf6545efef35d098fe","modified":1520109936114},{"_id":"source/_posts/Making-masks-with-Landsat-8-Quality-Assessment-band-using-Python/maskresult.png","hash":"69cdac0aefd80011982e49d1d84e890968a0384e","modified":1520109936118},{"_id":"source/_posts/Celebrating-the-1-000-data-portals-at-OpenDataDiscovery-org/region-map.png","hash":"4fb74ad0a48d766694bbcacec8402d3f82138099","modified":1520109936114},{"_id":"themes/material-flow-yu/snapshots/index.png","hash":"a4aa937770d1573032f3e830be3cd75672a26036","modified":1520109936146},{"_id":"source/_posts/The-Launch-of-OpenDataDiscovery.org/map.png","hash":"6129dfe258e3e1703cc652105ff1189bf4970034","modified":1520109936122},{"_id":"source/_posts/Boundary-Now-a-simple-tool-to-extract-OSM-place-boundaries/boundary-now.png","hash":"0e3909b5c7669e04982cdbabff7c4b6cd22af04b","modified":1520109936110},{"_id":"source/_posts/Work-Life-2016/trait.jpg","hash":"cbd6dbbcd221690863164f087d07261ecea5de08","modified":1520109936134}],"Category":[{"name":"Project","_id":"cjf5jlgqs00048j0v6n9ezop9"},{"name":"AWS","_id":"cjf5jlgqz000a8j0vqxm5w85p"},{"name":"GIS","_id":"cjf5jlgr3000f8j0vka48e7fs"},{"name":"Open Data","_id":"cjf5jlgrq001g8j0vy0nrdwr6"},{"name":"Life","_id":"cjf5jlgru001p8j0v18m29hiv"}],"Data":[],"Page":[{"title":"all-archives","layout":"all-archives","_content":"","source":"all-archives/index.md","raw":"title: \"all-archives\"\nlayout: \"all-archives\"\n---\n","date":"2018-03-03T20:45:36.138Z","updated":"2018-03-03T20:45:36.138Z","path":"all-archives/index.html","comments":1,"_id":"cjf5jlgqo00018j0vtndtjuip","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"all-categories","layout":"all-categories","_content":"","source":"all-categories/index.md","raw":"title: \"all-categories\"\nlayout: \"all-categories\"\n---\n","date":"2018-03-03T20:45:36.138Z","updated":"2018-03-03T20:45:36.138Z","path":"all-categories/index.html","comments":1,"_id":"cjf5jlgqr00038j0viemlgl4q","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"all-tags","layout":"all-tags","_content":"","source":"all-tags/index.md","raw":"title: \"all-tags\"\nlayout: \"all-tags\"\n---\n","date":"2018-03-03T20:45:36.138Z","updated":"2018-03-03T20:45:36.138Z","path":"all-tags/index.html","comments":1,"_id":"cjf5jlgqv00078j0vhbuc6ys9","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Building Automatic Vector Tile Preseeding Service on Cloud","date":"2016-10-27T04:00:00.000Z","_content":"\n[OpenDataDiscovery.org](http://www.opendatadiscovery.org) publishes the status of open data portals every week therefore it needs a weekly update for its vector tile map. In this article, I will discuss how I set up the automatic vector tile preseeding service using AWS EC2 instances and Auto-Scaling service.\n\n<!-- more -->\n\nBefore explaining the solution, I would like to briefly talk about the problem.\n\n[OpenDataDiscovery.org](http://www.opendatadiscovery.org) currently has very low traffic and it merely requires a micro EC2 instance (1GB memory and 1-core CPU) to host both the server and the database.\n\nThough it only takes 20 minutes, the tile preseeding is much more expensive and it needs a medium EC2 instance (4GB memory and 2-core CPU) to generate worldwide vector tile data.\n\nMy goal is to maintain a micro EC2 instance for hosting the website and only set up a medium EC2 instance when it's time to update map data. The whole procedure should be automatic and doesn't require human interwind. In this way, I can minimize my time and expense to maintain the service.\n\nAfter reading the article [](), I decide to use AWS Auto-Scaling service to create instance for tile generation, which is able to self-initialize and self-destroy. With a proper estimation of the time required by tile generation, the procedure would include two steps:\n\n1. the auto-scaling service sets up a medium\n","source":"_drafts/Building-Automatic-Vector-Tile-Preseeding-Service-on-Cloud.md","raw":"title: Building Automatic Vector Tile Preseeding Service on Cloud\ndate: 2016-10-27\ncategories:\n- Project\ntags:\n- gis\n- OpenDataDiscovery.org\n---\n\n[OpenDataDiscovery.org](http://www.opendatadiscovery.org) publishes the status of open data portals every week therefore it needs a weekly update for its vector tile map. In this article, I will discuss how I set up the automatic vector tile preseeding service using AWS EC2 instances and Auto-Scaling service.\n\n<!-- more -->\n\nBefore explaining the solution, I would like to briefly talk about the problem.\n\n[OpenDataDiscovery.org](http://www.opendatadiscovery.org) currently has very low traffic and it merely requires a micro EC2 instance (1GB memory and 1-core CPU) to host both the server and the database.\n\nThough it only takes 20 minutes, the tile preseeding is much more expensive and it needs a medium EC2 instance (4GB memory and 2-core CPU) to generate worldwide vector tile data.\n\nMy goal is to maintain a micro EC2 instance for hosting the website and only set up a medium EC2 instance when it's time to update map data. The whole procedure should be automatic and doesn't require human interwind. In this way, I can minimize my time and expense to maintain the service.\n\nAfter reading the article [](), I decide to use AWS Auto-Scaling service to create instance for tile generation, which is able to self-initialize and self-destroy. With a proper estimation of the time required by tile generation, the procedure would include two steps:\n\n1. the auto-scaling service sets up a medium\n","slug":"Building-Automatic-Vector-Tile-Preseeding-Service-on-Cloud","published":0,"updated":"2018-03-03T20:45:36.102Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgqj00008j0v59nqxa19","content":"<p><a href=\"http://www.opendatadiscovery.org\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a> publishes the status of open data portals every week therefore it needs a weekly update for its vector tile map. In this article, I will discuss how I set up the automatic vector tile preseeding service using AWS EC2 instances and Auto-Scaling service.</p><a id=\"more\"></a><p>Before explaining the solution, I would like to briefly talk about the problem.</p><p><a href=\"http://www.opendatadiscovery.org\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a> currently has very low traffic and it merely requires a micro EC2 instance (1GB memory and 1-core CPU) to host both the server and the database.</p><p>Though it only takes 20 minutes, the tile preseeding is much more expensive and it needs a medium EC2 instance (4GB memory and 2-core CPU) to generate worldwide vector tile data.</p><p>My goal is to maintain a micro EC2 instance for hosting the website and only set up a medium EC2 instance when it’s time to update map data. The whole procedure should be automatic and doesn’t require human interwind. In this way, I can minimize my time and expense to maintain the service.</p><p>After reading the article <a href=\"\"></a>, I decide to use AWS Auto-Scaling service to create instance for tile generation, which is able to self-initialize and self-destroy. With a proper estimation of the time required by tile generation, the procedure would include two steps:</p><ol><li>the auto-scaling service sets up a medium</li></ol>","site":{"data":{}},"excerpt":"<p><a href=\"http://www.opendatadiscovery.org\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a> publishes the status of open data portals every week therefore it needs a weekly update for its vector tile map. In this article, I will discuss how I set up the automatic vector tile preseeding service using AWS EC2 instances and Auto-Scaling service.</p>","more":"<p>Before explaining the solution, I would like to briefly talk about the problem.</p><p><a href=\"http://www.opendatadiscovery.org\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a> currently has very low traffic and it merely requires a micro EC2 instance (1GB memory and 1-core CPU) to host both the server and the database.</p><p>Though it only takes 20 minutes, the tile preseeding is much more expensive and it needs a medium EC2 instance (4GB memory and 2-core CPU) to generate worldwide vector tile data.</p><p>My goal is to maintain a micro EC2 instance for hosting the website and only set up a medium EC2 instance when it’s time to update map data. The whole procedure should be automatic and doesn’t require human interwind. In this way, I can minimize my time and expense to maintain the service.</p><p>After reading the article <a href=\"\"></a>, I decide to use AWS Auto-Scaling service to create instance for tile generation, which is able to self-initialize and self-destroy. With a proper estimation of the time required by tile generation, the procedure would include two steps:</p><ol><li>the auto-scaling service sets up a medium</li></ol>"},{"title":"Using RxJS with PostgreSQL","date":"2017-04-13T18:47:46.000Z","_content":"\nReactive programming is an interesting way in JavaScript to handle asynchronous actions. Some aspects of its nature makes it a powerful tool to build [Node.js]() application that handles large volume of data in the database. In this article, I am going to introduce [RxJS](), the most widely used reactive programming library, and how to use it handle the PostgreSQL database operations.\n\n<!-- more -->\n\n## What's reactive programming?\n","source":"_drafts/Using-RxJS-with-PostgreSQL.md","raw":"title: Using RxJS with PostgreSQL\ndate: 2017-04-13 14:47:46\ntags:\n---\n\nReactive programming is an interesting way in JavaScript to handle asynchronous actions. Some aspects of its nature makes it a powerful tool to build [Node.js]() application that handles large volume of data in the database. In this article, I am going to introduce [RxJS](), the most widely used reactive programming library, and how to use it handle the PostgreSQL database operations.\n\n<!-- more -->\n\n## What's reactive programming?\n","slug":"Using-RxJS-with-PostgreSQL","published":0,"updated":"2018-03-03T20:45:36.122Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgqp00028j0vc0blkriv","content":"<p>Reactive programming is an interesting way in JavaScript to handle asynchronous actions. Some aspects of its nature makes it a powerful tool to build <a href=\"\">Node.js</a> application that handles large volume of data in the database. In this article, I am going to introduce <a href=\"\">RxJS</a>, the most widely used reactive programming library, and how to use it handle the PostgreSQL database operations.</p><a id=\"more\"></a><h2 id=\"What’s-reactive-programming\"><a href=\"#What’s-reactive-programming\" class=\"headerlink\" title=\"What’s reactive programming?\"></a>What’s reactive programming?</h2>","site":{"data":{}},"excerpt":"<p>Reactive programming is an interesting way in JavaScript to handle asynchronous actions. Some aspects of its nature makes it a powerful tool to build <a href=\"\">Node.js</a> application that handles large volume of data in the database. In this article, I am going to introduce <a href=\"\">RxJS</a>, the most widely used reactive programming library, and how to use it handle the PostgreSQL database operations.</p>","more":"<h2 id=\"What’s-reactive-programming\"><a href=\"#What’s-reactive-programming\" class=\"headerlink\" title=\"What’s reactive programming?\"></a>What’s reactive programming?</h2>"},{"_content":"","source":"_posts/AWS-ECS-auto-deployment-with-Travis-CI.md","raw":"","slug":"AWS-ECS-auto-deployment-with-Travis-CI","published":1,"date":"2018-03-24T15:46:58.643Z","updated":"2018-03-24T15:46:58.643Z","_id":"cjf5jlgqt00068j0vc6eo7s1c","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"","site":{"data":{}},"excerpt":"","more":""},{"_content":"Note on the keynote of 25th GIS/SIG annual conference\n=====================================================\n\nIn today's [GIS/SIG annual conference (Pittsford, NY)](http://gis-sig.org/conference/), the very impressive keynote is given by Steve Coast, known as the founder of [OpenStreetMap](http://www.openstreetmap.org). In this keynote *The Past, Present, and Future of OpenStreetMap*, Steve shares the exciting history of OpenStreetMap's rapid growth and discussed the theory behind the open map's success.\n\nClose Map vs. Open Map\n----------------------\n\nThe story of OpenStreetMap dates back to the mid-2000, when the printed map was still the mainstream and the close source online map started to emerge. Like many startup stories today, the idea of map created by everyone was because of Steve's dissatisfaction of this or that problem of the existing products.\n\nAlthough publishing the map on the web had pushed the convenience of usage a lot, it just changed the way of publicaition and did inherited many problems originated from printed map. And Steve simply listed three with his own experience.\n\nThe first one was about the quantity and quality of map data. I am sure most GIS people aren't unfamiliar with this problem since we are spending our whole career life on looking for high quality data: whether they exist, how is the quality, and how to deliver. At the time when OpenStreetMap was just established, there was on publicly available (and very affordable) road network data in the western Europe and not to mention those developing countries.\n\nThe second problem is about the update frequency of map data. Steve told a very funny about the Yahoo! Map and a bridge washed away by flood. Guess how long did Yahoo! Map to update the map: 6 month to confirm the accident + 6 month to validate and publish data = 1 year in which noboday could route to the right way.\n\n**There is a bridge on the Yahoo! Map! It must exist! (well, in fact not)**\n\nThe third problem was the copyright of map data. Like a secret convention of mapping industry, many map producers would add some unrealistic map markers (e.g faked roads) to identify their products. These markers were usually placed to some generally unnoticed places. But as man itself is pretty unpredictable, there were always people living beyond the 'general thinking' and affected by these faked markers for copyright.\n\nInspired by the Wikipedia, the OpenStreetMap aimed to the revisable open map data created by everyone. The OpenStreetMap at the earliest day was actually awful compared to all existing products. Just image the first contributor in Europe started from nothing but the coast line.\n\n![user count](http://wiki.openstreetmap.org/w/images/thumb/7/79/Osmdbstats1_users.png/800px-Osmdbstats1_users.png)\n\nAs OpenStreetMap's user increased rapidly, the visible data on the map increased rapidly as well. On the other handle, the more complete data was attracting more people to use and contribute to the map.\n\n<iframe src=\"https://player.vimeo.com/video/51341994\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe><p><a href=\"https://vimeo.com/51341994\">US edits to OpenStreetMap 2007-2012</a> from <a href=\"https://vimeo.com/itoworld\">ItoWorld</a> on <a href=\"https://vimeo.com\">Vimeo</a>.</p>\n\nTheory of Innovation\n--------------------\n\nOK, so what made the OpenStreetMap so successful?\n\nSteve concluded it in the following three points:\n\n-\tFun. OpenStreetMap tries hard to make the mapping more friendly and have more fun. (and then more addictive!!!)\n\n-\tEasy.\n\nNext Map?\n---------\n","source":"_drafts/note.md","raw":"Note on the keynote of 25th GIS/SIG annual conference\n=====================================================\n\nIn today's [GIS/SIG annual conference (Pittsford, NY)](http://gis-sig.org/conference/), the very impressive keynote is given by Steve Coast, known as the founder of [OpenStreetMap](http://www.openstreetmap.org). In this keynote *The Past, Present, and Future of OpenStreetMap*, Steve shares the exciting history of OpenStreetMap's rapid growth and discussed the theory behind the open map's success.\n\nClose Map vs. Open Map\n----------------------\n\nThe story of OpenStreetMap dates back to the mid-2000, when the printed map was still the mainstream and the close source online map started to emerge. Like many startup stories today, the idea of map created by everyone was because of Steve's dissatisfaction of this or that problem of the existing products.\n\nAlthough publishing the map on the web had pushed the convenience of usage a lot, it just changed the way of publicaition and did inherited many problems originated from printed map. And Steve simply listed three with his own experience.\n\nThe first one was about the quantity and quality of map data. I am sure most GIS people aren't unfamiliar with this problem since we are spending our whole career life on looking for high quality data: whether they exist, how is the quality, and how to deliver. At the time when OpenStreetMap was just established, there was on publicly available (and very affordable) road network data in the western Europe and not to mention those developing countries.\n\nThe second problem is about the update frequency of map data. Steve told a very funny about the Yahoo! Map and a bridge washed away by flood. Guess how long did Yahoo! Map to update the map: 6 month to confirm the accident + 6 month to validate and publish data = 1 year in which noboday could route to the right way.\n\n**There is a bridge on the Yahoo! Map! It must exist! (well, in fact not)**\n\nThe third problem was the copyright of map data. Like a secret convention of mapping industry, many map producers would add some unrealistic map markers (e.g faked roads) to identify their products. These markers were usually placed to some generally unnoticed places. But as man itself is pretty unpredictable, there were always people living beyond the 'general thinking' and affected by these faked markers for copyright.\n\nInspired by the Wikipedia, the OpenStreetMap aimed to the revisable open map data created by everyone. The OpenStreetMap at the earliest day was actually awful compared to all existing products. Just image the first contributor in Europe started from nothing but the coast line.\n\n![user count](http://wiki.openstreetmap.org/w/images/thumb/7/79/Osmdbstats1_users.png/800px-Osmdbstats1_users.png)\n\nAs OpenStreetMap's user increased rapidly, the visible data on the map increased rapidly as well. On the other handle, the more complete data was attracting more people to use and contribute to the map.\n\n<iframe src=\"https://player.vimeo.com/video/51341994\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe><p><a href=\"https://vimeo.com/51341994\">US edits to OpenStreetMap 2007-2012</a> from <a href=\"https://vimeo.com/itoworld\">ItoWorld</a> on <a href=\"https://vimeo.com\">Vimeo</a>.</p>\n\nTheory of Innovation\n--------------------\n\nOK, so what made the OpenStreetMap so successful?\n\nSteve concluded it in the following three points:\n\n-\tFun. OpenStreetMap tries hard to make the mapping more friendly and have more fun. (and then more addictive!!!)\n\n-\tEasy.\n\nNext Map?\n---------\n","slug":"note","published":0,"date":"2018-03-03T20:45:36.102Z","updated":"2018-03-03T20:45:36.102Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgqw00088j0vr7ntod46","content":"<h1 id=\"Note-on-the-keynote-of-25th-GIS-SIG-annual-conference\"><a href=\"#Note-on-the-keynote-of-25th-GIS-SIG-annual-conference\" class=\"headerlink\" title=\"Note on the keynote of 25th GIS/SIG annual conference\"></a>Note on the keynote of 25th GIS/SIG annual conference</h1><p>In today’s <a href=\"http://gis-sig.org/conference/\" target=\"_blank\" rel=\"noopener\">GIS/SIG annual conference (Pittsford, NY)</a>, the very impressive keynote is given by Steve Coast, known as the founder of <a href=\"http://www.openstreetmap.org\" target=\"_blank\" rel=\"noopener\">OpenStreetMap</a>. In this keynote <em>The Past, Present, and Future of OpenStreetMap</em>, Steve shares the exciting history of OpenStreetMap’s rapid growth and discussed the theory behind the open map’s success.</p><h2 id=\"Close-Map-vs-Open-Map\"><a href=\"#Close-Map-vs-Open-Map\" class=\"headerlink\" title=\"Close Map vs. Open Map\"></a>Close Map vs. Open Map</h2><p>The story of OpenStreetMap dates back to the mid-2000, when the printed map was still the mainstream and the close source online map started to emerge. Like many startup stories today, the idea of map created by everyone was because of Steve’s dissatisfaction of this or that problem of the existing products.</p><p>Although publishing the map on the web had pushed the convenience of usage a lot, it just changed the way of publicaition and did inherited many problems originated from printed map. And Steve simply listed three with his own experience.</p><p>The first one was about the quantity and quality of map data. I am sure most GIS people aren’t unfamiliar with this problem since we are spending our whole career life on looking for high quality data: whether they exist, how is the quality, and how to deliver. At the time when OpenStreetMap was just established, there was on publicly available (and very affordable) road network data in the western Europe and not to mention those developing countries.</p><p>The second problem is about the update frequency of map data. Steve told a very funny about the Yahoo! Map and a bridge washed away by flood. Guess how long did Yahoo! Map to update the map: 6 month to confirm the accident + 6 month to validate and publish data = 1 year in which noboday could route to the right way.</p><p><strong>There is a bridge on the Yahoo! Map! It must exist! (well, in fact not)</strong></p><p>The third problem was the copyright of map data. Like a secret convention of mapping industry, many map producers would add some unrealistic map markers (e.g faked roads) to identify their products. These markers were usually placed to some generally unnoticed places. But as man itself is pretty unpredictable, there were always people living beyond the ‘general thinking’ and affected by these faked markers for copyright.</p><p>Inspired by the Wikipedia, the OpenStreetMap aimed to the revisable open map data created by everyone. The OpenStreetMap at the earliest day was actually awful compared to all existing products. Just image the first contributor in Europe started from nothing but the coast line.</p><p><img src=\"http://wiki.openstreetmap.org/w/images/thumb/7/79/Osmdbstats1_users.png/800px-Osmdbstats1_users.png\" alt=\"user count\"></p><p>As OpenStreetMap’s user increased rapidly, the visible data on the map increased rapidly as well. On the other handle, the more complete data was attracting more people to use and contribute to the map.</p><p><iframe src=\"https://player.vimeo.com/video/51341994\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen=\"\" mozallowfullscreen=\"\" allowfullscreen></iframe></p><p><a href=\"https://vimeo.com/51341994\" target=\"_blank\" rel=\"noopener\">US edits to OpenStreetMap 2007-2012</a> from <a href=\"https://vimeo.com/itoworld\" target=\"_blank\" rel=\"noopener\">ItoWorld</a> on <a href=\"https://vimeo.com\" target=\"_blank\" rel=\"noopener\">Vimeo</a>.</p><p></p><h2 id=\"Theory-of-Innovation\"><a href=\"#Theory-of-Innovation\" class=\"headerlink\" title=\"Theory of Innovation\"></a>Theory of Innovation</h2><p>OK, so what made the OpenStreetMap so successful?</p><p>Steve concluded it in the following three points:</p><ul><li><p>Fun. OpenStreetMap tries hard to make the mapping more friendly and have more fun. (and then more addictive!!!)</p></li><li><p>Easy.</p></li></ul><h2 id=\"Next-Map\"><a href=\"#Next-Map\" class=\"headerlink\" title=\"Next Map?\"></a>Next Map?</h2>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Note-on-the-keynote-of-25th-GIS-SIG-annual-conference\"><a href=\"#Note-on-the-keynote-of-25th-GIS-SIG-annual-conference\" class=\"headerlink\" title=\"Note on the keynote of 25th GIS/SIG annual conference\"></a>Note on the keynote of 25th GIS/SIG annual conference</h1><p>In today’s <a href=\"http://gis-sig.org/conference/\" target=\"_blank\" rel=\"noopener\">GIS/SIG annual conference (Pittsford, NY)</a>, the very impressive keynote is given by Steve Coast, known as the founder of <a href=\"http://www.openstreetmap.org\" target=\"_blank\" rel=\"noopener\">OpenStreetMap</a>. In this keynote <em>The Past, Present, and Future of OpenStreetMap</em>, Steve shares the exciting history of OpenStreetMap’s rapid growth and discussed the theory behind the open map’s success.</p><h2 id=\"Close-Map-vs-Open-Map\"><a href=\"#Close-Map-vs-Open-Map\" class=\"headerlink\" title=\"Close Map vs. Open Map\"></a>Close Map vs. Open Map</h2><p>The story of OpenStreetMap dates back to the mid-2000, when the printed map was still the mainstream and the close source online map started to emerge. Like many startup stories today, the idea of map created by everyone was because of Steve’s dissatisfaction of this or that problem of the existing products.</p><p>Although publishing the map on the web had pushed the convenience of usage a lot, it just changed the way of publicaition and did inherited many problems originated from printed map. And Steve simply listed three with his own experience.</p><p>The first one was about the quantity and quality of map data. I am sure most GIS people aren’t unfamiliar with this problem since we are spending our whole career life on looking for high quality data: whether they exist, how is the quality, and how to deliver. At the time when OpenStreetMap was just established, there was on publicly available (and very affordable) road network data in the western Europe and not to mention those developing countries.</p><p>The second problem is about the update frequency of map data. Steve told a very funny about the Yahoo! Map and a bridge washed away by flood. Guess how long did Yahoo! Map to update the map: 6 month to confirm the accident + 6 month to validate and publish data = 1 year in which noboday could route to the right way.</p><p><strong>There is a bridge on the Yahoo! Map! It must exist! (well, in fact not)</strong></p><p>The third problem was the copyright of map data. Like a secret convention of mapping industry, many map producers would add some unrealistic map markers (e.g faked roads) to identify their products. These markers were usually placed to some generally unnoticed places. But as man itself is pretty unpredictable, there were always people living beyond the ‘general thinking’ and affected by these faked markers for copyright.</p><p>Inspired by the Wikipedia, the OpenStreetMap aimed to the revisable open map data created by everyone. The OpenStreetMap at the earliest day was actually awful compared to all existing products. Just image the first contributor in Europe started from nothing but the coast line.</p><p><img src=\"http://wiki.openstreetmap.org/w/images/thumb/7/79/Osmdbstats1_users.png/800px-Osmdbstats1_users.png\" alt=\"user count\"></p><p>As OpenStreetMap’s user increased rapidly, the visible data on the map increased rapidly as well. On the other handle, the more complete data was attracting more people to use and contribute to the map.</p><p><iframe src=\"https://player.vimeo.com/video/51341994\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen=\"\" mozallowfullscreen=\"\" allowfullscreen></iframe></p><p><a href=\"https://vimeo.com/51341994\" target=\"_blank\" rel=\"noopener\">US edits to OpenStreetMap 2007-2012</a> from <a href=\"https://vimeo.com/itoworld\" target=\"_blank\" rel=\"noopener\">ItoWorld</a> on <a href=\"https://vimeo.com\" target=\"_blank\" rel=\"noopener\">Vimeo</a>.</p><p></p><h2 id=\"Theory-of-Innovation\"><a href=\"#Theory-of-Innovation\" class=\"headerlink\" title=\"Theory of Innovation\"></a>Theory of Innovation</h2><p>OK, so what made the OpenStreetMap so successful?</p><p>Steve concluded it in the following three points:</p><ul><li><p>Fun. OpenStreetMap tries hard to make the mapping more friendly and have more fun. (and then more addictive!!!)</p></li><li><p>Easy.</p></li></ul><h2 id=\"Next-Map\"><a href=\"#Next-Map\" class=\"headerlink\" title=\"Next Map?\"></a>Next Map?</h2>"},{"title":"Adding GeoJSON layers to your Leaflet map in TypeScript","date":"2017-02-04T05:53:35.000Z","_content":"\nAdding a GeoJSON layer to a [Leaflet](http://leafletjs.com/) map in [TypeScript](http://www.typescriptlang.org/) has some difference from that in JavaScript.\n\n<!-- more -->\n\n It's because the GeoJSON is typed in TypeScript and the type declaration of Leaflet adopts it. So whenever you construct the GeoJSON object in TypeScript, it's important to declare the type of the variable as GeoJSON type:\n\n ``` typescript\n// it's necessary to tell variable type\nlet featureCollection: GeoJSON.FeatureCollection<any> = {\n  type: 'FeatureCollection',\n  features: [\n    {\n      type: 'Feature',\n      geometry: {\n        type: 'Point',\n        coordinates: [0, 0]\n      },\n      properties: {}\n    }\n  ]\n};\n\n// the Leaflet API is the same as the JavaScript one, except for the parameter type requirement\nL.geoJSON(featureCollection).addTo(this.map);\n```\n\nFor more about the specification and example, take a look at the [GeoJSON type definition](https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/geojson).\n","source":"_posts/Adding-GeoJSON-layers-in-your-Leaflet-project-in-TypeScript.md","raw":"title: Adding GeoJSON layers to your Leaflet map in TypeScript\ndate: 2017-02-04 00:53:35\ncategories:\n- GIS\ntags:\n- geojson\n- leaflet\n-\ttypescript\n---\n\nAdding a GeoJSON layer to a [Leaflet](http://leafletjs.com/) map in [TypeScript](http://www.typescriptlang.org/) has some difference from that in JavaScript.\n\n<!-- more -->\n\n It's because the GeoJSON is typed in TypeScript and the type declaration of Leaflet adopts it. So whenever you construct the GeoJSON object in TypeScript, it's important to declare the type of the variable as GeoJSON type:\n\n ``` typescript\n// it's necessary to tell variable type\nlet featureCollection: GeoJSON.FeatureCollection<any> = {\n  type: 'FeatureCollection',\n  features: [\n    {\n      type: 'Feature',\n      geometry: {\n        type: 'Point',\n        coordinates: [0, 0]\n      },\n      properties: {}\n    }\n  ]\n};\n\n// the Leaflet API is the same as the JavaScript one, except for the parameter type requirement\nL.geoJSON(featureCollection).addTo(this.map);\n```\n\nFor more about the specification and example, take a look at the [GeoJSON type definition](https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/geojson).\n","slug":"Adding-GeoJSON-layers-in-your-Leaflet-project-in-TypeScript","published":1,"updated":"2018-03-03T20:45:36.102Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgqx00098j0vfa7mshph","content":"<p>Adding a GeoJSON layer to a <a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> map in <a href=\"http://www.typescriptlang.org/\" target=\"_blank\" rel=\"noopener\">TypeScript</a> has some difference from that in JavaScript.</p><a id=\"more\"></a><p>It’s because the GeoJSON is typed in TypeScript and the type declaration of Leaflet adopts it. So whenever you construct the GeoJSON object in TypeScript, it’s important to declare the type of the variable as GeoJSON type:</p><figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// it's necessary to tell variable type</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> featureCollection: GeoJSON.FeatureCollection&lt;<span class=\"built_in\">any</span>&gt; = &#123;</span><br><span class=\"line\">  <span class=\"keyword\">type</span>: <span class=\"string\">'FeatureCollection'</span>,</span><br><span class=\"line\">  features: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"keyword\">type</span>: <span class=\"string\">'Feature'</span>,</span><br><span class=\"line\">      geometry: &#123;</span><br><span class=\"line\">        <span class=\"keyword\">type</span>: <span class=\"string\">'Point'</span>,</span><br><span class=\"line\">        coordinates: [<span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      properties: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// the Leaflet API is the same as the JavaScript one, except for the parameter type requirement</span></span><br><span class=\"line\">L.geoJSON(featureCollection).addTo(<span class=\"keyword\">this</span>.map);</span><br></pre></td></tr></table></figure><p>For more about the specification and example, take a look at the <a href=\"https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/geojson\" target=\"_blank\" rel=\"noopener\">GeoJSON type definition</a>.</p>","site":{"data":{}},"excerpt":"<p>Adding a GeoJSON layer to a <a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> map in <a href=\"http://www.typescriptlang.org/\" target=\"_blank\" rel=\"noopener\">TypeScript</a> has some difference from that in JavaScript.</p>","more":"<p>It’s because the GeoJSON is typed in TypeScript and the type declaration of Leaflet adopts it. So whenever you construct the GeoJSON object in TypeScript, it’s important to declare the type of the variable as GeoJSON type:</p><figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// it's necessary to tell variable type</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> featureCollection: GeoJSON.FeatureCollection&lt;<span class=\"built_in\">any</span>&gt; = &#123;</span><br><span class=\"line\">  <span class=\"keyword\">type</span>: <span class=\"string\">'FeatureCollection'</span>,</span><br><span class=\"line\">  features: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"keyword\">type</span>: <span class=\"string\">'Feature'</span>,</span><br><span class=\"line\">      geometry: &#123;</span><br><span class=\"line\">        <span class=\"keyword\">type</span>: <span class=\"string\">'Point'</span>,</span><br><span class=\"line\">        coordinates: [<span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      properties: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// the Leaflet API is the same as the JavaScript one, except for the parameter type requirement</span></span><br><span class=\"line\">L.geoJSON(featureCollection).addTo(<span class=\"keyword\">this</span>.map);</span><br></pre></td></tr></table></figure><p>For more about the specification and example, take a look at the <a href=\"https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/geojson\" target=\"_blank\" rel=\"noopener\">GeoJSON type definition</a>.</p>"},{"title":"Boundary.Now: a simple tool to extract OSM place boundaries","date":"2017-02-04T22:15:56.000Z","updated":"2017-02-26T05:00:00.000Z","_content":"\nGetting a place boundary is sometimes harder than it looks like.\n\n<!-- more -->\n\nThere are a couple of reasons why it's hard:\n\n* The boundary data is actually unavailable or not released.\n* The boundary data is available, but packaged in a national dataset, like most governmental open data.\n* The boundary data is visible, but not downloadable, like the Google map does.\n* The boundary data is exportable, but the use is limited, like the Bing map geocoding API does.\n\nSo it's pretty common for a data analyst to take a lot of effort to find and extract place boundaries. It's even more painful when we have to download national datasets just for a few cities' boundary.\n\nOh, wait! Isn't it a free and global geospatial database out there?\n\nYeah, [OpenStreetMap](https://www.openstreetmap.org/) is awesome and the great [Nominatim](http://nominatim.openstreetmap.org/) service allows us to search through the OSM database with a place name.\n\nThe only problem is the Nominatim interface is not designed for data extraction, even though the API does return place boundary. So I develop [**Boundary.Now**](https://haoliangyu.github.io/boundary.now/), an interface for Nominatim geocoding API to download place boundary.\n\n{% asset_img boundary-now.png This is an example image %}\n\nLike the original interface, it will provide a search box for the desired place name. In the result list, only search results with boundary data are shown. The boundary data could be downloaded in **GeoJSON**, a format widely used in web development, or in **Shapefile**, a standard format in the GIS world.\n\nYou can open the tool [**here**](https://haoliangyu.github.io/boundary.now/) and the project is open at [GitHub](https://github.com/haoliangyu/boundary.now/).\n","source":"_posts/Boundary-Now-a-simple-tool-to-extract-OSM-place-boundaries.md","raw":"title: 'Boundary.Now: a simple tool to extract OSM place boundaries'\ndate: 2017-02-04 17:15:56\nupdated: 2017-02-26\ncategories:\n- Project\ntags:\n- gis\n- openstreetmap\n---\n\nGetting a place boundary is sometimes harder than it looks like.\n\n<!-- more -->\n\nThere are a couple of reasons why it's hard:\n\n* The boundary data is actually unavailable or not released.\n* The boundary data is available, but packaged in a national dataset, like most governmental open data.\n* The boundary data is visible, but not downloadable, like the Google map does.\n* The boundary data is exportable, but the use is limited, like the Bing map geocoding API does.\n\nSo it's pretty common for a data analyst to take a lot of effort to find and extract place boundaries. It's even more painful when we have to download national datasets just for a few cities' boundary.\n\nOh, wait! Isn't it a free and global geospatial database out there?\n\nYeah, [OpenStreetMap](https://www.openstreetmap.org/) is awesome and the great [Nominatim](http://nominatim.openstreetmap.org/) service allows us to search through the OSM database with a place name.\n\nThe only problem is the Nominatim interface is not designed for data extraction, even though the API does return place boundary. So I develop [**Boundary.Now**](https://haoliangyu.github.io/boundary.now/), an interface for Nominatim geocoding API to download place boundary.\n\n{% asset_img boundary-now.png This is an example image %}\n\nLike the original interface, it will provide a search box for the desired place name. In the result list, only search results with boundary data are shown. The boundary data could be downloaded in **GeoJSON**, a format widely used in web development, or in **Shapefile**, a standard format in the GIS world.\n\nYou can open the tool [**here**](https://haoliangyu.github.io/boundary.now/) and the project is open at [GitHub](https://github.com/haoliangyu/boundary.now/).\n","slug":"Boundary-Now-a-simple-tool-to-extract-OSM-place-boundaries","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgqz000c8j0v5575jex4","content":"<p>Getting a place boundary is sometimes harder than it looks like.</p><a id=\"more\"></a><p>There are a couple of reasons why it’s hard:</p><ul><li>The boundary data is actually unavailable or not released.</li><li>The boundary data is available, but packaged in a national dataset, like most governmental open data.</li><li>The boundary data is visible, but not downloadable, like the Google map does.</li><li>The boundary data is exportable, but the use is limited, like the Bing map geocoding API does.</li></ul><p>So it’s pretty common for a data analyst to take a lot of effort to find and extract place boundaries. It’s even more painful when we have to download national datasets just for a few cities’ boundary.</p><p>Oh, wait! Isn’t it a free and global geospatial database out there?</p><p>Yeah, <a href=\"https://www.openstreetmap.org/\" target=\"_blank\" rel=\"noopener\">OpenStreetMap</a> is awesome and the great <a href=\"http://nominatim.openstreetmap.org/\" target=\"_blank\" rel=\"noopener\">Nominatim</a> service allows us to search through the OSM database with a place name.</p><p>The only problem is the Nominatim interface is not designed for data extraction, even though the API does return place boundary. So I develop <a href=\"https://haoliangyu.github.io/boundary.now/\"><strong>Boundary.Now</strong></a>, an interface for Nominatim geocoding API to download place boundary.</p><p>Like the original interface, it will provide a search box for the desired place name. In the result list, only search results with boundary data are shown. The boundary data could be downloaded in <strong>GeoJSON</strong>, a format widely used in web development, or in <strong>Shapefile</strong>, a standard format in the GIS world.</p><p>You can open the tool <a href=\"https://haoliangyu.github.io/boundary.now/\"><strong>here</strong></a> and the project is open at <a href=\"https://github.com/haoliangyu/boundary.now/\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>","site":{"data":{}},"excerpt":"<p>Getting a place boundary is sometimes harder than it looks like.</p>","more":"<p>There are a couple of reasons why it’s hard:</p><ul><li>The boundary data is actually unavailable or not released.</li><li>The boundary data is available, but packaged in a national dataset, like most governmental open data.</li><li>The boundary data is visible, but not downloadable, like the Google map does.</li><li>The boundary data is exportable, but the use is limited, like the Bing map geocoding API does.</li></ul><p>So it’s pretty common for a data analyst to take a lot of effort to find and extract place boundaries. It’s even more painful when we have to download national datasets just for a few cities’ boundary.</p><p>Oh, wait! Isn’t it a free and global geospatial database out there?</p><p>Yeah, <a href=\"https://www.openstreetmap.org/\" target=\"_blank\" rel=\"noopener\">OpenStreetMap</a> is awesome and the great <a href=\"http://nominatim.openstreetmap.org/\" target=\"_blank\" rel=\"noopener\">Nominatim</a> service allows us to search through the OSM database with a place name.</p><p>The only problem is the Nominatim interface is not designed for data extraction, even though the API does return place boundary. So I develop <a href=\"https://haoliangyu.github.io/boundary.now/\"><strong>Boundary.Now</strong></a>, an interface for Nominatim geocoding API to download place boundary.</p><p>Like the original interface, it will provide a search box for the desired place name. In the result list, only search results with boundary data are shown. The boundary data could be downloaded in <strong>GeoJSON</strong>, a format widely used in web development, or in <strong>Shapefile</strong>, a standard format in the GIS world.</p><p>You can open the tool <a href=\"https://haoliangyu.github.io/boundary.now/\"><strong>here</strong></a> and the project is open at <a href=\"https://github.com/haoliangyu/boundary.now/\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>"},{"title":"ArcMap Raster Edit Suite","date":"2014-09-17T04:00:00.000Z","updated":"2015-12-05T05:00:00.000Z","_content":"\nArcMap Raster Edit Suite (ARES) is an addin for ArcMap 10.x that enables value editing of single pixels on raster layer. This is an open-source software and the project is hosted at [GitHub](https://github.com/haoliangyu/ares) and published at [SourceForge](http://sourceforge.net/projects/arcmaprastereditor/?source=navbar) as well.\n<!-- more -->\nThis addin only works on ArcMap 10.0/10.1/10.2/10.3.\n\nA detail user guide could be found at: **[ArcMap Raster Edit Suite](https://github.com/haoliangyu/ares/wiki)**\n\n## Download\n\n[ARES 0.2.1](https://github.com/dz316424/ares/releases/download/v0.2.1/ARES.0.2.1.zip)\n\nThe listed packages are stable releases and may not include up-to-date features. To download latest version, please visit the [project page](https://github.com/haoliangyu/ares/).\n\n## Installation\n\nSimply double-click the RasterEditor.esriAddIn in the package and ArcGIS AddIn installation wizzard will guide you. for more detail, check the wiki page [Install and Uninstall](https://github.com/haoliangyu/ares/wiki/Install-and-Uninstall).\n","source":"_posts/ArcMap-Raster-Edit-Suite.md","raw":"title: ArcMap Raster Edit Suite\ndate: 2014-09-17\nupdated: 2015-12-05\ncategories:\n- Project\ntags:\n- gis\n- project\n- arcgis\n---\n\nArcMap Raster Edit Suite (ARES) is an addin for ArcMap 10.x that enables value editing of single pixels on raster layer. This is an open-source software and the project is hosted at [GitHub](https://github.com/haoliangyu/ares) and published at [SourceForge](http://sourceforge.net/projects/arcmaprastereditor/?source=navbar) as well.\n<!-- more -->\nThis addin only works on ArcMap 10.0/10.1/10.2/10.3.\n\nA detail user guide could be found at: **[ArcMap Raster Edit Suite](https://github.com/haoliangyu/ares/wiki)**\n\n## Download\n\n[ARES 0.2.1](https://github.com/dz316424/ares/releases/download/v0.2.1/ARES.0.2.1.zip)\n\nThe listed packages are stable releases and may not include up-to-date features. To download latest version, please visit the [project page](https://github.com/haoliangyu/ares/).\n\n## Installation\n\nSimply double-click the RasterEditor.esriAddIn in the package and ArcGIS AddIn installation wizzard will guide you. for more detail, check the wiki page [Install and Uninstall](https://github.com/haoliangyu/ares/wiki/Install-and-Uninstall).\n","slug":"ArcMap-Raster-Edit-Suite","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgr1000d8j0vuygjfi7v","content":"<p>ArcMap Raster Edit Suite (ARES) is an addin for ArcMap 10.x that enables value editing of single pixels on raster layer. This is an open-source software and the project is hosted at <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">GitHub</a> and published at <a href=\"http://sourceforge.net/projects/arcmaprastereditor/?source=navbar\" target=\"_blank\" rel=\"noopener\">SourceForge</a> as well.<br><a id=\"more\"></a><br>This addin only works on ArcMap 10.0/10.1/10.2/10.3.</p><p>A detail user guide could be found at: <strong><a href=\"https://github.com/haoliangyu/ares/wiki\" target=\"_blank\" rel=\"noopener\">ArcMap Raster Edit Suite</a></strong></p><h2 id=\"Download\"><a href=\"#Download\" class=\"headerlink\" title=\"Download\"></a>Download</h2><p><a href=\"https://github.com/dz316424/ares/releases/download/v0.2.1/ARES.0.2.1.zip\" target=\"_blank\" rel=\"noopener\">ARES 0.2.1</a></p><p>The listed packages are stable releases and may not include up-to-date features. To download latest version, please visit the <a href=\"https://github.com/haoliangyu/ares/\" target=\"_blank\" rel=\"noopener\">project page</a>.</p><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>Simply double-click the RasterEditor.esriAddIn in the package and ArcGIS AddIn installation wizzard will guide you. for more detail, check the wiki page <a href=\"https://github.com/haoliangyu/ares/wiki/Install-and-Uninstall\" target=\"_blank\" rel=\"noopener\">Install and Uninstall</a>.</p>","site":{"data":{}},"excerpt":"<p>ArcMap Raster Edit Suite (ARES) is an addin for ArcMap 10.x that enables value editing of single pixels on raster layer. This is an open-source software and the project is hosted at <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">GitHub</a> and published at <a href=\"http://sourceforge.net/projects/arcmaprastereditor/?source=navbar\" target=\"_blank\" rel=\"noopener\">SourceForge</a> as well.<br>","more":"<br>This addin only works on ArcMap 10.0/10.1/10.2/10.3.</p><p>A detail user guide could be found at: <strong><a href=\"https://github.com/haoliangyu/ares/wiki\" target=\"_blank\" rel=\"noopener\">ArcMap Raster Edit Suite</a></strong></p><h2 id=\"Download\"><a href=\"#Download\" class=\"headerlink\" title=\"Download\"></a>Download</h2><p><a href=\"https://github.com/dz316424/ares/releases/download/v0.2.1/ARES.0.2.1.zip\" target=\"_blank\" rel=\"noopener\">ARES 0.2.1</a></p><p>The listed packages are stable releases and may not include up-to-date features. To download latest version, please visit the <a href=\"https://github.com/haoliangyu/ares/\" target=\"_blank\" rel=\"noopener\">project page</a>.</p><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>Simply double-click the RasterEditor.esriAddIn in the package and ArcGIS AddIn installation wizzard will guide you. for more detail, check the wiki page <a href=\"https://github.com/haoliangyu/ares/wiki/Install-and-Uninstall\" target=\"_blank\" rel=\"noopener\">Install and Uninstall</a>.</p>"},{"title":"Celebrating the 1,000 data portals at OpenDataDiscovery.org","date":"2017-01-16T05:00:00.000Z","comments":1,"_content":"\nI am pleased to announce that [OpenDataDiscovery.org](http://www.opendatadiscovery.org/) is now tracking more than 1,000 open data portals, 40% of data portals in the world!\n\n<!-- more -->\n\n{% asset_img region-map.png This is an example image %}\n\n\nA map of all recorded 329 cities / provinces / countries worldwide, in which each color category includes 20% of all portals.\n\nThanks to [OpenDataSoft](https://www.opendatasoft.com/)'s comprehensive open data portal survey (see [their blog](https://opendatainception.io/)), I am able to quickly identify a list of important open data service providers. So far seven major open data service providers have been supported:\n\n* [ArcGIS Open Data](http://opendata.arcgis.com/) (595 portals, 26,281 datasets)\n* [CKAN](http://ckan.org/) (89 portals, 842,154 datasets)\n* [DKAN](http://www.nucivic.com/dkan/) (40 portals, 14,289 datasets)\n* [GeoNode](http://geonode.org/) (10 portals, 9,604 datasets)\n* [Junar](http://junar.com) (11 portals, 1,860 datasets)\n* [OpenDataSoft](https://www.opendatasoft.com/) (79 portals, 6,084 datasets)\n* [Socrata](http://socrata.com/) (177 portals, 110,130 datasets)\n\nAs of 01/16/2017, the total number of datasets opened at these portals is more than 1 million! Also, thousands of data categories and publishers, and nearly a million data tags have been identified. This project just reveals an immense and existing world of open data and all these numbers are still likely to be underestimated.\n\nFor the following months, I will focus on analyzing the existing/coming data and building better data visualization. As the portal level metadata collection procedure is close to done, it is also time to explore the collection of the dataset level metadata.\n\nI can wait to work on it to see what story this data is telling!\n","source":"_posts/Celebrating-the-1-000-data-portals-at-OpenDataDiscovery-org.md","raw":"title: 'Celebrating the 1,000 data portals at OpenDataDiscovery.org'\ndate: 2017-01-16\ncomments: true\ncategories:\n- GIS\ntags:\n- open data\n- gis\n- OpenDataDiscovery.org\n---\n\nI am pleased to announce that [OpenDataDiscovery.org](http://www.opendatadiscovery.org/) is now tracking more than 1,000 open data portals, 40% of data portals in the world!\n\n<!-- more -->\n\n{% asset_img region-map.png This is an example image %}\n\n\nA map of all recorded 329 cities / provinces / countries worldwide, in which each color category includes 20% of all portals.\n\nThanks to [OpenDataSoft](https://www.opendatasoft.com/)'s comprehensive open data portal survey (see [their blog](https://opendatainception.io/)), I am able to quickly identify a list of important open data service providers. So far seven major open data service providers have been supported:\n\n* [ArcGIS Open Data](http://opendata.arcgis.com/) (595 portals, 26,281 datasets)\n* [CKAN](http://ckan.org/) (89 portals, 842,154 datasets)\n* [DKAN](http://www.nucivic.com/dkan/) (40 portals, 14,289 datasets)\n* [GeoNode](http://geonode.org/) (10 portals, 9,604 datasets)\n* [Junar](http://junar.com) (11 portals, 1,860 datasets)\n* [OpenDataSoft](https://www.opendatasoft.com/) (79 portals, 6,084 datasets)\n* [Socrata](http://socrata.com/) (177 portals, 110,130 datasets)\n\nAs of 01/16/2017, the total number of datasets opened at these portals is more than 1 million! Also, thousands of data categories and publishers, and nearly a million data tags have been identified. This project just reveals an immense and existing world of open data and all these numbers are still likely to be underestimated.\n\nFor the following months, I will focus on analyzing the existing/coming data and building better data visualization. As the portal level metadata collection procedure is close to done, it is also time to explore the collection of the dataset level metadata.\n\nI can wait to work on it to see what story this data is telling!\n","slug":"Celebrating-the-1-000-data-portals-at-OpenDataDiscovery-org","published":1,"updated":"2018-03-03T20:45:36.110Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgr3000h8j0v5hh3c2gb","content":"<p>I am pleased to announce that <a href=\"http://www.opendatadiscovery.org/\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a> is now tracking more than 1,000 open data portals, 40% of data portals in the world!</p><a id=\"more\"></a><p>A map of all recorded 329 cities / provinces / countries worldwide, in which each color category includes 20% of all portals.</p><p>Thanks to <a href=\"https://www.opendatasoft.com/\" target=\"_blank\" rel=\"noopener\">OpenDataSoft</a>‘s comprehensive open data portal survey (see <a href=\"https://opendatainception.io/\" target=\"_blank\" rel=\"noopener\">their blog</a>), I am able to quickly identify a list of important open data service providers. So far seven major open data service providers have been supported:</p><ul><li><a href=\"http://opendata.arcgis.com/\" target=\"_blank\" rel=\"noopener\">ArcGIS Open Data</a> (595 portals, 26,281 datasets)</li><li><a href=\"http://ckan.org/\" target=\"_blank\" rel=\"noopener\">CKAN</a> (89 portals, 842,154 datasets)</li><li><a href=\"http://www.nucivic.com/dkan/\" target=\"_blank\" rel=\"noopener\">DKAN</a> (40 portals, 14,289 datasets)</li><li><a href=\"http://geonode.org/\" target=\"_blank\" rel=\"noopener\">GeoNode</a> (10 portals, 9,604 datasets)</li><li><a href=\"http://junar.com\" target=\"_blank\" rel=\"noopener\">Junar</a> (11 portals, 1,860 datasets)</li><li><a href=\"https://www.opendatasoft.com/\" target=\"_blank\" rel=\"noopener\">OpenDataSoft</a> (79 portals, 6,084 datasets)</li><li><a href=\"http://socrata.com/\" target=\"_blank\" rel=\"noopener\">Socrata</a> (177 portals, 110,130 datasets)</li></ul><p>As of 01/16/2017, the total number of datasets opened at these portals is more than 1 million! Also, thousands of data categories and publishers, and nearly a million data tags have been identified. This project just reveals an immense and existing world of open data and all these numbers are still likely to be underestimated.</p><p>For the following months, I will focus on analyzing the existing/coming data and building better data visualization. As the portal level metadata collection procedure is close to done, it is also time to explore the collection of the dataset level metadata.</p><p>I can wait to work on it to see what story this data is telling!</p>","site":{"data":{}},"excerpt":"<p>I am pleased to announce that <a href=\"http://www.opendatadiscovery.org/\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a> is now tracking more than 1,000 open data portals, 40% of data portals in the world!</p>","more":"<p>A map of all recorded 329 cities / provinces / countries worldwide, in which each color category includes 20% of all portals.</p><p>Thanks to <a href=\"https://www.opendatasoft.com/\" target=\"_blank\" rel=\"noopener\">OpenDataSoft</a>‘s comprehensive open data portal survey (see <a href=\"https://opendatainception.io/\" target=\"_blank\" rel=\"noopener\">their blog</a>), I am able to quickly identify a list of important open data service providers. So far seven major open data service providers have been supported:</p><ul><li><a href=\"http://opendata.arcgis.com/\" target=\"_blank\" rel=\"noopener\">ArcGIS Open Data</a> (595 portals, 26,281 datasets)</li><li><a href=\"http://ckan.org/\" target=\"_blank\" rel=\"noopener\">CKAN</a> (89 portals, 842,154 datasets)</li><li><a href=\"http://www.nucivic.com/dkan/\" target=\"_blank\" rel=\"noopener\">DKAN</a> (40 portals, 14,289 datasets)</li><li><a href=\"http://geonode.org/\" target=\"_blank\" rel=\"noopener\">GeoNode</a> (10 portals, 9,604 datasets)</li><li><a href=\"http://junar.com\" target=\"_blank\" rel=\"noopener\">Junar</a> (11 portals, 1,860 datasets)</li><li><a href=\"https://www.opendatasoft.com/\" target=\"_blank\" rel=\"noopener\">OpenDataSoft</a> (79 portals, 6,084 datasets)</li><li><a href=\"http://socrata.com/\" target=\"_blank\" rel=\"noopener\">Socrata</a> (177 portals, 110,130 datasets)</li></ul><p>As of 01/16/2017, the total number of datasets opened at these portals is more than 1 million! Also, thousands of data categories and publishers, and nearly a million data tags have been identified. This project just reveals an immense and existing world of open data and all these numbers are still likely to be underestimated.</p><p>For the following months, I will focus on analyzing the existing/coming data and building better data visualization. As the portal level metadata collection procedure is close to done, it is also time to explore the collection of the dataset level metadata.</p><p>I can wait to work on it to see what story this data is telling!</p>"},{"title":"Comparison of different sampling rules in SVM classification","date":"2015-01-26T05:00:00.000Z","comments":1,"_content":"\nThe problem of sampling rule in Support Vector Machine raised in the discussion when I was in the course *Advanced Remote Sensing*.\n\nThe quality of training sample has deterministic influence to the accuracy of supervised classification methods. A properly designed sampling rule plays a substantial role in yielding an informative training sample set. The design of sampling strategy depends on both the characteristics of objects of interest and the applied classification methods.\n<!-- more -->\nSupport Vector Machine (SVM) is an increasingly popular classification method for remote sensing image both in industry and research. As for the theory and concept of SVM, there have been many introductory articles such as [Roemer`s blog](http://rvlasveld.github.io/blog/2013/07/12/introduction-to-one-class-support-vector-machines/). Because support vectors are selected from training samples for maximizing the margin between classes, quality of sample set will decide the effectiveness of the hyperplane and affect the performance of the classifier.\n\nIn brief the mechanism of SVM is very different from traditional methods like Maximum Likelihood Classification. Here comes the question: **Does the sampling rule used in traditional methods also work for SVM? How does the sampling rule affect the SVM classification result?**\n\n## Experiment\n\n---\n\nTo answer this question, I would like to set up a scenario for the classification experiment. In this case, I choose to perform a cloud detection based on Landsat 8 OLI image for two reasons:\n\n* It is a most basic binary classification.\n\n* Cloud detection could be very challenging because thin cloud is very difficult to detect in many situations.\n\nI use an image with both thick cloud and thin cloud in order to increase the difficulty of classification (See Figure 1). [Band 2 to 7](http://landsat.usgs.gov/band_designations_landsat_satellites.php) are used and the SVM classifier in ENVI is utilized with default configuration. Four hundred pixels are randomly picked up as test sample: half of them are cloud (blue points) and the others are ground objects (yellow points).\n\n{% asset_img testSample.png This is an example image %}\n\n## Sampling Rules\n\n---\n\nI am particularly interested in three sample rules.\n\n* Stratified random sampling\n\nThis is a classic sample rule. Its idea is to randomly select training samples of one class from the sample pool of that class. The sample size of each class could be a fixed number or proportional to the size of sample pool of that class.\n\n* Cluster sampling\n\nHowever, in practice random sampling is sometimes difficult to achieve, especially when the sample is selected by hand or a semi-automatic method. The sample pixels generally tend to be more clustering than random. (it is actually what we do in the ENVI class: drag a region of interest and treat it as sample set)\n\n* Boundary sampling\n\nIts basic idea is that support vectors are likely also located near the geographical boundary of two classes. Although pixels located around geographic boundaries might contain spectral information of both classes to some extent, Foody and Mathur (2006) suggested that mixing pixels at two sides of ground object boundary could be highly effective in SVM even the sample size was very smaller. They considered this approach as a competitive alternative of conventional sampling strategy.\n\nSo I select three training sets based on above sampling rules (See Figure 2).\n\n{% asset_img trainsample.png This is an example image %}\n\n## Training set in feature space\n\n---\n\nWhile using the SVM, we hope that our training samples are located near the boundary of classes in the feature space. Figure 3 shows how samples in three training sets, as well as the test set, scatter at a feature space (red band vs. NIR band).\n\n{% asset_img featurespace.png This is an example image %}\n\nCloud has high reflectance in both red band and near infrared band, however, the reflectance of ground objects (most are vegetation) is low in red band and high in near infrared band. Due to the reflectance difference, samples in the feature space apparently belong to two distinct groups: cloud and ground objects. As shown in Figure 3, the distribution of samples in different training sets are totally different. Boundary sampling produced samples located near the boundary of two classes. Samples generated with stratified random sampling could better represent the overall characteristics of two classes. Clustering sampling within high confidence area would generate samples also clustering in the feature space.\n\n## Result\n\n---\n\nThe classification results are shown in Table 1 and Figure 4.\n\n{% asset_img accuracytable.png This is an example image %}\n\n{% asset_img accuracyfigure.png This is an example image %}\n\nThe results, as expected, indicate that boundary sampling is able to generate better training sample and contribute to higher classification accuracy, compared to the other two sampling strategies.\n\nALl trained classifiers are also applied to the whole study image. Classifier trained with boundary samples is very sensitive to the difference between cloud and non-cloud pixels. It will try to differentiate all mixing pixels and this could be too sensitive. Classifier trained by cluster samples only recognizes thick cloud on the image and ignores pixels with mixing spectral information. Classifier trained by stratified random samples takes a balance between them: neither too aggressive nor too conventional. For detailed discussion, please read my report (see link below).\n\n## Conclusion\n\n---\n\nLet's get back to our initial questions and their answers.\n\n* Does the sampling rule used in traditional methods also work for SVM?\n\nApparently the traditional stratified random sampling still works pretty well for the SVM classification. The classification accuracy in the experiment is about 90%, which is high enough for most situations.\n\n* How does the sampling rule affect the SVM classification result?\n\nIf we can use the portion of boundary (mixing) pixels in the training set to define sampling rule, we are able to build a link among three sampling rules used above. As we include more boundary pixels into the training set, the classifier would become more sensitive and have a better performance in identifying mixing objects. However, high sensitivity could also increase the error rate while identifying mixing objects. There is a trade-off between high sensitivity and low error rate within the selection of sampling strategies.\n\nThere is no generally appropriate sampling rule for all situations. However, depending on the need of classification, there exits an appropriate sampling rule for specific situation. Therefore, it is not difficult to understand why the stratified random sampling is still the first choice in practical use. Though classifier trained stratified random sampling is expected to have fair performance, it is less likely to be trapped into the problem of overestimation and underestimation.\n\n## Link\n\n---\n\nThis article is a simplified version of my project report. For more detail, please read my full report [A Comparison of Sampling Strategies in SVM Classification](https://www.dropbox.com/s/yadta4jnuqgml9s/svm_sampling_report.pdf?dl=0).\n\n## Reference\n\n---\n\n[1] Foody, G. M. and A. Mathur (2006). \"The use of small training sets containing mixed pixels for accurate hard image classification: Training on mixed spectral responses for classification by a SVM.\" Remote Sensing of Environment 103(2): 179-189.\n","source":"_posts/Comparison-of-different-sampling-rules-in-SVM-classification.md","raw":"title: Comparison of different sampling rules in SVM classification\ndate: 2015-01-26 00:00:00\ncomments: true\ncategories:\n- GIS\ntags:\n- remote sensing\n---\n\nThe problem of sampling rule in Support Vector Machine raised in the discussion when I was in the course *Advanced Remote Sensing*.\n\nThe quality of training sample has deterministic influence to the accuracy of supervised classification methods. A properly designed sampling rule plays a substantial role in yielding an informative training sample set. The design of sampling strategy depends on both the characteristics of objects of interest and the applied classification methods.\n<!-- more -->\nSupport Vector Machine (SVM) is an increasingly popular classification method for remote sensing image both in industry and research. As for the theory and concept of SVM, there have been many introductory articles such as [Roemer`s blog](http://rvlasveld.github.io/blog/2013/07/12/introduction-to-one-class-support-vector-machines/). Because support vectors are selected from training samples for maximizing the margin between classes, quality of sample set will decide the effectiveness of the hyperplane and affect the performance of the classifier.\n\nIn brief the mechanism of SVM is very different from traditional methods like Maximum Likelihood Classification. Here comes the question: **Does the sampling rule used in traditional methods also work for SVM? How does the sampling rule affect the SVM classification result?**\n\n## Experiment\n\n---\n\nTo answer this question, I would like to set up a scenario for the classification experiment. In this case, I choose to perform a cloud detection based on Landsat 8 OLI image for two reasons:\n\n* It is a most basic binary classification.\n\n* Cloud detection could be very challenging because thin cloud is very difficult to detect in many situations.\n\nI use an image with both thick cloud and thin cloud in order to increase the difficulty of classification (See Figure 1). [Band 2 to 7](http://landsat.usgs.gov/band_designations_landsat_satellites.php) are used and the SVM classifier in ENVI is utilized with default configuration. Four hundred pixels are randomly picked up as test sample: half of them are cloud (blue points) and the others are ground objects (yellow points).\n\n{% asset_img testSample.png This is an example image %}\n\n## Sampling Rules\n\n---\n\nI am particularly interested in three sample rules.\n\n* Stratified random sampling\n\nThis is a classic sample rule. Its idea is to randomly select training samples of one class from the sample pool of that class. The sample size of each class could be a fixed number or proportional to the size of sample pool of that class.\n\n* Cluster sampling\n\nHowever, in practice random sampling is sometimes difficult to achieve, especially when the sample is selected by hand or a semi-automatic method. The sample pixels generally tend to be more clustering than random. (it is actually what we do in the ENVI class: drag a region of interest and treat it as sample set)\n\n* Boundary sampling\n\nIts basic idea is that support vectors are likely also located near the geographical boundary of two classes. Although pixels located around geographic boundaries might contain spectral information of both classes to some extent, Foody and Mathur (2006) suggested that mixing pixels at two sides of ground object boundary could be highly effective in SVM even the sample size was very smaller. They considered this approach as a competitive alternative of conventional sampling strategy.\n\nSo I select three training sets based on above sampling rules (See Figure 2).\n\n{% asset_img trainsample.png This is an example image %}\n\n## Training set in feature space\n\n---\n\nWhile using the SVM, we hope that our training samples are located near the boundary of classes in the feature space. Figure 3 shows how samples in three training sets, as well as the test set, scatter at a feature space (red band vs. NIR band).\n\n{% asset_img featurespace.png This is an example image %}\n\nCloud has high reflectance in both red band and near infrared band, however, the reflectance of ground objects (most are vegetation) is low in red band and high in near infrared band. Due to the reflectance difference, samples in the feature space apparently belong to two distinct groups: cloud and ground objects. As shown in Figure 3, the distribution of samples in different training sets are totally different. Boundary sampling produced samples located near the boundary of two classes. Samples generated with stratified random sampling could better represent the overall characteristics of two classes. Clustering sampling within high confidence area would generate samples also clustering in the feature space.\n\n## Result\n\n---\n\nThe classification results are shown in Table 1 and Figure 4.\n\n{% asset_img accuracytable.png This is an example image %}\n\n{% asset_img accuracyfigure.png This is an example image %}\n\nThe results, as expected, indicate that boundary sampling is able to generate better training sample and contribute to higher classification accuracy, compared to the other two sampling strategies.\n\nALl trained classifiers are also applied to the whole study image. Classifier trained with boundary samples is very sensitive to the difference between cloud and non-cloud pixels. It will try to differentiate all mixing pixels and this could be too sensitive. Classifier trained by cluster samples only recognizes thick cloud on the image and ignores pixels with mixing spectral information. Classifier trained by stratified random samples takes a balance between them: neither too aggressive nor too conventional. For detailed discussion, please read my report (see link below).\n\n## Conclusion\n\n---\n\nLet's get back to our initial questions and their answers.\n\n* Does the sampling rule used in traditional methods also work for SVM?\n\nApparently the traditional stratified random sampling still works pretty well for the SVM classification. The classification accuracy in the experiment is about 90%, which is high enough for most situations.\n\n* How does the sampling rule affect the SVM classification result?\n\nIf we can use the portion of boundary (mixing) pixels in the training set to define sampling rule, we are able to build a link among three sampling rules used above. As we include more boundary pixels into the training set, the classifier would become more sensitive and have a better performance in identifying mixing objects. However, high sensitivity could also increase the error rate while identifying mixing objects. There is a trade-off between high sensitivity and low error rate within the selection of sampling strategies.\n\nThere is no generally appropriate sampling rule for all situations. However, depending on the need of classification, there exits an appropriate sampling rule for specific situation. Therefore, it is not difficult to understand why the stratified random sampling is still the first choice in practical use. Though classifier trained stratified random sampling is expected to have fair performance, it is less likely to be trapped into the problem of overestimation and underestimation.\n\n## Link\n\n---\n\nThis article is a simplified version of my project report. For more detail, please read my full report [A Comparison of Sampling Strategies in SVM Classification](https://www.dropbox.com/s/yadta4jnuqgml9s/svm_sampling_report.pdf?dl=0).\n\n## Reference\n\n---\n\n[1] Foody, G. M. and A. Mathur (2006). \"The use of small training sets containing mixed pixels for accurate hard image classification: Training on mixed spectral responses for classification by a SVM.\" Remote Sensing of Environment 103(2): 179-189.\n","slug":"Comparison-of-different-sampling-rules-in-SVM-classification","published":1,"updated":"2018-03-03T20:45:36.114Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgr7000j8j0vaa3tvxgf","content":"<p>The problem of sampling rule in Support Vector Machine raised in the discussion when I was in the course <em>Advanced Remote Sensing</em>.</p><p>The quality of training sample has deterministic influence to the accuracy of supervised classification methods. A properly designed sampling rule plays a substantial role in yielding an informative training sample set. The design of sampling strategy depends on both the characteristics of objects of interest and the applied classification methods.<br><a id=\"more\"></a><br>Support Vector Machine (SVM) is an increasingly popular classification method for remote sensing image both in industry and research. As for the theory and concept of SVM, there have been many introductory articles such as <a href=\"http://rvlasveld.github.io/blog/2013/07/12/introduction-to-one-class-support-vector-machines/\" target=\"_blank\" rel=\"noopener\">Roemer`s blog</a>. Because support vectors are selected from training samples for maximizing the margin between classes, quality of sample set will decide the effectiveness of the hyperplane and affect the performance of the classifier.</p><p>In brief the mechanism of SVM is very different from traditional methods like Maximum Likelihood Classification. Here comes the question: <strong>Does the sampling rule used in traditional methods also work for SVM? How does the sampling rule affect the SVM classification result?</strong></p><h2 id=\"Experiment\"><a href=\"#Experiment\" class=\"headerlink\" title=\"Experiment\"></a>Experiment</h2><hr><p>To answer this question, I would like to set up a scenario for the classification experiment. In this case, I choose to perform a cloud detection based on Landsat 8 OLI image for two reasons:</p><ul><li><p>It is a most basic binary classification.</p></li><li><p>Cloud detection could be very challenging because thin cloud is very difficult to detect in many situations.</p></li></ul><p>I use an image with both thick cloud and thin cloud in order to increase the difficulty of classification (See Figure 1). <a href=\"http://landsat.usgs.gov/band_designations_landsat_satellites.php\" target=\"_blank\" rel=\"noopener\">Band 2 to 7</a> are used and the SVM classifier in ENVI is utilized with default configuration. Four hundred pixels are randomly picked up as test sample: half of them are cloud (blue points) and the others are ground objects (yellow points).</p><h2 id=\"Sampling-Rules\"><a href=\"#Sampling-Rules\" class=\"headerlink\" title=\"Sampling Rules\"></a>Sampling Rules</h2><hr><p>I am particularly interested in three sample rules.</p><ul><li>Stratified random sampling</li></ul><p>This is a classic sample rule. Its idea is to randomly select training samples of one class from the sample pool of that class. The sample size of each class could be a fixed number or proportional to the size of sample pool of that class.</p><ul><li>Cluster sampling</li></ul><p>However, in practice random sampling is sometimes difficult to achieve, especially when the sample is selected by hand or a semi-automatic method. The sample pixels generally tend to be more clustering than random. (it is actually what we do in the ENVI class: drag a region of interest and treat it as sample set)</p><ul><li>Boundary sampling</li></ul><p>Its basic idea is that support vectors are likely also located near the geographical boundary of two classes. Although pixels located around geographic boundaries might contain spectral information of both classes to some extent, Foody and Mathur (2006) suggested that mixing pixels at two sides of ground object boundary could be highly effective in SVM even the sample size was very smaller. They considered this approach as a competitive alternative of conventional sampling strategy.</p><p>So I select three training sets based on above sampling rules (See Figure 2).</p><h2 id=\"Training-set-in-feature-space\"><a href=\"#Training-set-in-feature-space\" class=\"headerlink\" title=\"Training set in feature space\"></a>Training set in feature space</h2><hr><p>While using the SVM, we hope that our training samples are located near the boundary of classes in the feature space. Figure 3 shows how samples in three training sets, as well as the test set, scatter at a feature space (red band vs. NIR band).</p><p>Cloud has high reflectance in both red band and near infrared band, however, the reflectance of ground objects (most are vegetation) is low in red band and high in near infrared band. Due to the reflectance difference, samples in the feature space apparently belong to two distinct groups: cloud and ground objects. As shown in Figure 3, the distribution of samples in different training sets are totally different. Boundary sampling produced samples located near the boundary of two classes. Samples generated with stratified random sampling could better represent the overall characteristics of two classes. Clustering sampling within high confidence area would generate samples also clustering in the feature space.</p><h2 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h2><hr><p>The classification results are shown in Table 1 and Figure 4.</p><p>The results, as expected, indicate that boundary sampling is able to generate better training sample and contribute to higher classification accuracy, compared to the other two sampling strategies.</p><p>ALl trained classifiers are also applied to the whole study image. Classifier trained with boundary samples is very sensitive to the difference between cloud and non-cloud pixels. It will try to differentiate all mixing pixels and this could be too sensitive. Classifier trained by cluster samples only recognizes thick cloud on the image and ignores pixels with mixing spectral information. Classifier trained by stratified random samples takes a balance between them: neither too aggressive nor too conventional. For detailed discussion, please read my report (see link below).</p><h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><hr><p>Let’s get back to our initial questions and their answers.</p><ul><li>Does the sampling rule used in traditional methods also work for SVM?</li></ul><p>Apparently the traditional stratified random sampling still works pretty well for the SVM classification. The classification accuracy in the experiment is about 90%, which is high enough for most situations.</p><ul><li>How does the sampling rule affect the SVM classification result?</li></ul><p>If we can use the portion of boundary (mixing) pixels in the training set to define sampling rule, we are able to build a link among three sampling rules used above. As we include more boundary pixels into the training set, the classifier would become more sensitive and have a better performance in identifying mixing objects. However, high sensitivity could also increase the error rate while identifying mixing objects. There is a trade-off between high sensitivity and low error rate within the selection of sampling strategies.</p><p>There is no generally appropriate sampling rule for all situations. However, depending on the need of classification, there exits an appropriate sampling rule for specific situation. Therefore, it is not difficult to understand why the stratified random sampling is still the first choice in practical use. Though classifier trained stratified random sampling is expected to have fair performance, it is less likely to be trapped into the problem of overestimation and underestimation.</p><h2 id=\"Link\"><a href=\"#Link\" class=\"headerlink\" title=\"Link\"></a>Link</h2><hr><p>This article is a simplified version of my project report. For more detail, please read my full report <a href=\"https://www.dropbox.com/s/yadta4jnuqgml9s/svm_sampling_report.pdf?dl=0\" target=\"_blank\" rel=\"noopener\">A Comparison of Sampling Strategies in SVM Classification</a>.</p><h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><hr><p>[1] Foody, G. M. and A. Mathur (2006). “The use of small training sets containing mixed pixels for accurate hard image classification: Training on mixed spectral responses for classification by a SVM.” Remote Sensing of Environment 103(2): 179-189.</p>","site":{"data":{}},"excerpt":"<p>The problem of sampling rule in Support Vector Machine raised in the discussion when I was in the course <em>Advanced Remote Sensing</em>.</p><p>The quality of training sample has deterministic influence to the accuracy of supervised classification methods. A properly designed sampling rule plays a substantial role in yielding an informative training sample set. The design of sampling strategy depends on both the characteristics of objects of interest and the applied classification methods.<br>","more":"<br>Support Vector Machine (SVM) is an increasingly popular classification method for remote sensing image both in industry and research. As for the theory and concept of SVM, there have been many introductory articles such as <a href=\"http://rvlasveld.github.io/blog/2013/07/12/introduction-to-one-class-support-vector-machines/\" target=\"_blank\" rel=\"noopener\">Roemer`s blog</a>. Because support vectors are selected from training samples for maximizing the margin between classes, quality of sample set will decide the effectiveness of the hyperplane and affect the performance of the classifier.</p><p>In brief the mechanism of SVM is very different from traditional methods like Maximum Likelihood Classification. Here comes the question: <strong>Does the sampling rule used in traditional methods also work for SVM? How does the sampling rule affect the SVM classification result?</strong></p><h2 id=\"Experiment\"><a href=\"#Experiment\" class=\"headerlink\" title=\"Experiment\"></a>Experiment</h2><hr><p>To answer this question, I would like to set up a scenario for the classification experiment. In this case, I choose to perform a cloud detection based on Landsat 8 OLI image for two reasons:</p><ul><li><p>It is a most basic binary classification.</p></li><li><p>Cloud detection could be very challenging because thin cloud is very difficult to detect in many situations.</p></li></ul><p>I use an image with both thick cloud and thin cloud in order to increase the difficulty of classification (See Figure 1). <a href=\"http://landsat.usgs.gov/band_designations_landsat_satellites.php\" target=\"_blank\" rel=\"noopener\">Band 2 to 7</a> are used and the SVM classifier in ENVI is utilized with default configuration. Four hundred pixels are randomly picked up as test sample: half of them are cloud (blue points) and the others are ground objects (yellow points).</p><h2 id=\"Sampling-Rules\"><a href=\"#Sampling-Rules\" class=\"headerlink\" title=\"Sampling Rules\"></a>Sampling Rules</h2><hr><p>I am particularly interested in three sample rules.</p><ul><li>Stratified random sampling</li></ul><p>This is a classic sample rule. Its idea is to randomly select training samples of one class from the sample pool of that class. The sample size of each class could be a fixed number or proportional to the size of sample pool of that class.</p><ul><li>Cluster sampling</li></ul><p>However, in practice random sampling is sometimes difficult to achieve, especially when the sample is selected by hand or a semi-automatic method. The sample pixels generally tend to be more clustering than random. (it is actually what we do in the ENVI class: drag a region of interest and treat it as sample set)</p><ul><li>Boundary sampling</li></ul><p>Its basic idea is that support vectors are likely also located near the geographical boundary of two classes. Although pixels located around geographic boundaries might contain spectral information of both classes to some extent, Foody and Mathur (2006) suggested that mixing pixels at two sides of ground object boundary could be highly effective in SVM even the sample size was very smaller. They considered this approach as a competitive alternative of conventional sampling strategy.</p><p>So I select three training sets based on above sampling rules (See Figure 2).</p><h2 id=\"Training-set-in-feature-space\"><a href=\"#Training-set-in-feature-space\" class=\"headerlink\" title=\"Training set in feature space\"></a>Training set in feature space</h2><hr><p>While using the SVM, we hope that our training samples are located near the boundary of classes in the feature space. Figure 3 shows how samples in three training sets, as well as the test set, scatter at a feature space (red band vs. NIR band).</p><p>Cloud has high reflectance in both red band and near infrared band, however, the reflectance of ground objects (most are vegetation) is low in red band and high in near infrared band. Due to the reflectance difference, samples in the feature space apparently belong to two distinct groups: cloud and ground objects. As shown in Figure 3, the distribution of samples in different training sets are totally different. Boundary sampling produced samples located near the boundary of two classes. Samples generated with stratified random sampling could better represent the overall characteristics of two classes. Clustering sampling within high confidence area would generate samples also clustering in the feature space.</p><h2 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h2><hr><p>The classification results are shown in Table 1 and Figure 4.</p><p>The results, as expected, indicate that boundary sampling is able to generate better training sample and contribute to higher classification accuracy, compared to the other two sampling strategies.</p><p>ALl trained classifiers are also applied to the whole study image. Classifier trained with boundary samples is very sensitive to the difference between cloud and non-cloud pixels. It will try to differentiate all mixing pixels and this could be too sensitive. Classifier trained by cluster samples only recognizes thick cloud on the image and ignores pixels with mixing spectral information. Classifier trained by stratified random samples takes a balance between them: neither too aggressive nor too conventional. For detailed discussion, please read my report (see link below).</p><h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><hr><p>Let’s get back to our initial questions and their answers.</p><ul><li>Does the sampling rule used in traditional methods also work for SVM?</li></ul><p>Apparently the traditional stratified random sampling still works pretty well for the SVM classification. The classification accuracy in the experiment is about 90%, which is high enough for most situations.</p><ul><li>How does the sampling rule affect the SVM classification result?</li></ul><p>If we can use the portion of boundary (mixing) pixels in the training set to define sampling rule, we are able to build a link among three sampling rules used above. As we include more boundary pixels into the training set, the classifier would become more sensitive and have a better performance in identifying mixing objects. However, high sensitivity could also increase the error rate while identifying mixing objects. There is a trade-off between high sensitivity and low error rate within the selection of sampling strategies.</p><p>There is no generally appropriate sampling rule for all situations. However, depending on the need of classification, there exits an appropriate sampling rule for specific situation. Therefore, it is not difficult to understand why the stratified random sampling is still the first choice in practical use. Though classifier trained stratified random sampling is expected to have fair performance, it is less likely to be trapped into the problem of overestimation and underestimation.</p><h2 id=\"Link\"><a href=\"#Link\" class=\"headerlink\" title=\"Link\"></a>Link</h2><hr><p>This article is a simplified version of my project report. For more detail, please read my full report <a href=\"https://www.dropbox.com/s/yadta4jnuqgml9s/svm_sampling_report.pdf?dl=0\" target=\"_blank\" rel=\"noopener\">A Comparison of Sampling Strategies in SVM Classification</a>.</p><h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><hr><p>[1] Foody, G. M. and A. Mathur (2006). “The use of small training sets containing mixed pixels for accurate hard image classification: Training on mixed spectral responses for classification by a SVM.” Remote Sensing of Environment 103(2): 179-189.</p>"},{"title":"Converting C# Data Value to ArcObject Raster Pixel Value","date":"2015-03-22T01:30:54.000Z","comments":1,"_content":"\nThe length of remote sensing pixel value is constrained by a predefined pixel value type. It is an unchangeable property for each remote sensing image and saving an unsupported value to a image may cause unpredictable errors like application crash or information loss resulted from implicit data type conversion.\n<!-- more -->\nIf you are developing application based on ArcObject, you could know the pixel type of a raster layer simply with following code.\n\n``` csharp\nIRasterLayer rasterLayer = (IRasterLayer)layer;\nIRasterProps rasterProps = (IRasterProps)rasterLayer.Raster;\n\n// Get the pixel type of you raster layer\nrstPixelType pixelType = rasterProps.PixelType;\n```\n\nYou can find a full list and detailed explanation of ArcObject raster pixel types in [this page](http://resources.esri.com/help/9.3/arcgisengine/java/api/arcobjects/com/esri/arcgis/geodatabase/rstPixelType.html).\n\nNot every raster pixel types has a corresponding C# value type. So I make a list for those pixels types having relative in C# so that we can make correct conversion while developing.\n\nArcMap Pixel Type  | Description                     | Corresponding C# Data Type  | Supported\n------------------ | ------------------------------- | --------------------------- |-----------\nPT_UNKNOWN         | unknown                         |                             | No\nPT_U1              | 1 bit                           |                             | No\nPT_U2              | 2 bit                           |                             | No\nPT_U4              | 4 bit                           |                             | No\nPT_UCHAR           | unsigned 8 bit integer          | Byte                        | Yes\nPT_CHAR            | 8 bit integer                   | SByte                       | Yes\nPT_USHORT          | unsigned 16 bit integer         | UInt16                      | Yes\nPT_SHORT           | 16 bit integer                  | Int16                       | Yes\nPT_ULONG           | unsigned 32 bit integer         | UInt32                      | Yes\nPT_LONG            | 32 bit integer                  | Int32                       | Yes\nPT_FLOAT           | single precision floating point | Single                      | Yes\nPT_DOUBLE          | double precision floating point | Double                      | Yes\nPT_COMPLEX         | single precision complex        |                             | No\nPT_DCOMPLEX        | double precision complex        |                             | No\nPT_CSHORT          | short integer complex           |                             | No\nPT_CLONG           | long integer complex            |                             | No\n\n\nBased on this table, I write a function to wrap the conversion from C# data type to valid ArcObject pixel value type. I use it in my project [ArcMap Raster Edit Suite](https://github.com/haoliangyu/ares) and it work pretty well.\n\n```csharp\n/// <summary>\n/// Convert the csharp value to the ArcObject pixel value.\n/// </summary>\n/// <param name=\"csharpValue\">Cshapr value</param>\n/// <param name=\"pixelValueType\">The pixel type of ouput value</param>\n/// <param name=\"pixelValue\">Output pixel value</param>\n/// <returns>A value indicating whether the convention is successful</returns>\npublic static bool CSharpValue2PixelValue(object csharpValue, rstPixelType pixelValueType, out object pixelValue)\n{\n    try\n    {\n        switch (pixelValueType)\n        {\n            case rstPixelType.PT_UCHAR:\n                pixelValue = (object)Convert.ToByte(csharpValue);\n                return true;\n            case rstPixelType.PT_CHAR:\n                pixelValue = (object)Convert.ToSByte(csharpValue);\n                return true;\n            case rstPixelType.PT_SHORT:\n                pixelValue = (object)Convert.ToInt16(csharpValue);\n                return true;\n            case rstPixelType.PT_USHORT:\n                pixelValue = (object)Convert.ToUInt16(csharpValue);\n                return true;\n            case rstPixelType.PT_CLONG:\n                pixelValue = (object)Convert.ToInt32(csharpValue);\n                return true;\n            case rstPixelType.PT_ULONG:\n                pixelValue = (object)Convert.ToUInt32(csharpValue);\n                return true;\n            case rstPixelType.PT_FLOAT:\n                pixelValue = (object)Convert.ToSingle(csharpValue);\n                return true;\n            case rstPixelType.PT_DOUBLE:\n                pixelValue = (object)Convert.ToDouble(csharpValue);\n                return true;\n            default:\n                pixelValue = null;\n                return false;\n        }\n    }\n    catch (Exception)\n    {\n        pixelValue = null;\n        return false;\n    }\n}\n```\n","source":"_posts/Converting-C-Data-Value-to-ArcObject-Raster-Pixel-Value.md","raw":"title: Converting C# Data Value to ArcObject Raster Pixel Value\ndate: 2015-03-21 21:30:54\ncomments: true\ncategories:\n- GIS\ntags:\n- arcobject\n- C#\n---\n\nThe length of remote sensing pixel value is constrained by a predefined pixel value type. It is an unchangeable property for each remote sensing image and saving an unsupported value to a image may cause unpredictable errors like application crash or information loss resulted from implicit data type conversion.\n<!-- more -->\nIf you are developing application based on ArcObject, you could know the pixel type of a raster layer simply with following code.\n\n``` csharp\nIRasterLayer rasterLayer = (IRasterLayer)layer;\nIRasterProps rasterProps = (IRasterProps)rasterLayer.Raster;\n\n// Get the pixel type of you raster layer\nrstPixelType pixelType = rasterProps.PixelType;\n```\n\nYou can find a full list and detailed explanation of ArcObject raster pixel types in [this page](http://resources.esri.com/help/9.3/arcgisengine/java/api/arcobjects/com/esri/arcgis/geodatabase/rstPixelType.html).\n\nNot every raster pixel types has a corresponding C# value type. So I make a list for those pixels types having relative in C# so that we can make correct conversion while developing.\n\nArcMap Pixel Type  | Description                     | Corresponding C# Data Type  | Supported\n------------------ | ------------------------------- | --------------------------- |-----------\nPT_UNKNOWN         | unknown                         |                             | No\nPT_U1              | 1 bit                           |                             | No\nPT_U2              | 2 bit                           |                             | No\nPT_U4              | 4 bit                           |                             | No\nPT_UCHAR           | unsigned 8 bit integer          | Byte                        | Yes\nPT_CHAR            | 8 bit integer                   | SByte                       | Yes\nPT_USHORT          | unsigned 16 bit integer         | UInt16                      | Yes\nPT_SHORT           | 16 bit integer                  | Int16                       | Yes\nPT_ULONG           | unsigned 32 bit integer         | UInt32                      | Yes\nPT_LONG            | 32 bit integer                  | Int32                       | Yes\nPT_FLOAT           | single precision floating point | Single                      | Yes\nPT_DOUBLE          | double precision floating point | Double                      | Yes\nPT_COMPLEX         | single precision complex        |                             | No\nPT_DCOMPLEX        | double precision complex        |                             | No\nPT_CSHORT          | short integer complex           |                             | No\nPT_CLONG           | long integer complex            |                             | No\n\n\nBased on this table, I write a function to wrap the conversion from C# data type to valid ArcObject pixel value type. I use it in my project [ArcMap Raster Edit Suite](https://github.com/haoliangyu/ares) and it work pretty well.\n\n```csharp\n/// <summary>\n/// Convert the csharp value to the ArcObject pixel value.\n/// </summary>\n/// <param name=\"csharpValue\">Cshapr value</param>\n/// <param name=\"pixelValueType\">The pixel type of ouput value</param>\n/// <param name=\"pixelValue\">Output pixel value</param>\n/// <returns>A value indicating whether the convention is successful</returns>\npublic static bool CSharpValue2PixelValue(object csharpValue, rstPixelType pixelValueType, out object pixelValue)\n{\n    try\n    {\n        switch (pixelValueType)\n        {\n            case rstPixelType.PT_UCHAR:\n                pixelValue = (object)Convert.ToByte(csharpValue);\n                return true;\n            case rstPixelType.PT_CHAR:\n                pixelValue = (object)Convert.ToSByte(csharpValue);\n                return true;\n            case rstPixelType.PT_SHORT:\n                pixelValue = (object)Convert.ToInt16(csharpValue);\n                return true;\n            case rstPixelType.PT_USHORT:\n                pixelValue = (object)Convert.ToUInt16(csharpValue);\n                return true;\n            case rstPixelType.PT_CLONG:\n                pixelValue = (object)Convert.ToInt32(csharpValue);\n                return true;\n            case rstPixelType.PT_ULONG:\n                pixelValue = (object)Convert.ToUInt32(csharpValue);\n                return true;\n            case rstPixelType.PT_FLOAT:\n                pixelValue = (object)Convert.ToSingle(csharpValue);\n                return true;\n            case rstPixelType.PT_DOUBLE:\n                pixelValue = (object)Convert.ToDouble(csharpValue);\n                return true;\n            default:\n                pixelValue = null;\n                return false;\n        }\n    }\n    catch (Exception)\n    {\n        pixelValue = null;\n        return false;\n    }\n}\n```\n","slug":"Converting-C-Data-Value-to-ArcObject-Raster-Pixel-Value","published":1,"updated":"2018-03-03T20:45:36.114Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgr9000n8j0vg422qhhk","content":"<p>The length of remote sensing pixel value is constrained by a predefined pixel value type. It is an unchangeable property for each remote sensing image and saving an unsupported value to a image may cause unpredictable errors like application crash or information loss resulted from implicit data type conversion.<br><a id=\"more\"></a><br>If you are developing application based on ArcObject, you could know the pixel type of a raster layer simply with following code.</p><figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">IRasterLayer rasterLayer = (IRasterLayer)layer;</span><br><span class=\"line\">IRasterProps rasterProps = (IRasterProps)rasterLayer.Raster;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Get the pixel type of you raster layer</span></span><br><span class=\"line\">rstPixelType pixelType = rasterProps.PixelType;</span><br></pre></td></tr></table></figure><p>You can find a full list and detailed explanation of ArcObject raster pixel types in <a href=\"http://resources.esri.com/help/9.3/arcgisengine/java/api/arcobjects/com/esri/arcgis/geodatabase/rstPixelType.html\" target=\"_blank\" rel=\"noopener\">this page</a>.</p><p>Not every raster pixel types has a corresponding C# value type. So I make a list for those pixels types having relative in C# so that we can make correct conversion while developing.</p><table><thead><tr><th>ArcMap Pixel Type</th><th>Description</th><th>Corresponding C# Data Type</th><th>Supported</th></tr></thead><tbody><tr><td>PT_UNKNOWN</td><td>unknown</td><td></td><td>No</td></tr><tr><td>PT_U1</td><td>1 bit</td><td></td><td>No</td></tr><tr><td>PT_U2</td><td>2 bit</td><td></td><td>No</td></tr><tr><td>PT_U4</td><td>4 bit</td><td></td><td>No</td></tr><tr><td>PT_UCHAR</td><td>unsigned 8 bit integer</td><td>Byte</td><td>Yes</td></tr><tr><td>PT_CHAR</td><td>8 bit integer</td><td>SByte</td><td>Yes</td></tr><tr><td>PT_USHORT</td><td>unsigned 16 bit integer</td><td>UInt16</td><td>Yes</td></tr><tr><td>PT_SHORT</td><td>16 bit integer</td><td>Int16</td><td>Yes</td></tr><tr><td>PT_ULONG</td><td>unsigned 32 bit integer</td><td>UInt32</td><td>Yes</td></tr><tr><td>PT_LONG</td><td>32 bit integer</td><td>Int32</td><td>Yes</td></tr><tr><td>PT_FLOAT</td><td>single precision floating point</td><td>Single</td><td>Yes</td></tr><tr><td>PT_DOUBLE</td><td>double precision floating point</td><td>Double</td><td>Yes</td></tr><tr><td>PT_COMPLEX</td><td>single precision complex</td><td></td><td>No</td></tr><tr><td>PT_DCOMPLEX</td><td>double precision complex</td><td></td><td>No</td></tr><tr><td>PT_CSHORT</td><td>short integer complex</td><td></td><td>No</td></tr><tr><td>PT_CLONG</td><td>long integer complex</td><td></td><td>No</td></tr></tbody></table><p>Based on this table, I write a function to wrap the conversion from C# data type to valid ArcObject pixel value type. I use it in my project <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">ArcMap Raster Edit Suite</a> and it work pretty well.</p><figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;summary&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> Convert the csharp value to the ArcObject pixel value.</span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;/summary&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;param name=\"csharpValue\"&gt;</span>Cshapr value<span class=\"doctag\">&lt;/param&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;param name=\"pixelValueType\"&gt;</span>The pixel type of ouput value<span class=\"doctag\">&lt;/param&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;param name=\"pixelValue\"&gt;</span>Output pixel value<span class=\"doctag\">&lt;/param&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;returns&gt;</span>A value indicating whether the convention is successful<span class=\"doctag\">&lt;/returns&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">bool</span> <span class=\"title\">CSharpValue2PixelValue</span>(<span class=\"params\"><span class=\"keyword\">object</span> csharpValue, rstPixelType pixelValueType, <span class=\"keyword\">out</span> <span class=\"keyword\">object</span> pixelValue</span>)</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">switch</span> (pixelValueType)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_UCHAR:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToByte(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_CHAR:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToSByte(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_SHORT:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToInt16(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_USHORT:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToUInt16(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_CLONG:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToInt32(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_ULONG:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToUInt32(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_FLOAT:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToSingle(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_DOUBLE:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToDouble(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">default</span>:</span><br><span class=\"line\">                pixelValue = <span class=\"literal\">null</span>;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (Exception)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        pixelValue = <span class=\"literal\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>The length of remote sensing pixel value is constrained by a predefined pixel value type. It is an unchangeable property for each remote sensing image and saving an unsupported value to a image may cause unpredictable errors like application crash or information loss resulted from implicit data type conversion.<br>","more":"<br>If you are developing application based on ArcObject, you could know the pixel type of a raster layer simply with following code.</p><figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">IRasterLayer rasterLayer = (IRasterLayer)layer;</span><br><span class=\"line\">IRasterProps rasterProps = (IRasterProps)rasterLayer.Raster;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Get the pixel type of you raster layer</span></span><br><span class=\"line\">rstPixelType pixelType = rasterProps.PixelType;</span><br></pre></td></tr></table></figure><p>You can find a full list and detailed explanation of ArcObject raster pixel types in <a href=\"http://resources.esri.com/help/9.3/arcgisengine/java/api/arcobjects/com/esri/arcgis/geodatabase/rstPixelType.html\" target=\"_blank\" rel=\"noopener\">this page</a>.</p><p>Not every raster pixel types has a corresponding C# value type. So I make a list for those pixels types having relative in C# so that we can make correct conversion while developing.</p><table><thead><tr><th>ArcMap Pixel Type</th><th>Description</th><th>Corresponding C# Data Type</th><th>Supported</th></tr></thead><tbody><tr><td>PT_UNKNOWN</td><td>unknown</td><td></td><td>No</td></tr><tr><td>PT_U1</td><td>1 bit</td><td></td><td>No</td></tr><tr><td>PT_U2</td><td>2 bit</td><td></td><td>No</td></tr><tr><td>PT_U4</td><td>4 bit</td><td></td><td>No</td></tr><tr><td>PT_UCHAR</td><td>unsigned 8 bit integer</td><td>Byte</td><td>Yes</td></tr><tr><td>PT_CHAR</td><td>8 bit integer</td><td>SByte</td><td>Yes</td></tr><tr><td>PT_USHORT</td><td>unsigned 16 bit integer</td><td>UInt16</td><td>Yes</td></tr><tr><td>PT_SHORT</td><td>16 bit integer</td><td>Int16</td><td>Yes</td></tr><tr><td>PT_ULONG</td><td>unsigned 32 bit integer</td><td>UInt32</td><td>Yes</td></tr><tr><td>PT_LONG</td><td>32 bit integer</td><td>Int32</td><td>Yes</td></tr><tr><td>PT_FLOAT</td><td>single precision floating point</td><td>Single</td><td>Yes</td></tr><tr><td>PT_DOUBLE</td><td>double precision floating point</td><td>Double</td><td>Yes</td></tr><tr><td>PT_COMPLEX</td><td>single precision complex</td><td></td><td>No</td></tr><tr><td>PT_DCOMPLEX</td><td>double precision complex</td><td></td><td>No</td></tr><tr><td>PT_CSHORT</td><td>short integer complex</td><td></td><td>No</td></tr><tr><td>PT_CLONG</td><td>long integer complex</td><td></td><td>No</td></tr></tbody></table><p>Based on this table, I write a function to wrap the conversion from C# data type to valid ArcObject pixel value type. I use it in my project <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">ArcMap Raster Edit Suite</a> and it work pretty well.</p><figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;summary&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> Convert the csharp value to the ArcObject pixel value.</span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;/summary&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;param name=\"csharpValue\"&gt;</span>Cshapr value<span class=\"doctag\">&lt;/param&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;param name=\"pixelValueType\"&gt;</span>The pixel type of ouput value<span class=\"doctag\">&lt;/param&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;param name=\"pixelValue\"&gt;</span>Output pixel value<span class=\"doctag\">&lt;/param&gt;</span></span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">///</span> <span class=\"doctag\">&lt;returns&gt;</span>A value indicating whether the convention is successful<span class=\"doctag\">&lt;/returns&gt;</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">bool</span> <span class=\"title\">CSharpValue2PixelValue</span>(<span class=\"params\"><span class=\"keyword\">object</span> csharpValue, rstPixelType pixelValueType, <span class=\"keyword\">out</span> <span class=\"keyword\">object</span> pixelValue</span>)</span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">switch</span> (pixelValueType)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_UCHAR:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToByte(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_CHAR:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToSByte(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_SHORT:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToInt16(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_USHORT:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToUInt16(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_CLONG:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToInt32(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_ULONG:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToUInt32(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_FLOAT:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToSingle(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> rstPixelType.PT_DOUBLE:</span><br><span class=\"line\">                pixelValue = (<span class=\"keyword\">object</span>)Convert.ToDouble(csharpValue);</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">default</span>:</span><br><span class=\"line\">                pixelValue = <span class=\"literal\">null</span>;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (Exception)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        pixelValue = <span class=\"literal\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Editing single pixels of raster layer in ArcMap with just a few clicks","date":"2015-02-18T02:42:56.000Z","comments":1,"_content":"\nEditing single pixels of a raster layer is a common task in daily GIS and RS practice. For example\n\n* Removing misclassified pixels from a land cover classification result\n\n* Creating a set of multiple raster layers with minor difference for model simulation\n\n* etc.\n\nIn ArcMap we use Raster Calculator and Reclassification tool as many instructions suggest. However, these tools are designed to edit the layer as a whole and they are not flexible enough for minor modification. If ArcMap allows us to edit single features of a vector layer, why we cannot edit single pixels of a raster layer in ArcMap? That is the reason why the project ArcMap Raster Edit Suite (ARES) starts. It aims at providing an ArcMAp Add-In with tools to allows single raster pixels editing, just like what we can do with the vector layer. Flexible, quick and neat!\n<!-- more -->\n## Download and Install\n\n---\n\nThis project is hosted and published at [GitHub](https://github.com/haoliangyu/ares). You can download the installation file at [Here](https://github.com/haoliangyu/ares/releases/download/0.1.3/AREA.0.1.3.zip)\n\nAfter the download finishes, you need to choose the installation file that matches the ArcMap on your computer because this Add-In support ArcMap 10.0/10.1/10.2. There are two files in the folder and **ARES.esriAddin** is what you need:\n\n{% asset_img unzipped_folder.png This is an example image %}\n\nDouble click and you could see the installation wizard.\n\n{% asset_img install_wizard.png This is an example image %}\n\nJust click **Install Add-In** and then you get it.\n\n## Raster Editor Toolbar\n\n----\n\nNow you have a new toolbar **Raster Editor** installed in your ArcMap.\n\n{% asset_img eidtor_toolbar.png This is an example image %}\n\nThis toolbar includes following tools:\n\n\n* {% asset_img edit_tool.png This is an example image %}: **Select & Edit**, which is used to select pixels for editing.\n\n* {% asset_img identify_tool.png This is an example image %}: **Identify**, which is used to select pixels in order to get their values, row/column indexes and zonal statistics.\n\n* {% asset_img gotopixel_tool.png This is an example image %}: **Go To Pixel**, which is used to locate pixel with given row and column index.\n\nThe purpose of this toolbar is to provide tools for precise modification with known row and column index.\n\n## Step by Step: Editing Raster Layer\n\n---\n\nIn this section, I am going to show a brief guide on how to edit single pixels of raster layer in ArcMap.\n\n* First of all, we have the layer imported in ArcMap.\n\n* Then start the editing section at the ***Start Editor*** menu by clicking ***Start Editing*** button. You can only edit one raster layer at one time. If there are more than one raster layers in ArcMap, there will be a prompt-up window to let you choose one.\n\n* Click the ***Select & Edit*** button to activate the tool.\n\n* Click or drag a region of interest on the layer to selected pixels. All selected pixels will be highlighted on the map with a blue frame. **Noted that selecting too much pixels may lead to crash of ArcMap**.\n\n{% asset_img select_pixels.png This is an example image %}\n\n* Edit values of selected pixel at the **Raster Edit** Window. All edits will be highlighted on the map with a yellow symbol.\n\n{% asset_img edit_pixels.png This is an example image %}\n\nMake sure your input value is compatible with the pixel type of the raster layer. Any pixel left blank will be considered as NoData Pixel.\n\n* Save edits to the raster file using ***Save Edits*** button on the ***Raster Editor*** menu. If you want to save edits to a new file, click the ***Save Edits As*** button. You will see the change of layer right after refreshing the ArcMap.\n\n{% asset_img finish_editing.png This is an example image %}\n\n* Stop the editing section by clicking ***Stop Editing*** button.\n\nNow you finish the editing section and get the desired result.\n\n## Why there is only one toolbar in the suite?\n\n---\n\nWell, we are working on anther toolbar so that we can make it a real tool suite. Please have a visit on our [project page](https://github.com/haoliangyu/ares) later.\n\nIf you like this project, give it a star :)\n","source":"_posts/Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks.md","raw":"title: Editing single pixels of raster layer in ArcMap with just a few clicks\ndate: 2015-02-17 21:42:56\ncomments: true\ncategories:\n- GIS\ntags:\n- gis\n- arcgis\n---\n\nEditing single pixels of a raster layer is a common task in daily GIS and RS practice. For example\n\n* Removing misclassified pixels from a land cover classification result\n\n* Creating a set of multiple raster layers with minor difference for model simulation\n\n* etc.\n\nIn ArcMap we use Raster Calculator and Reclassification tool as many instructions suggest. However, these tools are designed to edit the layer as a whole and they are not flexible enough for minor modification. If ArcMap allows us to edit single features of a vector layer, why we cannot edit single pixels of a raster layer in ArcMap? That is the reason why the project ArcMap Raster Edit Suite (ARES) starts. It aims at providing an ArcMAp Add-In with tools to allows single raster pixels editing, just like what we can do with the vector layer. Flexible, quick and neat!\n<!-- more -->\n## Download and Install\n\n---\n\nThis project is hosted and published at [GitHub](https://github.com/haoliangyu/ares). You can download the installation file at [Here](https://github.com/haoliangyu/ares/releases/download/0.1.3/AREA.0.1.3.zip)\n\nAfter the download finishes, you need to choose the installation file that matches the ArcMap on your computer because this Add-In support ArcMap 10.0/10.1/10.2. There are two files in the folder and **ARES.esriAddin** is what you need:\n\n{% asset_img unzipped_folder.png This is an example image %}\n\nDouble click and you could see the installation wizard.\n\n{% asset_img install_wizard.png This is an example image %}\n\nJust click **Install Add-In** and then you get it.\n\n## Raster Editor Toolbar\n\n----\n\nNow you have a new toolbar **Raster Editor** installed in your ArcMap.\n\n{% asset_img eidtor_toolbar.png This is an example image %}\n\nThis toolbar includes following tools:\n\n\n* {% asset_img edit_tool.png This is an example image %}: **Select & Edit**, which is used to select pixels for editing.\n\n* {% asset_img identify_tool.png This is an example image %}: **Identify**, which is used to select pixels in order to get their values, row/column indexes and zonal statistics.\n\n* {% asset_img gotopixel_tool.png This is an example image %}: **Go To Pixel**, which is used to locate pixel with given row and column index.\n\nThe purpose of this toolbar is to provide tools for precise modification with known row and column index.\n\n## Step by Step: Editing Raster Layer\n\n---\n\nIn this section, I am going to show a brief guide on how to edit single pixels of raster layer in ArcMap.\n\n* First of all, we have the layer imported in ArcMap.\n\n* Then start the editing section at the ***Start Editor*** menu by clicking ***Start Editing*** button. You can only edit one raster layer at one time. If there are more than one raster layers in ArcMap, there will be a prompt-up window to let you choose one.\n\n* Click the ***Select & Edit*** button to activate the tool.\n\n* Click or drag a region of interest on the layer to selected pixels. All selected pixels will be highlighted on the map with a blue frame. **Noted that selecting too much pixels may lead to crash of ArcMap**.\n\n{% asset_img select_pixels.png This is an example image %}\n\n* Edit values of selected pixel at the **Raster Edit** Window. All edits will be highlighted on the map with a yellow symbol.\n\n{% asset_img edit_pixels.png This is an example image %}\n\nMake sure your input value is compatible with the pixel type of the raster layer. Any pixel left blank will be considered as NoData Pixel.\n\n* Save edits to the raster file using ***Save Edits*** button on the ***Raster Editor*** menu. If you want to save edits to a new file, click the ***Save Edits As*** button. You will see the change of layer right after refreshing the ArcMap.\n\n{% asset_img finish_editing.png This is an example image %}\n\n* Stop the editing section by clicking ***Stop Editing*** button.\n\nNow you finish the editing section and get the desired result.\n\n## Why there is only one toolbar in the suite?\n\n---\n\nWell, we are working on anther toolbar so that we can make it a real tool suite. Please have a visit on our [project page](https://github.com/haoliangyu/ares) later.\n\nIf you like this project, give it a star :)\n","slug":"Editing-single-pixels-of-raster-layer-in-ArcMap-with-just-a-few-clicks","published":1,"updated":"2018-03-03T20:45:36.114Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgrb000p8j0v71ta8wda","content":"<p>Editing single pixels of a raster layer is a common task in daily GIS and RS practice. For example</p><ul><li><p>Removing misclassified pixels from a land cover classification result</p></li><li><p>Creating a set of multiple raster layers with minor difference for model simulation</p></li><li><p>etc.</p></li></ul><p>In ArcMap we use Raster Calculator and Reclassification tool as many instructions suggest. However, these tools are designed to edit the layer as a whole and they are not flexible enough for minor modification. If ArcMap allows us to edit single features of a vector layer, why we cannot edit single pixels of a raster layer in ArcMap? That is the reason why the project ArcMap Raster Edit Suite (ARES) starts. It aims at providing an ArcMAp Add-In with tools to allows single raster pixels editing, just like what we can do with the vector layer. Flexible, quick and neat!<br><a id=\"more\"></a></p><h2 id=\"Download-and-Install\"><a href=\"#Download-and-Install\" class=\"headerlink\" title=\"Download and Install\"></a>Download and Install</h2><hr><p>This project is hosted and published at <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">GitHub</a>. You can download the installation file at <a href=\"https://github.com/haoliangyu/ares/releases/download/0.1.3/AREA.0.1.3.zip\" target=\"_blank\" rel=\"noopener\">Here</a></p><p>After the download finishes, you need to choose the installation file that matches the ArcMap on your computer because this Add-In support ArcMap 10.0/10.1/10.2. There are two files in the folder and <strong>ARES.esriAddin</strong> is what you need:</p><p>Double click and you could see the installation wizard.</p><p>Just click <strong>Install Add-In</strong> and then you get it.</p><h2 id=\"Raster-Editor-Toolbar\"><a href=\"#Raster-Editor-Toolbar\" class=\"headerlink\" title=\"Raster Editor Toolbar\"></a>Raster Editor Toolbar</h2><hr><p>Now you have a new toolbar <strong>Raster Editor</strong> installed in your ArcMap.</p><p>This toolbar includes following tools:</p><ul><li><p>: <strong>Select &amp; Edit</strong>, which is used to select pixels for editing.</p></li><li><p>: <strong>Identify</strong>, which is used to select pixels in order to get their values, row/column indexes and zonal statistics.</p></li><li><p>: <strong>Go To Pixel</strong>, which is used to locate pixel with given row and column index.</p></li></ul><p>The purpose of this toolbar is to provide tools for precise modification with known row and column index.</p><h2 id=\"Step-by-Step-Editing-Raster-Layer\"><a href=\"#Step-by-Step-Editing-Raster-Layer\" class=\"headerlink\" title=\"Step by Step: Editing Raster Layer\"></a>Step by Step: Editing Raster Layer</h2><hr><p>In this section, I am going to show a brief guide on how to edit single pixels of raster layer in ArcMap.</p><ul><li><p>First of all, we have the layer imported in ArcMap.</p></li><li><p>Then start the editing section at the <strong><em>Start Editor</em></strong> menu by clicking <strong><em>Start Editing</em></strong> button. You can only edit one raster layer at one time. If there are more than one raster layers in ArcMap, there will be a prompt-up window to let you choose one.</p></li><li><p>Click the <strong><em>Select &amp; Edit</em></strong> button to activate the tool.</p></li><li><p>Click or drag a region of interest on the layer to selected pixels. All selected pixels will be highlighted on the map with a blue frame. <strong>Noted that selecting too much pixels may lead to crash of ArcMap</strong>.</p></li></ul><ul><li>Edit values of selected pixel at the <strong>Raster Edit</strong> Window. All edits will be highlighted on the map with a yellow symbol.</li></ul><p>Make sure your input value is compatible with the pixel type of the raster layer. Any pixel left blank will be considered as NoData Pixel.</p><ul><li>Save edits to the raster file using <strong><em>Save Edits</em></strong> button on the <strong><em>Raster Editor</em></strong> menu. If you want to save edits to a new file, click the <strong><em>Save Edits As</em></strong> button. You will see the change of layer right after refreshing the ArcMap.</li></ul><ul><li>Stop the editing section by clicking <strong><em>Stop Editing</em></strong> button.</li></ul><p>Now you finish the editing section and get the desired result.</p><h2 id=\"Why-there-is-only-one-toolbar-in-the-suite\"><a href=\"#Why-there-is-only-one-toolbar-in-the-suite\" class=\"headerlink\" title=\"Why there is only one toolbar in the suite?\"></a>Why there is only one toolbar in the suite?</h2><hr><p>Well, we are working on anther toolbar so that we can make it a real tool suite. Please have a visit on our <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">project page</a> later.</p><p>If you like this project, give it a star :)</p>","site":{"data":{}},"excerpt":"<p>Editing single pixels of a raster layer is a common task in daily GIS and RS practice. For example</p><ul><li><p>Removing misclassified pixels from a land cover classification result</p></li><li><p>Creating a set of multiple raster layers with minor difference for model simulation</p></li><li><p>etc.</p></li></ul><p>In ArcMap we use Raster Calculator and Reclassification tool as many instructions suggest. However, these tools are designed to edit the layer as a whole and they are not flexible enough for minor modification. If ArcMap allows us to edit single features of a vector layer, why we cannot edit single pixels of a raster layer in ArcMap? That is the reason why the project ArcMap Raster Edit Suite (ARES) starts. It aims at providing an ArcMAp Add-In with tools to allows single raster pixels editing, just like what we can do with the vector layer. Flexible, quick and neat!<br>","more":"</p><h2 id=\"Download-and-Install\"><a href=\"#Download-and-Install\" class=\"headerlink\" title=\"Download and Install\"></a>Download and Install</h2><hr><p>This project is hosted and published at <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">GitHub</a>. You can download the installation file at <a href=\"https://github.com/haoliangyu/ares/releases/download/0.1.3/AREA.0.1.3.zip\" target=\"_blank\" rel=\"noopener\">Here</a></p><p>After the download finishes, you need to choose the installation file that matches the ArcMap on your computer because this Add-In support ArcMap 10.0/10.1/10.2. There are two files in the folder and <strong>ARES.esriAddin</strong> is what you need:</p><p>Double click and you could see the installation wizard.</p><p>Just click <strong>Install Add-In</strong> and then you get it.</p><h2 id=\"Raster-Editor-Toolbar\"><a href=\"#Raster-Editor-Toolbar\" class=\"headerlink\" title=\"Raster Editor Toolbar\"></a>Raster Editor Toolbar</h2><hr><p>Now you have a new toolbar <strong>Raster Editor</strong> installed in your ArcMap.</p><p>This toolbar includes following tools:</p><ul><li><p>: <strong>Select &amp; Edit</strong>, which is used to select pixels for editing.</p></li><li><p>: <strong>Identify</strong>, which is used to select pixels in order to get their values, row/column indexes and zonal statistics.</p></li><li><p>: <strong>Go To Pixel</strong>, which is used to locate pixel with given row and column index.</p></li></ul><p>The purpose of this toolbar is to provide tools for precise modification with known row and column index.</p><h2 id=\"Step-by-Step-Editing-Raster-Layer\"><a href=\"#Step-by-Step-Editing-Raster-Layer\" class=\"headerlink\" title=\"Step by Step: Editing Raster Layer\"></a>Step by Step: Editing Raster Layer</h2><hr><p>In this section, I am going to show a brief guide on how to edit single pixels of raster layer in ArcMap.</p><ul><li><p>First of all, we have the layer imported in ArcMap.</p></li><li><p>Then start the editing section at the <strong><em>Start Editor</em></strong> menu by clicking <strong><em>Start Editing</em></strong> button. You can only edit one raster layer at one time. If there are more than one raster layers in ArcMap, there will be a prompt-up window to let you choose one.</p></li><li><p>Click the <strong><em>Select &amp; Edit</em></strong> button to activate the tool.</p></li><li><p>Click or drag a region of interest on the layer to selected pixels. All selected pixels will be highlighted on the map with a blue frame. <strong>Noted that selecting too much pixels may lead to crash of ArcMap</strong>.</p></li></ul><ul><li>Edit values of selected pixel at the <strong>Raster Edit</strong> Window. All edits will be highlighted on the map with a yellow symbol.</li></ul><p>Make sure your input value is compatible with the pixel type of the raster layer. Any pixel left blank will be considered as NoData Pixel.</p><ul><li>Save edits to the raster file using <strong><em>Save Edits</em></strong> button on the <strong><em>Raster Editor</em></strong> menu. If you want to save edits to a new file, click the <strong><em>Save Edits As</em></strong> button. You will see the change of layer right after refreshing the ArcMap.</li></ul><ul><li>Stop the editing section by clicking <strong><em>Stop Editing</em></strong> button.</li></ul><p>Now you finish the editing section and get the desired result.</p><h2 id=\"Why-there-is-only-one-toolbar-in-the-suite\"><a href=\"#Why-there-is-only-one-toolbar-in-the-suite\" class=\"headerlink\" title=\"Why there is only one toolbar in the suite?\"></a>Why there is only one toolbar in the suite?</h2><hr><p>Well, we are working on anther toolbar so that we can make it a real tool suite. Please have a visit on our <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\">project page</a> later.</p><p>If you like this project, give it a star :)</p>"},{"title":"Generating masks from Landsat 8 image in ArcMap","date":"2015-05-09T01:38:02.000Z","comments":1,"_content":"\nTwo months ago I have written a small python package [pymasker](https://github.com/haoliangyu/pymasker) to generate mask from the Quality Assessment band of Landsat 8 image and MODIS land products. This package is gaining popularity, But scripting may not be convenient for users who are not familiar with programming, therefore I create a ArcMap python toolbox based on this package for interactive masking.\n<!-- more -->\nThe **ArcMasking** toolbox contains two script tools, one designed for Landsat 8 QA band and one for generic quality assessment bits in other NASA remote sensing products like MODIS.\n\nThis tool can be download at [GitHub](https://github.com/haoliangyu/arcmasker/releases/tag/ArcMasker_0.1). After unzipping the package, you could open the ArcMasker.tbx file at the Catalog window in ArcMap and find following tools.\n\n## From Landsat 8 QA Band\n\n---\n\n{% asset_img Masking_from_Landsat_8.png This is an example image %}\n\nThis tool is used to create masks from the Quality Assessment band of Landsat 8 OLI image. It requires several inputs:\n\n* **Quality Assessment Band** of Landsat 8 image\n\n* **Mask type** including cloud, cirrus, water, snow or vegetation\n\n* **Confidence Level** that indicates the likelihood of existing of specific situation. You can also choose to include confidence level above what has been selected.\n\n* **Output Mask** saving path\n\n## From Quality Assessment Bits\n\n---\n\n{% asset_img Masking_from_Quality_Assessment_Bits.png This is an example image %}\n\nThis tool is used to create masks from other NASA remote sensing products with general quality assessment bit like [MODIS land products](https://github.com/haoliangyu/pymasker/wiki/MODIS-use-sample). As each portion of QA bits suggests a certain condition of the image, this toolbox simply examines the value of specific portion of QA bits and generates mask accordingly. Required inputs include:\n\n* **Quality Assessment Band**\n\n* **Bit Position** that indicates where the desired portion of bits starts.\n\n* **Bit Length** that indicates the length of bits.\n\n* **Bit Value** that indicates the desired situation.\n\n* **Output Mask** saving path\n","source":"_posts/Generating-masks-from-Landsat-8-image-in-ArcMap.md","raw":"title: Generating masks from Landsat 8 image in ArcMap\ndate: 2015-05-08 21:38:02\ncomments: true\ncategories:\n- GIS\ntags:\n- landsat\n- remote sensing\n- arcgis\n---\n\nTwo months ago I have written a small python package [pymasker](https://github.com/haoliangyu/pymasker) to generate mask from the Quality Assessment band of Landsat 8 image and MODIS land products. This package is gaining popularity, But scripting may not be convenient for users who are not familiar with programming, therefore I create a ArcMap python toolbox based on this package for interactive masking.\n<!-- more -->\nThe **ArcMasking** toolbox contains two script tools, one designed for Landsat 8 QA band and one for generic quality assessment bits in other NASA remote sensing products like MODIS.\n\nThis tool can be download at [GitHub](https://github.com/haoliangyu/arcmasker/releases/tag/ArcMasker_0.1). After unzipping the package, you could open the ArcMasker.tbx file at the Catalog window in ArcMap and find following tools.\n\n## From Landsat 8 QA Band\n\n---\n\n{% asset_img Masking_from_Landsat_8.png This is an example image %}\n\nThis tool is used to create masks from the Quality Assessment band of Landsat 8 OLI image. It requires several inputs:\n\n* **Quality Assessment Band** of Landsat 8 image\n\n* **Mask type** including cloud, cirrus, water, snow or vegetation\n\n* **Confidence Level** that indicates the likelihood of existing of specific situation. You can also choose to include confidence level above what has been selected.\n\n* **Output Mask** saving path\n\n## From Quality Assessment Bits\n\n---\n\n{% asset_img Masking_from_Quality_Assessment_Bits.png This is an example image %}\n\nThis tool is used to create masks from other NASA remote sensing products with general quality assessment bit like [MODIS land products](https://github.com/haoliangyu/pymasker/wiki/MODIS-use-sample). As each portion of QA bits suggests a certain condition of the image, this toolbox simply examines the value of specific portion of QA bits and generates mask accordingly. Required inputs include:\n\n* **Quality Assessment Band**\n\n* **Bit Position** that indicates where the desired portion of bits starts.\n\n* **Bit Length** that indicates the length of bits.\n\n* **Bit Value** that indicates the desired situation.\n\n* **Output Mask** saving path\n","slug":"Generating-masks-from-Landsat-8-image-in-ArcMap","published":1,"updated":"2018-03-03T20:45:36.118Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgrc000s8j0vutpnk92z","content":"<p>Two months ago I have written a small python package <a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">pymasker</a> to generate mask from the Quality Assessment band of Landsat 8 image and MODIS land products. This package is gaining popularity, But scripting may not be convenient for users who are not familiar with programming, therefore I create a ArcMap python toolbox based on this package for interactive masking.<br><a id=\"more\"></a><br>The <strong>ArcMasking</strong> toolbox contains two script tools, one designed for Landsat 8 QA band and one for generic quality assessment bits in other NASA remote sensing products like MODIS.</p><p>This tool can be download at <a href=\"https://github.com/haoliangyu/arcmasker/releases/tag/ArcMasker_0.1\" target=\"_blank\" rel=\"noopener\">GitHub</a>. After unzipping the package, you could open the ArcMasker.tbx file at the Catalog window in ArcMap and find following tools.</p><h2 id=\"From-Landsat-8-QA-Band\"><a href=\"#From-Landsat-8-QA-Band\" class=\"headerlink\" title=\"From Landsat 8 QA Band\"></a>From Landsat 8 QA Band</h2><hr><p>This tool is used to create masks from the Quality Assessment band of Landsat 8 OLI image. It requires several inputs:</p><ul><li><p><strong>Quality Assessment Band</strong> of Landsat 8 image</p></li><li><p><strong>Mask type</strong> including cloud, cirrus, water, snow or vegetation</p></li><li><p><strong>Confidence Level</strong> that indicates the likelihood of existing of specific situation. You can also choose to include confidence level above what has been selected.</p></li><li><p><strong>Output Mask</strong> saving path</p></li></ul><h2 id=\"From-Quality-Assessment-Bits\"><a href=\"#From-Quality-Assessment-Bits\" class=\"headerlink\" title=\"From Quality Assessment Bits\"></a>From Quality Assessment Bits</h2><hr><p>This tool is used to create masks from other NASA remote sensing products with general quality assessment bit like <a href=\"https://github.com/haoliangyu/pymasker/wiki/MODIS-use-sample\" target=\"_blank\" rel=\"noopener\">MODIS land products</a>. As each portion of QA bits suggests a certain condition of the image, this toolbox simply examines the value of specific portion of QA bits and generates mask accordingly. Required inputs include:</p><ul><li><p><strong>Quality Assessment Band</strong></p></li><li><p><strong>Bit Position</strong> that indicates where the desired portion of bits starts.</p></li><li><p><strong>Bit Length</strong> that indicates the length of bits.</p></li><li><p><strong>Bit Value</strong> that indicates the desired situation.</p></li><li><p><strong>Output Mask</strong> saving path</p></li></ul>","site":{"data":{}},"excerpt":"<p>Two months ago I have written a small python package <a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">pymasker</a> to generate mask from the Quality Assessment band of Landsat 8 image and MODIS land products. This package is gaining popularity, But scripting may not be convenient for users who are not familiar with programming, therefore I create a ArcMap python toolbox based on this package for interactive masking.<br>","more":"<br>The <strong>ArcMasking</strong> toolbox contains two script tools, one designed for Landsat 8 QA band and one for generic quality assessment bits in other NASA remote sensing products like MODIS.</p><p>This tool can be download at <a href=\"https://github.com/haoliangyu/arcmasker/releases/tag/ArcMasker_0.1\" target=\"_blank\" rel=\"noopener\">GitHub</a>. After unzipping the package, you could open the ArcMasker.tbx file at the Catalog window in ArcMap and find following tools.</p><h2 id=\"From-Landsat-8-QA-Band\"><a href=\"#From-Landsat-8-QA-Band\" class=\"headerlink\" title=\"From Landsat 8 QA Band\"></a>From Landsat 8 QA Band</h2><hr><p>This tool is used to create masks from the Quality Assessment band of Landsat 8 OLI image. It requires several inputs:</p><ul><li><p><strong>Quality Assessment Band</strong> of Landsat 8 image</p></li><li><p><strong>Mask type</strong> including cloud, cirrus, water, snow or vegetation</p></li><li><p><strong>Confidence Level</strong> that indicates the likelihood of existing of specific situation. You can also choose to include confidence level above what has been selected.</p></li><li><p><strong>Output Mask</strong> saving path</p></li></ul><h2 id=\"From-Quality-Assessment-Bits\"><a href=\"#From-Quality-Assessment-Bits\" class=\"headerlink\" title=\"From Quality Assessment Bits\"></a>From Quality Assessment Bits</h2><hr><p>This tool is used to create masks from other NASA remote sensing products with general quality assessment bit like <a href=\"https://github.com/haoliangyu/pymasker/wiki/MODIS-use-sample\" target=\"_blank\" rel=\"noopener\">MODIS land products</a>. As each portion of QA bits suggests a certain condition of the image, this toolbox simply examines the value of specific portion of QA bits and generates mask accordingly. Required inputs include:</p><ul><li><p><strong>Quality Assessment Band</strong></p></li><li><p><strong>Bit Position</strong> that indicates where the desired portion of bits starts.</p></li><li><p><strong>Bit Length</strong> that indicates the length of bits.</p></li><li><p><strong>Bit Value</strong> that indicates the desired situation.</p></li><li><p><strong>Output Mask</strong> saving path</p></li></ul>"},{"title":"Making Map with Leaflet in TypeScript","date":"2016-05-06T04:00:00.000Z","update":"2016-12-27T05:00:00.000Z","_content":"\n**UPDATE 27/12/2016**: update for TypeScript 2.0\n\nRecently I am working on a web mapping project based on [Angular 2](https://angular.io/). There isn't much data on how to create web map using [Leaflet](http://leafletjs.com/) in TypeScript. So I think it's good to write a post on it.\n\n<!-- more -->\n\n### Leaflet, Typed\n\nTypeScript is definitely typed so you need to provide a type declaration for Leaflet first. The installation of type declaration is much easier at TypeScript 2.0 for its direct support of [npm](https://www.npmjs.com/) and you just needs\n\n``` bash\n/**\n * Type declaration for GeoJSON, a dependency\n */\n\nnpm install @types/geojson\n\n/**\n * Type declaration for Leaflet\n */\n\nnpm install @types/leaflet\n```\n\nIt will download the type declaration publish [DefinitelyTyped](http://definitelytyped.org/) and relate to the installed package. Simple and no more package manager!\n\n### Mapping\n\nUsing Leaflet in TypeScript doesn't have an essential difference with using it in JavaScript. The only difference is, in the typed environment, many things are declared as class. So you may need to new a class before directly using it:\n\n``` javascript\nlet map = new L.Map('map', {\n  center: new L.LatLng(40.731253, -73.996139),\n  zoom: 12,\n});\n```\n\nAlso you will need to provide extra type information when using function:\n\n``` javascript\nmap.on('click', (e: LeafletMouseEvent) => {\n  let marker = L.marker(e.latlng)\n  .bindPopup('Popup')\n  .addTo(map)\n  .openPopup();\n});\n```\n\nAnd that's it. You should have no extra difficult in using Leaflet in TypeScript, if you are familiar with using it in JavaScript and has read the type declaration on what you need.\n\nHope you enjoy the journey with TypeScript :)\n","source":"_posts/Making-A-Map-with-Leaflet-in-TypeScript.md","raw":"title: Making Map with Leaflet in TypeScript\ndate: 2016-05-06\nupdate: 2016-12-27\ncategories:\n- GIS\ntags:\n- leaflet\n-\ttypescript\n---\n\n**UPDATE 27/12/2016**: update for TypeScript 2.0\n\nRecently I am working on a web mapping project based on [Angular 2](https://angular.io/). There isn't much data on how to create web map using [Leaflet](http://leafletjs.com/) in TypeScript. So I think it's good to write a post on it.\n\n<!-- more -->\n\n### Leaflet, Typed\n\nTypeScript is definitely typed so you need to provide a type declaration for Leaflet first. The installation of type declaration is much easier at TypeScript 2.0 for its direct support of [npm](https://www.npmjs.com/) and you just needs\n\n``` bash\n/**\n * Type declaration for GeoJSON, a dependency\n */\n\nnpm install @types/geojson\n\n/**\n * Type declaration for Leaflet\n */\n\nnpm install @types/leaflet\n```\n\nIt will download the type declaration publish [DefinitelyTyped](http://definitelytyped.org/) and relate to the installed package. Simple and no more package manager!\n\n### Mapping\n\nUsing Leaflet in TypeScript doesn't have an essential difference with using it in JavaScript. The only difference is, in the typed environment, many things are declared as class. So you may need to new a class before directly using it:\n\n``` javascript\nlet map = new L.Map('map', {\n  center: new L.LatLng(40.731253, -73.996139),\n  zoom: 12,\n});\n```\n\nAlso you will need to provide extra type information when using function:\n\n``` javascript\nmap.on('click', (e: LeafletMouseEvent) => {\n  let marker = L.marker(e.latlng)\n  .bindPopup('Popup')\n  .addTo(map)\n  .openPopup();\n});\n```\n\nAnd that's it. You should have no extra difficult in using Leaflet in TypeScript, if you are familiar with using it in JavaScript and has read the type declaration on what you need.\n\nHope you enjoy the journey with TypeScript :)\n","slug":"Making-A-Map-with-Leaflet-in-TypeScript","published":1,"updated":"2018-03-03T20:45:36.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgrd000u8j0vie984jn3","content":"<p><strong>UPDATE 27/12/2016</strong>: update for TypeScript 2.0</p><p>Recently I am working on a web mapping project based on <a href=\"https://angular.io/\" target=\"_blank\" rel=\"noopener\">Angular 2</a>. There isn’t much data on how to create web map using <a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> in TypeScript. So I think it’s good to write a post on it.</p><a id=\"more\"></a><h3 id=\"Leaflet-Typed\"><a href=\"#Leaflet-Typed\" class=\"headerlink\" title=\"Leaflet, Typed\"></a>Leaflet, Typed</h3><p>TypeScript is definitely typed so you need to provide a type declaration for Leaflet first. The installation of type declaration is much easier at TypeScript 2.0 for its direct support of <a href=\"https://www.npmjs.com/\" target=\"_blank\" rel=\"noopener\">npm</a> and you just needs</p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Type declaration <span class=\"keyword\">for</span> GeoJSON, a dependency</span><br><span class=\"line\"> */</span><br><span class=\"line\"></span><br><span class=\"line\">npm install @types/geojson</span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Type declaration <span class=\"keyword\">for</span> Leaflet</span><br><span class=\"line\"> */</span><br><span class=\"line\"></span><br><span class=\"line\">npm install @types/leaflet</span><br></pre></td></tr></table></figure><p>It will download the type declaration publish <a href=\"http://definitelytyped.org/\" target=\"_blank\" rel=\"noopener\">DefinitelyTyped</a> and relate to the installed package. Simple and no more package manager!</p><h3 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h3><p>Using Leaflet in TypeScript doesn’t have an essential difference with using it in JavaScript. The only difference is, in the typed environment, many things are declared as class. So you may need to new a class before directly using it:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">let</span> map = <span class=\"keyword\">new</span> L.Map(<span class=\"string\">'map'</span>, &#123;</span><br><span class=\"line\">  center: <span class=\"keyword\">new</span> L.LatLng(<span class=\"number\">40.731253</span>, <span class=\"number\">-73.996139</span>),</span><br><span class=\"line\">  zoom: <span class=\"number\">12</span>,</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure><p>Also you will need to provide extra type information when using function:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map.on(<span class=\"string\">'click'</span>, (e: LeafletMouseEvent) =&gt; &#123;</span><br><span class=\"line\">  <span class=\"keyword\">let</span> marker = L.marker(e.latlng)</span><br><span class=\"line\">  .bindPopup(<span class=\"string\">'Popup'</span>)</span><br><span class=\"line\">  .addTo(map)</span><br><span class=\"line\">  .openPopup();</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure><p>And that’s it. You should have no extra difficult in using Leaflet in TypeScript, if you are familiar with using it in JavaScript and has read the type declaration on what you need.</p><p>Hope you enjoy the journey with TypeScript :)</p>","site":{"data":{}},"excerpt":"<p><strong>UPDATE 27/12/2016</strong>: update for TypeScript 2.0</p><p>Recently I am working on a web mapping project based on <a href=\"https://angular.io/\" target=\"_blank\" rel=\"noopener\">Angular 2</a>. There isn’t much data on how to create web map using <a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> in TypeScript. So I think it’s good to write a post on it.</p>","more":"<h3 id=\"Leaflet-Typed\"><a href=\"#Leaflet-Typed\" class=\"headerlink\" title=\"Leaflet, Typed\"></a>Leaflet, Typed</h3><p>TypeScript is definitely typed so you need to provide a type declaration for Leaflet first. The installation of type declaration is much easier at TypeScript 2.0 for its direct support of <a href=\"https://www.npmjs.com/\" target=\"_blank\" rel=\"noopener\">npm</a> and you just needs</p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Type declaration <span class=\"keyword\">for</span> GeoJSON, a dependency</span><br><span class=\"line\"> */</span><br><span class=\"line\"></span><br><span class=\"line\">npm install @types/geojson</span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Type declaration <span class=\"keyword\">for</span> Leaflet</span><br><span class=\"line\"> */</span><br><span class=\"line\"></span><br><span class=\"line\">npm install @types/leaflet</span><br></pre></td></tr></table></figure><p>It will download the type declaration publish <a href=\"http://definitelytyped.org/\" target=\"_blank\" rel=\"noopener\">DefinitelyTyped</a> and relate to the installed package. Simple and no more package manager!</p><h3 id=\"Mapping\"><a href=\"#Mapping\" class=\"headerlink\" title=\"Mapping\"></a>Mapping</h3><p>Using Leaflet in TypeScript doesn’t have an essential difference with using it in JavaScript. The only difference is, in the typed environment, many things are declared as class. So you may need to new a class before directly using it:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">let</span> map = <span class=\"keyword\">new</span> L.Map(<span class=\"string\">'map'</span>, &#123;</span><br><span class=\"line\">  center: <span class=\"keyword\">new</span> L.LatLng(<span class=\"number\">40.731253</span>, <span class=\"number\">-73.996139</span>),</span><br><span class=\"line\">  zoom: <span class=\"number\">12</span>,</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure><p>Also you will need to provide extra type information when using function:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map.on(<span class=\"string\">'click'</span>, (e: LeafletMouseEvent) =&gt; &#123;</span><br><span class=\"line\">  <span class=\"keyword\">let</span> marker = L.marker(e.latlng)</span><br><span class=\"line\">  .bindPopup(<span class=\"string\">'Popup'</span>)</span><br><span class=\"line\">  .addTo(map)</span><br><span class=\"line\">  .openPopup();</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure><p>And that’s it. You should have no extra difficult in using Leaflet in TypeScript, if you are familiar with using it in JavaScript and has read the type declaration on what you need.</p><p>Hope you enjoy the journey with TypeScript :)</p>"},{"title":"Lazy man's package of nationwide U.S. boundaries","date":"2015-12-05T05:00:00.000Z","updated":"2016-01-24T05:00:00.000Z","_content":"\nI have been doing GIS work for quite a while and I do hate to download data from multiple sites every time. So I decide to collect those commonly geospatial data and make my own database. Of course, like all open-source people do, I'd love to share my work with you. The first release is the U.S. nationwide U.S. boundary. This dataset include **nation**, **state**, **county**, **place**, **census block**, and **census tract**. The source data come from U.S. Census Bureau and you can find the metadata [here](https://www.census.gov/geo/maps-data/data/tiger-cart-boundary.html).\n\nMultiple formats provided: **shapefile**, **geojson**, and a **postgis** database dump.<!-- more -->\n\nshapefile/geojson\n-----------------\n\n| Resolution   | 1:500,000                                                             | 1:5,000,000                                                           | 1:20,000,000                                                          |\n|--------------|-----------------------------------------------------------------------|-----------------------------------------------------------------------|-----------------------------------------------------------------------|\n| Nation       |                                                                       | [Shapefile](http://1drv.ms/1Q7B59y)/[GeoJson](http://1drv.ms/1Q7Bgln) | [Shapefile](http://1drv.ms/1OaB9j0)/[GeoJson](http://1drv.ms/1Q7BhFR) |\n| State        | [Shapefile](http://1drv.ms/1OaBfqW)/[GeoJson](http://1drv.ms/1XKAjUs) | [Shapefile](http://1drv.ms/1XKAaAg)/[GeoJson](http://1drv.ms/1XKAmzF) | [Shapefile](http://1drv.ms/1XKAcsb)/[GeoJson](http://1drv.ms/1XKAu25) |\n| County       | [Shapefile](http://1drv.ms/1YR7XVF)/[GeoJson](http://1drv.ms/1XKAjUs) | [Shapefile](http://1drv.ms/1YR81EY)/[GeoJson](http://1drv.ms/1XKAmzF) | [Shapefile](http://1drv.ms/1YR82sq)/[GeoJson](http://1drv.ms/1XKAu25) |\n| Census Tract | [Shapefile](http://1drv.ms/1TsP5Zm)/[GeoJson](http://1drv.ms/1TsPf2U) |                                                                       |                                                                       |\n| Census Block | [Shapefile](http://1drv.ms/1TsPafL)/[GeoJson](http://1drv.ms/1TsP9s6) |                                                                       |                                                                       |\n| Place        | [Shapefile](http://1drv.ms/1jViGyB)/[GeoJson](http://1drv.ms/1jViD63) |                                                                       |                                                                       |\n\npostgis\n-------\n\nDownload [U.S. boundary database](http://1drv.ms/1JtYaSe)\n\nThe data links are also at [GitHub](https://github.com/haoliangyu/us-boundary).\n\nOk, enjoy the data :)\n","source":"_posts/Lazy-man-s-package-of-U-S-boundaries.md","raw":"title: Lazy man's package of nationwide U.S. boundaries\ndate: 2015-12-05\nupdated: 2016-01-24\ncategories:\n- GIS\ntags:\n- gis\n-\topen data\n---\n\nI have been doing GIS work for quite a while and I do hate to download data from multiple sites every time. So I decide to collect those commonly geospatial data and make my own database. Of course, like all open-source people do, I'd love to share my work with you. The first release is the U.S. nationwide U.S. boundary. This dataset include **nation**, **state**, **county**, **place**, **census block**, and **census tract**. The source data come from U.S. Census Bureau and you can find the metadata [here](https://www.census.gov/geo/maps-data/data/tiger-cart-boundary.html).\n\nMultiple formats provided: **shapefile**, **geojson**, and a **postgis** database dump.<!-- more -->\n\nshapefile/geojson\n-----------------\n\n| Resolution   | 1:500,000                                                             | 1:5,000,000                                                           | 1:20,000,000                                                          |\n|--------------|-----------------------------------------------------------------------|-----------------------------------------------------------------------|-----------------------------------------------------------------------|\n| Nation       |                                                                       | [Shapefile](http://1drv.ms/1Q7B59y)/[GeoJson](http://1drv.ms/1Q7Bgln) | [Shapefile](http://1drv.ms/1OaB9j0)/[GeoJson](http://1drv.ms/1Q7BhFR) |\n| State        | [Shapefile](http://1drv.ms/1OaBfqW)/[GeoJson](http://1drv.ms/1XKAjUs) | [Shapefile](http://1drv.ms/1XKAaAg)/[GeoJson](http://1drv.ms/1XKAmzF) | [Shapefile](http://1drv.ms/1XKAcsb)/[GeoJson](http://1drv.ms/1XKAu25) |\n| County       | [Shapefile](http://1drv.ms/1YR7XVF)/[GeoJson](http://1drv.ms/1XKAjUs) | [Shapefile](http://1drv.ms/1YR81EY)/[GeoJson](http://1drv.ms/1XKAmzF) | [Shapefile](http://1drv.ms/1YR82sq)/[GeoJson](http://1drv.ms/1XKAu25) |\n| Census Tract | [Shapefile](http://1drv.ms/1TsP5Zm)/[GeoJson](http://1drv.ms/1TsPf2U) |                                                                       |                                                                       |\n| Census Block | [Shapefile](http://1drv.ms/1TsPafL)/[GeoJson](http://1drv.ms/1TsP9s6) |                                                                       |                                                                       |\n| Place        | [Shapefile](http://1drv.ms/1jViGyB)/[GeoJson](http://1drv.ms/1jViD63) |                                                                       |                                                                       |\n\npostgis\n-------\n\nDownload [U.S. boundary database](http://1drv.ms/1JtYaSe)\n\nThe data links are also at [GitHub](https://github.com/haoliangyu/us-boundary).\n\nOk, enjoy the data :)\n","slug":"Lazy-man-s-package-of-U-S-boundaries","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgrf000w8j0vog18mq22","content":"<p>I have been doing GIS work for quite a while and I do hate to download data from multiple sites every time. So I decide to collect those commonly geospatial data and make my own database. Of course, like all open-source people do, I’d love to share my work with you. The first release is the U.S. nationwide U.S. boundary. This dataset include <strong>nation</strong>, <strong>state</strong>, <strong>county</strong>, <strong>place</strong>, <strong>census block</strong>, and <strong>census tract</strong>. The source data come from U.S. Census Bureau and you can find the metadata <a href=\"https://www.census.gov/geo/maps-data/data/tiger-cart-boundary.html\" target=\"_blank\" rel=\"noopener\">here</a>.</p><p>Multiple formats provided: <strong>shapefile</strong>, <strong>geojson</strong>, and a <strong>postgis</strong> database dump.<a id=\"more\"></a></p><h2 id=\"shapefile-geojson\"><a href=\"#shapefile-geojson\" class=\"headerlink\" title=\"shapefile/geojson\"></a>shapefile/geojson</h2><table><thead><tr><th>Resolution</th><th>1:500,000</th><th>1:5,000,000</th><th>1:20,000,000</th></tr></thead><tbody><tr><td>Nation</td><td></td><td><a href=\"http://1drv.ms/1Q7B59y\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1Q7Bgln\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1OaB9j0\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1Q7BhFR\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td></tr><tr><td>State</td><td><a href=\"http://1drv.ms/1OaBfqW\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAjUs\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1XKAaAg\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAmzF\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1XKAcsb\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAu25\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td></tr><tr><td>County</td><td><a href=\"http://1drv.ms/1YR7XVF\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAjUs\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1YR81EY\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAmzF\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1YR82sq\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAu25\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td></tr><tr><td>Census Tract</td><td><a href=\"http://1drv.ms/1TsP5Zm\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1TsPf2U\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td></td><td></td></tr><tr><td>Census Block</td><td><a href=\"http://1drv.ms/1TsPafL\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1TsP9s6\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td></td><td></td></tr><tr><td>Place</td><td><a href=\"http://1drv.ms/1jViGyB\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1jViD63\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td></td></tr></tbody></table><h2 id=\"postgis\"><a href=\"#postgis\" class=\"headerlink\" title=\"postgis\"></a>postgis</h2><p>Download <a href=\"http://1drv.ms/1JtYaSe\" target=\"_blank\" rel=\"noopener\">U.S. boundary database</a></p><p>The data links are also at <a href=\"https://github.com/haoliangyu/us-boundary\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p><p>Ok, enjoy the data :)</p>","site":{"data":{}},"excerpt":"<p>I have been doing GIS work for quite a while and I do hate to download data from multiple sites every time. So I decide to collect those commonly geospatial data and make my own database. Of course, like all open-source people do, I’d love to share my work with you. The first release is the U.S. nationwide U.S. boundary. This dataset include <strong>nation</strong>, <strong>state</strong>, <strong>county</strong>, <strong>place</strong>, <strong>census block</strong>, and <strong>census tract</strong>. The source data come from U.S. Census Bureau and you can find the metadata <a href=\"https://www.census.gov/geo/maps-data/data/tiger-cart-boundary.html\" target=\"_blank\" rel=\"noopener\">here</a>.</p><p>Multiple formats provided: <strong>shapefile</strong>, <strong>geojson</strong>, and a <strong>postgis</strong> database dump.","more":"</p><h2 id=\"shapefile-geojson\"><a href=\"#shapefile-geojson\" class=\"headerlink\" title=\"shapefile/geojson\"></a>shapefile/geojson</h2><table><thead><tr><th>Resolution</th><th>1:500,000</th><th>1:5,000,000</th><th>1:20,000,000</th></tr></thead><tbody><tr><td>Nation</td><td></td><td><a href=\"http://1drv.ms/1Q7B59y\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1Q7Bgln\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1OaB9j0\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1Q7BhFR\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td></tr><tr><td>State</td><td><a href=\"http://1drv.ms/1OaBfqW\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAjUs\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1XKAaAg\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAmzF\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1XKAcsb\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAu25\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td></tr><tr><td>County</td><td><a href=\"http://1drv.ms/1YR7XVF\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAjUs\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1YR81EY\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAmzF\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td><a href=\"http://1drv.ms/1YR82sq\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1XKAu25\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td></tr><tr><td>Census Tract</td><td><a href=\"http://1drv.ms/1TsP5Zm\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1TsPf2U\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td></td><td></td></tr><tr><td>Census Block</td><td><a href=\"http://1drv.ms/1TsPafL\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1TsP9s6\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td></td><td></td></tr><tr><td>Place</td><td><a href=\"http://1drv.ms/1jViGyB\" target=\"_blank\" rel=\"noopener\">Shapefile</a>/<a href=\"http://1drv.ms/1jViD63\" target=\"_blank\" rel=\"noopener\">GeoJson</a></td><td></td></tr></tbody></table><h2 id=\"postgis\"><a href=\"#postgis\" class=\"headerlink\" title=\"postgis\"></a>postgis</h2><p>Download <a href=\"http://1drv.ms/1JtYaSe\" target=\"_blank\" rel=\"noopener\">U.S. boundary database</a></p><p>The data links are also at <a href=\"https://github.com/haoliangyu/us-boundary\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p><p>Ok, enjoy the data :)</p>"},{"title":"Making masks from Quality Control bits of MODIS land products in Python (Update)","date":"2015-02-20T02:23:29.000Z","update":"2016-08-14T04:00:00.000Z","comments":1,"_content":"\n**Update** Since 0.3.0, most class and function names have been updated according to pep8.\n\nDays ago when I published the first version of *[pymasker](https://github.com/haoliangyu/pymasker)* for masking Landsat 8 image, Dr. Robert A. Washington-Allen suggested me whether the package would be used for MODIS products. After I read technical documents of MODIS, I realize that the Quality Control bits of MOIDS products has the same structure as the QA band of Landsat 8. Therefore, I update the package to adapt MODIS products (or other NASA products with similar QC/QA bits).\n<!-- more -->\nIn this article, I am going to show how to extract masks from the Quality Control bits of MODIS land product in python.\n\n## MODIS QC/QA bits\n\n---\n\nThe QC/QA bits of MODIS is a binary number, of which each section represents the state of certain condition. Just take the 250m resolution land surface reflectance product (MOD09GQ) as example. The QC band (maybe called QA band in other products) is the fourth band of the HDF dataset. It is a unsigned 16-bit band. Each value on the pixel indicates a combination of pixel conditions. We can interpret the value by separating its binary form.\n\n{% asset_img bitstructure.png This is an example image %}\n\nThe individual bits within a binary number are read from let to right as described in the following table.\n\n{% asset_img bittable.png This is an example image %}\n\nTherefore when we put the interpretation back to the bit string, we are able to know what it indicates.\n\n{% asset_img bitsample.png This is an example image %}\n\nAs this binary number is 4096 in integer, all pixels having value 4096 in the QC band are high quality and cloud free with atmosphere correction, but no adjacency correction.\n\nThe structure of QC/QA bits vary in different MODISO products and different data collection. For full detail for each product, please have a look at\n\n* [MODIS Land Products QA Tutorial](https://lpdaac.usgs.gov/products/modis_products_table)\n\nIn the next sections, I will show how to make masks based on the QC/QA bits in python.\n\n## Preparation\n\n---\n\nBefore getting started, you need to do the following preparations:\n\n* Download and install **[pymasker](https://github.com/haoliangyu/pymasker)**.\n\n* Know the band number of QC/QA band in your HDF dataset.\n\n* Know the QC/QA bit structure of your dataset. If you only want the mask of quality level, you don't have to know the bit structure. Please go bottom and read the new update.\n\n## Maksing for MODIS product\n\n---\n\nI will continue to use MOD09GQ in the sample. First you need to load the QC Band\n\n```python\nfrom pymasker import Masker\n\n# Directly load from file, require GDAL (3 is the QA band number)\nmasker = Masker('MOD09GQ.A2015025.h12v04.005.2015027064556.hdf', 3)\n\n# Or you just load the dataset somewhere and get the band data as numpy array\nimport gdal\n\nhdfdataset = gdal.Open('MOD09GQ.A2015025.h12v04.005.2015027064556.hdf')\nsubdataset = hdfdataset.GetSubDatasets()[3][0]\nbandarray = gdal.Open(subdataset).ReadAsArray()\n\nmasker = Masker(bandarray)\n```\n\nYou need to know the bit information to generate certain masks. For example, we want a  mask only wit high quality pixels. In the previous section we have known that the quality bits start at the beginning (position 0) and the length is 2. We also know that *'00'* indicate corrected product produced at ideal quality in all bands. Therefore, the high quality mask could be made with\n\n```python\n# Get high quality mask\nmask = modismasker.ge_tmask(bitpos = 0, bitlen = 2, value = '00')\n\n# Save the mask as a TIF file\nmasker.save_tif(hqmask, 'result.tif')\n```\n\nThen you can get a binary mask where 1 represents the high quality pixel.\n\n{% asset_img hqmask.png This is an example image %}\n\n## Update\n\n*Pyamsker* has provided a new class for producing QA mask since version 0.2.2. So you don't have to look for and remember those binary bits (Well I don't like them, too).\n\nI have wrapped quality levels for MODIS land products.\n\n```python\nfrom pymasker import ModisQuality\n\n# Corrected product produced at ideal quality for all bands.\nquality = ModisQuality.high\n\n# Corrected product produced at less than ideal quality for some or all bands.\nquality = ModisQuality.medium\n\n# Corrected product not produced due to some reasons for some or all bands.\nquality = ModisQuality.low\n\n# Corrected product not produced due to cloud effects for all bands.\nquality = ModisQuality.low_cloud\n```\n\nTherefore, the masking code would be very intuitive and readable.\n\n```python\n# Create a MODIS QA masker, similar to creating a masker above\nfrom pymasker import ModisMasker\n\nmasker = ModisMasker('MOD09GQ.A2015025.h12v04.005.2015027064556.hdf')\nmask = masker.get_qa_mask(ModisQuality.high)\n```\n\nI am going to gradually support all MODIS products in the future release. Please look forward to my new update :)\n","source":"_posts/Making-masks-from-Quality-Control-bits-of-MODIS-land-products-in-Python-Update.md","raw":"title: Making masks from Quality Control bits of MODIS land products in Python (Update)\ndate: 2015-02-19 21:23:29\nupdate: 2016-08-14\ncomments: true\ncategories:\n- GIS\ntags:\n- remote sensing\n- modis\n- python\n---\n\n**Update** Since 0.3.0, most class and function names have been updated according to pep8.\n\nDays ago when I published the first version of *[pymasker](https://github.com/haoliangyu/pymasker)* for masking Landsat 8 image, Dr. Robert A. Washington-Allen suggested me whether the package would be used for MODIS products. After I read technical documents of MODIS, I realize that the Quality Control bits of MOIDS products has the same structure as the QA band of Landsat 8. Therefore, I update the package to adapt MODIS products (or other NASA products with similar QC/QA bits).\n<!-- more -->\nIn this article, I am going to show how to extract masks from the Quality Control bits of MODIS land product in python.\n\n## MODIS QC/QA bits\n\n---\n\nThe QC/QA bits of MODIS is a binary number, of which each section represents the state of certain condition. Just take the 250m resolution land surface reflectance product (MOD09GQ) as example. The QC band (maybe called QA band in other products) is the fourth band of the HDF dataset. It is a unsigned 16-bit band. Each value on the pixel indicates a combination of pixel conditions. We can interpret the value by separating its binary form.\n\n{% asset_img bitstructure.png This is an example image %}\n\nThe individual bits within a binary number are read from let to right as described in the following table.\n\n{% asset_img bittable.png This is an example image %}\n\nTherefore when we put the interpretation back to the bit string, we are able to know what it indicates.\n\n{% asset_img bitsample.png This is an example image %}\n\nAs this binary number is 4096 in integer, all pixels having value 4096 in the QC band are high quality and cloud free with atmosphere correction, but no adjacency correction.\n\nThe structure of QC/QA bits vary in different MODISO products and different data collection. For full detail for each product, please have a look at\n\n* [MODIS Land Products QA Tutorial](https://lpdaac.usgs.gov/products/modis_products_table)\n\nIn the next sections, I will show how to make masks based on the QC/QA bits in python.\n\n## Preparation\n\n---\n\nBefore getting started, you need to do the following preparations:\n\n* Download and install **[pymasker](https://github.com/haoliangyu/pymasker)**.\n\n* Know the band number of QC/QA band in your HDF dataset.\n\n* Know the QC/QA bit structure of your dataset. If you only want the mask of quality level, you don't have to know the bit structure. Please go bottom and read the new update.\n\n## Maksing for MODIS product\n\n---\n\nI will continue to use MOD09GQ in the sample. First you need to load the QC Band\n\n```python\nfrom pymasker import Masker\n\n# Directly load from file, require GDAL (3 is the QA band number)\nmasker = Masker('MOD09GQ.A2015025.h12v04.005.2015027064556.hdf', 3)\n\n# Or you just load the dataset somewhere and get the band data as numpy array\nimport gdal\n\nhdfdataset = gdal.Open('MOD09GQ.A2015025.h12v04.005.2015027064556.hdf')\nsubdataset = hdfdataset.GetSubDatasets()[3][0]\nbandarray = gdal.Open(subdataset).ReadAsArray()\n\nmasker = Masker(bandarray)\n```\n\nYou need to know the bit information to generate certain masks. For example, we want a  mask only wit high quality pixels. In the previous section we have known that the quality bits start at the beginning (position 0) and the length is 2. We also know that *'00'* indicate corrected product produced at ideal quality in all bands. Therefore, the high quality mask could be made with\n\n```python\n# Get high quality mask\nmask = modismasker.ge_tmask(bitpos = 0, bitlen = 2, value = '00')\n\n# Save the mask as a TIF file\nmasker.save_tif(hqmask, 'result.tif')\n```\n\nThen you can get a binary mask where 1 represents the high quality pixel.\n\n{% asset_img hqmask.png This is an example image %}\n\n## Update\n\n*Pyamsker* has provided a new class for producing QA mask since version 0.2.2. So you don't have to look for and remember those binary bits (Well I don't like them, too).\n\nI have wrapped quality levels for MODIS land products.\n\n```python\nfrom pymasker import ModisQuality\n\n# Corrected product produced at ideal quality for all bands.\nquality = ModisQuality.high\n\n# Corrected product produced at less than ideal quality for some or all bands.\nquality = ModisQuality.medium\n\n# Corrected product not produced due to some reasons for some or all bands.\nquality = ModisQuality.low\n\n# Corrected product not produced due to cloud effects for all bands.\nquality = ModisQuality.low_cloud\n```\n\nTherefore, the masking code would be very intuitive and readable.\n\n```python\n# Create a MODIS QA masker, similar to creating a masker above\nfrom pymasker import ModisMasker\n\nmasker = ModisMasker('MOD09GQ.A2015025.h12v04.005.2015027064556.hdf')\nmask = masker.get_qa_mask(ModisQuality.high)\n```\n\nI am going to gradually support all MODIS products in the future release. Please look forward to my new update :)\n","slug":"Making-masks-from-Quality-Control-bits-of-MODIS-land-products-in-Python-Update","published":1,"updated":"2018-03-03T20:45:36.118Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgrh00108j0v6dbknhks","content":"<p><strong>Update</strong> Since 0.3.0, most class and function names have been updated according to pep8.</p><p>Days ago when I published the first version of <em><a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">pymasker</a></em> for masking Landsat 8 image, Dr. Robert A. Washington-Allen suggested me whether the package would be used for MODIS products. After I read technical documents of MODIS, I realize that the Quality Control bits of MOIDS products has the same structure as the QA band of Landsat 8. Therefore, I update the package to adapt MODIS products (or other NASA products with similar QC/QA bits).<br><a id=\"more\"></a><br>In this article, I am going to show how to extract masks from the Quality Control bits of MODIS land product in python.</p><h2 id=\"MODIS-QC-QA-bits\"><a href=\"#MODIS-QC-QA-bits\" class=\"headerlink\" title=\"MODIS QC/QA bits\"></a>MODIS QC/QA bits</h2><hr><p>The QC/QA bits of MODIS is a binary number, of which each section represents the state of certain condition. Just take the 250m resolution land surface reflectance product (MOD09GQ) as example. The QC band (maybe called QA band in other products) is the fourth band of the HDF dataset. It is a unsigned 16-bit band. Each value on the pixel indicates a combination of pixel conditions. We can interpret the value by separating its binary form.</p><p>The individual bits within a binary number are read from let to right as described in the following table.</p><p>Therefore when we put the interpretation back to the bit string, we are able to know what it indicates.</p><p>As this binary number is 4096 in integer, all pixels having value 4096 in the QC band are high quality and cloud free with atmosphere correction, but no adjacency correction.</p><p>The structure of QC/QA bits vary in different MODISO products and different data collection. For full detail for each product, please have a look at</p><ul><li><a href=\"https://lpdaac.usgs.gov/products/modis_products_table\" target=\"_blank\" rel=\"noopener\">MODIS Land Products QA Tutorial</a></li></ul><p>In the next sections, I will show how to make masks based on the QC/QA bits in python.</p><h2 id=\"Preparation\"><a href=\"#Preparation\" class=\"headerlink\" title=\"Preparation\"></a>Preparation</h2><hr><p>Before getting started, you need to do the following preparations:</p><ul><li><p>Download and install <strong><a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">pymasker</a></strong>.</p></li><li><p>Know the band number of QC/QA band in your HDF dataset.</p></li><li><p>Know the QC/QA bit structure of your dataset. If you only want the mask of quality level, you don’t have to know the bit structure. Please go bottom and read the new update.</p></li></ul><h2 id=\"Maksing-for-MODIS-product\"><a href=\"#Maksing-for-MODIS-product\" class=\"headerlink\" title=\"Maksing for MODIS product\"></a>Maksing for MODIS product</h2><hr><p>I will continue to use MOD09GQ in the sample. First you need to load the QC Band</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> Masker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Directly load from file, require GDAL (3 is the QA band number)</span></span><br><span class=\"line\">masker = Masker(<span class=\"string\">'MOD09GQ.A2015025.h12v04.005.2015027064556.hdf'</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Or you just load the dataset somewhere and get the band data as numpy array</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> gdal</span><br><span class=\"line\"></span><br><span class=\"line\">hdfdataset = gdal.Open(<span class=\"string\">'MOD09GQ.A2015025.h12v04.005.2015027064556.hdf'</span>)</span><br><span class=\"line\">subdataset = hdfdataset.GetSubDatasets()[<span class=\"number\">3</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">bandarray = gdal.Open(subdataset).ReadAsArray()</span><br><span class=\"line\"></span><br><span class=\"line\">masker = Masker(bandarray)</span><br></pre></td></tr></table></figure><p>You need to know the bit information to generate certain masks. For example, we want a mask only wit high quality pixels. In the previous section we have known that the quality bits start at the beginning (position 0) and the length is 2. We also know that <em>‘00’</em> indicate corrected product produced at ideal quality in all bands. Therefore, the high quality mask could be made with</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Get high quality mask</span></span><br><span class=\"line\">mask = modismasker.ge_tmask(bitpos = <span class=\"number\">0</span>, bitlen = <span class=\"number\">2</span>, value = <span class=\"string\">'00'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the mask as a TIF file</span></span><br><span class=\"line\">masker.save_tif(hqmask, <span class=\"string\">'result.tif'</span>)</span><br></pre></td></tr></table></figure><p>Then you can get a binary mask where 1 represents the high quality pixel.</p><h2 id=\"Update\"><a href=\"#Update\" class=\"headerlink\" title=\"Update\"></a>Update</h2><p><em>Pyamsker</em> has provided a new class for producing QA mask since version 0.2.2. So you don’t have to look for and remember those binary bits (Well I don’t like them, too).</p><p>I have wrapped quality levels for MODIS land products.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> ModisQuality</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product produced at ideal quality for all bands.</span></span><br><span class=\"line\">quality = ModisQuality.high</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product produced at less than ideal quality for some or all bands.</span></span><br><span class=\"line\">quality = ModisQuality.medium</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product not produced due to some reasons for some or all bands.</span></span><br><span class=\"line\">quality = ModisQuality.low</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product not produced due to cloud effects for all bands.</span></span><br><span class=\"line\">quality = ModisQuality.low_cloud</span><br></pre></td></tr></table></figure><p>Therefore, the masking code would be very intuitive and readable.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create a MODIS QA masker, similar to creating a masker above</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> ModisMasker</span><br><span class=\"line\"></span><br><span class=\"line\">masker = ModisMasker(<span class=\"string\">'MOD09GQ.A2015025.h12v04.005.2015027064556.hdf'</span>)</span><br><span class=\"line\">mask = masker.get_qa_mask(ModisQuality.high)</span><br></pre></td></tr></table></figure><p>I am going to gradually support all MODIS products in the future release. Please look forward to my new update :)</p>","site":{"data":{}},"excerpt":"<p><strong>Update</strong> Since 0.3.0, most class and function names have been updated according to pep8.</p><p>Days ago when I published the first version of <em><a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">pymasker</a></em> for masking Landsat 8 image, Dr. Robert A. Washington-Allen suggested me whether the package would be used for MODIS products. After I read technical documents of MODIS, I realize that the Quality Control bits of MOIDS products has the same structure as the QA band of Landsat 8. Therefore, I update the package to adapt MODIS products (or other NASA products with similar QC/QA bits).<br>","more":"<br>In this article, I am going to show how to extract masks from the Quality Control bits of MODIS land product in python.</p><h2 id=\"MODIS-QC-QA-bits\"><a href=\"#MODIS-QC-QA-bits\" class=\"headerlink\" title=\"MODIS QC/QA bits\"></a>MODIS QC/QA bits</h2><hr><p>The QC/QA bits of MODIS is a binary number, of which each section represents the state of certain condition. Just take the 250m resolution land surface reflectance product (MOD09GQ) as example. The QC band (maybe called QA band in other products) is the fourth band of the HDF dataset. It is a unsigned 16-bit band. Each value on the pixel indicates a combination of pixel conditions. We can interpret the value by separating its binary form.</p><p>The individual bits within a binary number are read from let to right as described in the following table.</p><p>Therefore when we put the interpretation back to the bit string, we are able to know what it indicates.</p><p>As this binary number is 4096 in integer, all pixels having value 4096 in the QC band are high quality and cloud free with atmosphere correction, but no adjacency correction.</p><p>The structure of QC/QA bits vary in different MODISO products and different data collection. For full detail for each product, please have a look at</p><ul><li><a href=\"https://lpdaac.usgs.gov/products/modis_products_table\" target=\"_blank\" rel=\"noopener\">MODIS Land Products QA Tutorial</a></li></ul><p>In the next sections, I will show how to make masks based on the QC/QA bits in python.</p><h2 id=\"Preparation\"><a href=\"#Preparation\" class=\"headerlink\" title=\"Preparation\"></a>Preparation</h2><hr><p>Before getting started, you need to do the following preparations:</p><ul><li><p>Download and install <strong><a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">pymasker</a></strong>.</p></li><li><p>Know the band number of QC/QA band in your HDF dataset.</p></li><li><p>Know the QC/QA bit structure of your dataset. If you only want the mask of quality level, you don’t have to know the bit structure. Please go bottom and read the new update.</p></li></ul><h2 id=\"Maksing-for-MODIS-product\"><a href=\"#Maksing-for-MODIS-product\" class=\"headerlink\" title=\"Maksing for MODIS product\"></a>Maksing for MODIS product</h2><hr><p>I will continue to use MOD09GQ in the sample. First you need to load the QC Band</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> Masker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Directly load from file, require GDAL (3 is the QA band number)</span></span><br><span class=\"line\">masker = Masker(<span class=\"string\">'MOD09GQ.A2015025.h12v04.005.2015027064556.hdf'</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Or you just load the dataset somewhere and get the band data as numpy array</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> gdal</span><br><span class=\"line\"></span><br><span class=\"line\">hdfdataset = gdal.Open(<span class=\"string\">'MOD09GQ.A2015025.h12v04.005.2015027064556.hdf'</span>)</span><br><span class=\"line\">subdataset = hdfdataset.GetSubDatasets()[<span class=\"number\">3</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">bandarray = gdal.Open(subdataset).ReadAsArray()</span><br><span class=\"line\"></span><br><span class=\"line\">masker = Masker(bandarray)</span><br></pre></td></tr></table></figure><p>You need to know the bit information to generate certain masks. For example, we want a mask only wit high quality pixels. In the previous section we have known that the quality bits start at the beginning (position 0) and the length is 2. We also know that <em>‘00’</em> indicate corrected product produced at ideal quality in all bands. Therefore, the high quality mask could be made with</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Get high quality mask</span></span><br><span class=\"line\">mask = modismasker.ge_tmask(bitpos = <span class=\"number\">0</span>, bitlen = <span class=\"number\">2</span>, value = <span class=\"string\">'00'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the mask as a TIF file</span></span><br><span class=\"line\">masker.save_tif(hqmask, <span class=\"string\">'result.tif'</span>)</span><br></pre></td></tr></table></figure><p>Then you can get a binary mask where 1 represents the high quality pixel.</p><h2 id=\"Update\"><a href=\"#Update\" class=\"headerlink\" title=\"Update\"></a>Update</h2><p><em>Pyamsker</em> has provided a new class for producing QA mask since version 0.2.2. So you don’t have to look for and remember those binary bits (Well I don’t like them, too).</p><p>I have wrapped quality levels for MODIS land products.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> ModisQuality</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product produced at ideal quality for all bands.</span></span><br><span class=\"line\">quality = ModisQuality.high</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product produced at less than ideal quality for some or all bands.</span></span><br><span class=\"line\">quality = ModisQuality.medium</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product not produced due to some reasons for some or all bands.</span></span><br><span class=\"line\">quality = ModisQuality.low</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Corrected product not produced due to cloud effects for all bands.</span></span><br><span class=\"line\">quality = ModisQuality.low_cloud</span><br></pre></td></tr></table></figure><p>Therefore, the masking code would be very intuitive and readable.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Create a MODIS QA masker, similar to creating a masker above</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> ModisMasker</span><br><span class=\"line\"></span><br><span class=\"line\">masker = ModisMasker(<span class=\"string\">'MOD09GQ.A2015025.h12v04.005.2015027064556.hdf'</span>)</span><br><span class=\"line\">mask = masker.get_qa_mask(ModisQuality.high)</span><br></pre></td></tr></table></figure><p>I am going to gradually support all MODIS products in the future release. Please look forward to my new update :)</p>"},{"title":"Making masks with Landsat 8 Quality Assessment band using Python","date":"2015-01-19T02:13:06.000Z","update":"2016-08-14T04:00:00.000Z","comments":1,"_content":"\n**Update** Since 0.2.0, the *qabmasker* has been renamed as *landsatmasker* and the function *getmask* has been renamed as *getmultimask* for better identification. Please update your script accordingly.\n\n**Update** Since 0.3.0, most class and function names have been updated according to the pep8.\n\nThe Quality Assessment (QA) band is a standard product included in each Landsat 8 image downloaded from USGS, which contains the quality information of each pixel such as cloud, snow/ice, water body etc. The detailed information of this band can be found at [Landsat 8 Quality Assessment Band](http://landsat.usgs.gov/L8QualityAssessmentBand.php).\n<!-- more -->\nAlthough the bits structure of the QA band is easy-to-understand, it would several steps to extract the desired mask in [QGIS](http://courses.neteler.org/processing-landsat8-data-in-grass-gis-7/) or [L-LDOPE Toolbelt](https://hyspeedblog.wordpress.com/2014/08/27/working-with-landsat-8-using-and-interpreting-the-quality-assessment-qa-band/). In this article, I am going to introduce how to use *pymasker* to generate masks from Landsat 8 QA band in Python. This package is designed to provide a straightforward and intuitive way to generate masks from the QA band. It is an open-source package and the project is hosted at [GitHub](https://github.com/dz316424/pymasker).\n\n## Installation\n\nThe package can be shipped to your computer using pip.\n\n```python\npip install pymasker\n```\n\nOr just install it with the source code.\n\n```python\npython setup.py install\n```\n\nThis package depends on [**numpy**](http://www.numpy.org/). If you want to directly load the QA band file, [**GDAL**](https://pypi.python.org/pypi/GDAL/) is also in need.\n\n## Sample\n\nFirst of all, you need to load the QA band into the *qabmaser* class.\n\n```python\nfrom pymasker import LandsatMasker\n\n# load the QA band directly\nmasker = LandsatMasker('LC80170302014272LGN00_BQA.TIF')\n\n# load a numpy array that contains band data\nmasker = LandsatMasker(bandarray)\n```\n\nThe QA band contains the detection result of the following four specific conditions for each pixel:\n\n* Cloud\n\n* Cirrus\n\n* Snow/Ice\n\n* Vegetation\n\n* Water body\n\nFor each condition, the algorithm gives a confidence to indicate its existence on the pixel.\n\n```python\nfrom pymasker import LandsatConfidence\n\n# Algorithm has high confidence that this condition exists (67-100 percent confidence).\nconf = LandsatConfidence.high\n\n# Algorithm has medium confidence that this condition exists (34-66 percent confidence).\nconf = LandsatConfidence.medium\n\n# Algorithm has low to no confidence that this condition exists (0-33 percent confidence)\nconf = LandsatConfidence.low\n\n# Algorithm did not determine the status of this condition.\nconf = LandsatConfidence.undefined\n\n# Nothing, unspecified confidence\nconf = LandsatConfidence.none\n```\n\nTo generate a mask, you need to define a desired confidence for the target condition.\n\n*Pymasker* provides several functions to get the most commonly used mask. The resulting mask is a binary numpy array with 1 representing existence of specific condition and 0 representing nonexistence.\n\n```python\n# Get mask indicating cloud pixels with high confidence\nmask = masker.get_cloud_mask(LandsatConfidence.high)\n\n# Get mask indicating cloud pixels with at least medium confidence\nmask = masker.get_cloud_mask(LandsatConfidence.medium, cumulative = True)\n\n# Get mask indicating snow/ice pixels with at least medium confidence\nmask = masker.get_snow_mask(LandsatConfidence.medium, cumulative = True)\n\n# Get mask indicating water body pixels with high confidence\nmask = masker.get_water_mask(LandsatConfidence.high)\n\n# Get mask indicating vegetation pixels with high confidence\nmask = masker.get_veg_mask(LandsatConfidence.high)\n```\n\n*Pymasker* also provides a function for multi-criteria masking. In this function, you need to specify the confidence level of each condition. If you don't want the function consider one of conditions, you need to set it as confidence.none. Two different masking methods are provided:\n\n* Inclusive\t-\tMask pixels that meet at least one of all criteria.\n\n* Exclusive -\tOnly Mask pixels that meet all criteria. (default)\n\nSample code for multi-criteria masking\n\n```python\n# Get mask indicating cloud pixels (high confidence) and cirrus pixels (high confidence).\n# Exclusive and noncumulative\nmask = masker.get_multi_mask(cloud = LandsatConfidence.high, water = LandsatConfidence.high)\n\n# Save the result if you want.\nmasker.save_tif(mask, 'result.tif')\n```\n\n{% asset_img maskresult.png This is an example image %}\n\nNow you have your mask! Nice and quick!\n","source":"_posts/Making-masks-with-Landsat-8-Quality-Assessment-band-using-Python.md","raw":"title: Making masks with Landsat 8 Quality Assessment band using Python\ndate: 2015-01-18 21:13:06\nupdate: 2016-08-14\ncomments: true\ncategories:\n- GIS\ntags:\n- remote sensing\n- landsat\n- python\n---\n\n**Update** Since 0.2.0, the *qabmasker* has been renamed as *landsatmasker* and the function *getmask* has been renamed as *getmultimask* for better identification. Please update your script accordingly.\n\n**Update** Since 0.3.0, most class and function names have been updated according to the pep8.\n\nThe Quality Assessment (QA) band is a standard product included in each Landsat 8 image downloaded from USGS, which contains the quality information of each pixel such as cloud, snow/ice, water body etc. The detailed information of this band can be found at [Landsat 8 Quality Assessment Band](http://landsat.usgs.gov/L8QualityAssessmentBand.php).\n<!-- more -->\nAlthough the bits structure of the QA band is easy-to-understand, it would several steps to extract the desired mask in [QGIS](http://courses.neteler.org/processing-landsat8-data-in-grass-gis-7/) or [L-LDOPE Toolbelt](https://hyspeedblog.wordpress.com/2014/08/27/working-with-landsat-8-using-and-interpreting-the-quality-assessment-qa-band/). In this article, I am going to introduce how to use *pymasker* to generate masks from Landsat 8 QA band in Python. This package is designed to provide a straightforward and intuitive way to generate masks from the QA band. It is an open-source package and the project is hosted at [GitHub](https://github.com/dz316424/pymasker).\n\n## Installation\n\nThe package can be shipped to your computer using pip.\n\n```python\npip install pymasker\n```\n\nOr just install it with the source code.\n\n```python\npython setup.py install\n```\n\nThis package depends on [**numpy**](http://www.numpy.org/). If you want to directly load the QA band file, [**GDAL**](https://pypi.python.org/pypi/GDAL/) is also in need.\n\n## Sample\n\nFirst of all, you need to load the QA band into the *qabmaser* class.\n\n```python\nfrom pymasker import LandsatMasker\n\n# load the QA band directly\nmasker = LandsatMasker('LC80170302014272LGN00_BQA.TIF')\n\n# load a numpy array that contains band data\nmasker = LandsatMasker(bandarray)\n```\n\nThe QA band contains the detection result of the following four specific conditions for each pixel:\n\n* Cloud\n\n* Cirrus\n\n* Snow/Ice\n\n* Vegetation\n\n* Water body\n\nFor each condition, the algorithm gives a confidence to indicate its existence on the pixel.\n\n```python\nfrom pymasker import LandsatConfidence\n\n# Algorithm has high confidence that this condition exists (67-100 percent confidence).\nconf = LandsatConfidence.high\n\n# Algorithm has medium confidence that this condition exists (34-66 percent confidence).\nconf = LandsatConfidence.medium\n\n# Algorithm has low to no confidence that this condition exists (0-33 percent confidence)\nconf = LandsatConfidence.low\n\n# Algorithm did not determine the status of this condition.\nconf = LandsatConfidence.undefined\n\n# Nothing, unspecified confidence\nconf = LandsatConfidence.none\n```\n\nTo generate a mask, you need to define a desired confidence for the target condition.\n\n*Pymasker* provides several functions to get the most commonly used mask. The resulting mask is a binary numpy array with 1 representing existence of specific condition and 0 representing nonexistence.\n\n```python\n# Get mask indicating cloud pixels with high confidence\nmask = masker.get_cloud_mask(LandsatConfidence.high)\n\n# Get mask indicating cloud pixels with at least medium confidence\nmask = masker.get_cloud_mask(LandsatConfidence.medium, cumulative = True)\n\n# Get mask indicating snow/ice pixels with at least medium confidence\nmask = masker.get_snow_mask(LandsatConfidence.medium, cumulative = True)\n\n# Get mask indicating water body pixels with high confidence\nmask = masker.get_water_mask(LandsatConfidence.high)\n\n# Get mask indicating vegetation pixels with high confidence\nmask = masker.get_veg_mask(LandsatConfidence.high)\n```\n\n*Pymasker* also provides a function for multi-criteria masking. In this function, you need to specify the confidence level of each condition. If you don't want the function consider one of conditions, you need to set it as confidence.none. Two different masking methods are provided:\n\n* Inclusive\t-\tMask pixels that meet at least one of all criteria.\n\n* Exclusive -\tOnly Mask pixels that meet all criteria. (default)\n\nSample code for multi-criteria masking\n\n```python\n# Get mask indicating cloud pixels (high confidence) and cirrus pixels (high confidence).\n# Exclusive and noncumulative\nmask = masker.get_multi_mask(cloud = LandsatConfidence.high, water = LandsatConfidence.high)\n\n# Save the result if you want.\nmasker.save_tif(mask, 'result.tif')\n```\n\n{% asset_img maskresult.png This is an example image %}\n\nNow you have your mask! Nice and quick!\n","slug":"Making-masks-with-Landsat-8-Quality-Assessment-band-using-Python","published":1,"updated":"2018-03-03T20:45:36.118Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgri00138j0vye3gz2un","content":"<p><strong>Update</strong> Since 0.2.0, the <em>qabmasker</em> has been renamed as <em>landsatmasker</em> and the function <em>getmask</em> has been renamed as <em>getmultimask</em> for better identification. Please update your script accordingly.</p><p><strong>Update</strong> Since 0.3.0, most class and function names have been updated according to the pep8.</p><p>The Quality Assessment (QA) band is a standard product included in each Landsat 8 image downloaded from USGS, which contains the quality information of each pixel such as cloud, snow/ice, water body etc. The detailed information of this band can be found at <a href=\"http://landsat.usgs.gov/L8QualityAssessmentBand.php\" target=\"_blank\" rel=\"noopener\">Landsat 8 Quality Assessment Band</a>.<br><a id=\"more\"></a><br>Although the bits structure of the QA band is easy-to-understand, it would several steps to extract the desired mask in <a href=\"http://courses.neteler.org/processing-landsat8-data-in-grass-gis-7/\" target=\"_blank\" rel=\"noopener\">QGIS</a> or <a href=\"https://hyspeedblog.wordpress.com/2014/08/27/working-with-landsat-8-using-and-interpreting-the-quality-assessment-qa-band/\" target=\"_blank\" rel=\"noopener\">L-LDOPE Toolbelt</a>. In this article, I am going to introduce how to use <em>pymasker</em> to generate masks from Landsat 8 QA band in Python. This package is designed to provide a straightforward and intuitive way to generate masks from the QA band. It is an open-source package and the project is hosted at <a href=\"https://github.com/dz316424/pymasker\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>The package can be shipped to your computer using pip.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pymasker</span><br></pre></td></tr></table></figure><p>Or just install it with the source code.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><p>This package depends on <a href=\"http://www.numpy.org/\" target=\"_blank\" rel=\"noopener\"><strong>numpy</strong></a>. If you want to directly load the QA band file, <a href=\"https://pypi.python.org/pypi/GDAL/\" target=\"_blank\" rel=\"noopener\"><strong>GDAL</strong></a> is also in need.</p><h2 id=\"Sample\"><a href=\"#Sample\" class=\"headerlink\" title=\"Sample\"></a>Sample</h2><p>First of all, you need to load the QA band into the <em>qabmaser</em> class.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> LandsatMasker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load the QA band directly</span></span><br><span class=\"line\">masker = LandsatMasker(<span class=\"string\">'LC80170302014272LGN00_BQA.TIF'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load a numpy array that contains band data</span></span><br><span class=\"line\">masker = LandsatMasker(bandarray)</span><br></pre></td></tr></table></figure><p>The QA band contains the detection result of the following four specific conditions for each pixel:</p><ul><li><p>Cloud</p></li><li><p>Cirrus</p></li><li><p>Snow/Ice</p></li><li><p>Vegetation</p></li><li><p>Water body</p></li></ul><p>For each condition, the algorithm gives a confidence to indicate its existence on the pixel.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> LandsatConfidence</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm has high confidence that this condition exists (67-100 percent confidence).</span></span><br><span class=\"line\">conf = LandsatConfidence.high</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm has medium confidence that this condition exists (34-66 percent confidence).</span></span><br><span class=\"line\">conf = LandsatConfidence.medium</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm has low to no confidence that this condition exists (0-33 percent confidence)</span></span><br><span class=\"line\">conf = LandsatConfidence.low</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm did not determine the status of this condition.</span></span><br><span class=\"line\">conf = LandsatConfidence.undefined</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Nothing, unspecified confidence</span></span><br><span class=\"line\">conf = LandsatConfidence.none</span><br></pre></td></tr></table></figure><p>To generate a mask, you need to define a desired confidence for the target condition.</p><p><em>Pymasker</em> provides several functions to get the most commonly used mask. The resulting mask is a binary numpy array with 1 representing existence of specific condition and 0 representing nonexistence.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Get mask indicating cloud pixels with high confidence</span></span><br><span class=\"line\">mask = masker.get_cloud_mask(LandsatConfidence.high)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating cloud pixels with at least medium confidence</span></span><br><span class=\"line\">mask = masker.get_cloud_mask(LandsatConfidence.medium, cumulative = <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating snow/ice pixels with at least medium confidence</span></span><br><span class=\"line\">mask = masker.get_snow_mask(LandsatConfidence.medium, cumulative = <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating water body pixels with high confidence</span></span><br><span class=\"line\">mask = masker.get_water_mask(LandsatConfidence.high)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating vegetation pixels with high confidence</span></span><br><span class=\"line\">mask = masker.get_veg_mask(LandsatConfidence.high)</span><br></pre></td></tr></table></figure><p><em>Pymasker</em> also provides a function for multi-criteria masking. In this function, you need to specify the confidence level of each condition. If you don’t want the function consider one of conditions, you need to set it as confidence.none. Two different masking methods are provided:</p><ul><li><p>Inclusive - Mask pixels that meet at least one of all criteria.</p></li><li><p>Exclusive - Only Mask pixels that meet all criteria. (default)</p></li></ul><p>Sample code for multi-criteria masking</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Get mask indicating cloud pixels (high confidence) and cirrus pixels (high confidence).</span></span><br><span class=\"line\"><span class=\"comment\"># Exclusive and noncumulative</span></span><br><span class=\"line\">mask = masker.get_multi_mask(cloud = LandsatConfidence.high, water = LandsatConfidence.high)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the result if you want.</span></span><br><span class=\"line\">masker.save_tif(mask, <span class=\"string\">'result.tif'</span>)</span><br></pre></td></tr></table></figure><p>Now you have your mask! Nice and quick!</p>","site":{"data":{}},"excerpt":"<p><strong>Update</strong> Since 0.2.0, the <em>qabmasker</em> has been renamed as <em>landsatmasker</em> and the function <em>getmask</em> has been renamed as <em>getmultimask</em> for better identification. Please update your script accordingly.</p><p><strong>Update</strong> Since 0.3.0, most class and function names have been updated according to the pep8.</p><p>The Quality Assessment (QA) band is a standard product included in each Landsat 8 image downloaded from USGS, which contains the quality information of each pixel such as cloud, snow/ice, water body etc. The detailed information of this band can be found at <a href=\"http://landsat.usgs.gov/L8QualityAssessmentBand.php\" target=\"_blank\" rel=\"noopener\">Landsat 8 Quality Assessment Band</a>.<br>","more":"<br>Although the bits structure of the QA band is easy-to-understand, it would several steps to extract the desired mask in <a href=\"http://courses.neteler.org/processing-landsat8-data-in-grass-gis-7/\" target=\"_blank\" rel=\"noopener\">QGIS</a> or <a href=\"https://hyspeedblog.wordpress.com/2014/08/27/working-with-landsat-8-using-and-interpreting-the-quality-assessment-qa-band/\" target=\"_blank\" rel=\"noopener\">L-LDOPE Toolbelt</a>. In this article, I am going to introduce how to use <em>pymasker</em> to generate masks from Landsat 8 QA band in Python. This package is designed to provide a straightforward and intuitive way to generate masks from the QA band. It is an open-source package and the project is hosted at <a href=\"https://github.com/dz316424/pymasker\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>The package can be shipped to your computer using pip.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pymasker</span><br></pre></td></tr></table></figure><p>Or just install it with the source code.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><p>This package depends on <a href=\"http://www.numpy.org/\" target=\"_blank\" rel=\"noopener\"><strong>numpy</strong></a>. If you want to directly load the QA band file, <a href=\"https://pypi.python.org/pypi/GDAL/\" target=\"_blank\" rel=\"noopener\"><strong>GDAL</strong></a> is also in need.</p><h2 id=\"Sample\"><a href=\"#Sample\" class=\"headerlink\" title=\"Sample\"></a>Sample</h2><p>First of all, you need to load the QA band into the <em>qabmaser</em> class.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> LandsatMasker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load the QA band directly</span></span><br><span class=\"line\">masker = LandsatMasker(<span class=\"string\">'LC80170302014272LGN00_BQA.TIF'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># load a numpy array that contains band data</span></span><br><span class=\"line\">masker = LandsatMasker(bandarray)</span><br></pre></td></tr></table></figure><p>The QA band contains the detection result of the following four specific conditions for each pixel:</p><ul><li><p>Cloud</p></li><li><p>Cirrus</p></li><li><p>Snow/Ice</p></li><li><p>Vegetation</p></li><li><p>Water body</p></li></ul><p>For each condition, the algorithm gives a confidence to indicate its existence on the pixel.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymasker <span class=\"keyword\">import</span> LandsatConfidence</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm has high confidence that this condition exists (67-100 percent confidence).</span></span><br><span class=\"line\">conf = LandsatConfidence.high</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm has medium confidence that this condition exists (34-66 percent confidence).</span></span><br><span class=\"line\">conf = LandsatConfidence.medium</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm has low to no confidence that this condition exists (0-33 percent confidence)</span></span><br><span class=\"line\">conf = LandsatConfidence.low</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Algorithm did not determine the status of this condition.</span></span><br><span class=\"line\">conf = LandsatConfidence.undefined</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Nothing, unspecified confidence</span></span><br><span class=\"line\">conf = LandsatConfidence.none</span><br></pre></td></tr></table></figure><p>To generate a mask, you need to define a desired confidence for the target condition.</p><p><em>Pymasker</em> provides several functions to get the most commonly used mask. The resulting mask is a binary numpy array with 1 representing existence of specific condition and 0 representing nonexistence.</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Get mask indicating cloud pixels with high confidence</span></span><br><span class=\"line\">mask = masker.get_cloud_mask(LandsatConfidence.high)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating cloud pixels with at least medium confidence</span></span><br><span class=\"line\">mask = masker.get_cloud_mask(LandsatConfidence.medium, cumulative = <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating snow/ice pixels with at least medium confidence</span></span><br><span class=\"line\">mask = masker.get_snow_mask(LandsatConfidence.medium, cumulative = <span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating water body pixels with high confidence</span></span><br><span class=\"line\">mask = masker.get_water_mask(LandsatConfidence.high)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Get mask indicating vegetation pixels with high confidence</span></span><br><span class=\"line\">mask = masker.get_veg_mask(LandsatConfidence.high)</span><br></pre></td></tr></table></figure><p><em>Pymasker</em> also provides a function for multi-criteria masking. In this function, you need to specify the confidence level of each condition. If you don’t want the function consider one of conditions, you need to set it as confidence.none. Two different masking methods are provided:</p><ul><li><p>Inclusive - Mask pixels that meet at least one of all criteria.</p></li><li><p>Exclusive - Only Mask pixels that meet all criteria. (default)</p></li></ul><p>Sample code for multi-criteria masking</p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Get mask indicating cloud pixels (high confidence) and cirrus pixels (high confidence).</span></span><br><span class=\"line\"><span class=\"comment\"># Exclusive and noncumulative</span></span><br><span class=\"line\">mask = masker.get_multi_mask(cloud = LandsatConfidence.high, water = LandsatConfidence.high)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Save the result if you want.</span></span><br><span class=\"line\">masker.save_tif(mask, <span class=\"string\">'result.tif'</span>)</span><br></pre></td></tr></table></figure><p>Now you have your mask! Nice and quick!</p>"},{"title":"Pymasker","date":"2015-01-22T03:03:02.000Z","_content":"\nPymasker is a python package to generate various masks from the landsat 8 Quality Assessment band and MODIS products.\n<!-- more -->\nThis project is hosted at [GitHub](https://github.com/haoliangyu/pymasker).\n\n## Installation\n\nThe package can be shipped to your computer using pip.\n\n```bash\npip install pymasker\n```\n\nOr just install it with the source code.\n\n```bash\npython setup.py install\n```\n\nThis package depends on [**numpy**](http://www.numpy.org/). If you want to directly load the QA band file, [**GDAL**](https://pypi.python.org/pypi/GDAL/) is also in need if you want to .\n\n## Releasse\n\n* 0.1.0\n\t* First release of this package\n\n* 0.1.2\n\t* Added multi-criteria masking\n\t* Added new confidence leve: none\n\n* 0.1.3\n\t* Added *cumulative* options for multi-criteria masking\n\t* Fixed a default value problem in multi-criteria masking\n\n* 0.1.4\n\t* Removed the dependence of GDAL\n\n* 0.2.0\n\t* Added support for MODIS land products\n\n* 0.2.3\n\t* Restructure package\n","source":"_posts/Pymasker.md","raw":"title: Pymasker\ndate: 2015-01-21 22:03:02\ncategories:\n- Project\ntags:\n- gis\n- project\n- python\n---\n\nPymasker is a python package to generate various masks from the landsat 8 Quality Assessment band and MODIS products.\n<!-- more -->\nThis project is hosted at [GitHub](https://github.com/haoliangyu/pymasker).\n\n## Installation\n\nThe package can be shipped to your computer using pip.\n\n```bash\npip install pymasker\n```\n\nOr just install it with the source code.\n\n```bash\npython setup.py install\n```\n\nThis package depends on [**numpy**](http://www.numpy.org/). If you want to directly load the QA band file, [**GDAL**](https://pypi.python.org/pypi/GDAL/) is also in need if you want to .\n\n## Releasse\n\n* 0.1.0\n\t* First release of this package\n\n* 0.1.2\n\t* Added multi-criteria masking\n\t* Added new confidence leve: none\n\n* 0.1.3\n\t* Added *cumulative* options for multi-criteria masking\n\t* Fixed a default value problem in multi-criteria masking\n\n* 0.1.4\n\t* Removed the dependence of GDAL\n\n* 0.2.0\n\t* Added support for MODIS land products\n\n* 0.2.3\n\t* Restructure package\n","slug":"Pymasker","published":1,"updated":"2018-03-03T20:45:36.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgrk00178j0va9sl9xpx","content":"<p>Pymasker is a python package to generate various masks from the landsat 8 Quality Assessment band and MODIS products.<br><a id=\"more\"></a><br>This project is hosted at <a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>The package can be shipped to your computer using pip.</p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pymasker</span><br></pre></td></tr></table></figure><p>Or just install it with the source code.</p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><p>This package depends on <a href=\"http://www.numpy.org/\" target=\"_blank\" rel=\"noopener\"><strong>numpy</strong></a>. If you want to directly load the QA band file, <a href=\"https://pypi.python.org/pypi/GDAL/\" target=\"_blank\" rel=\"noopener\"><strong>GDAL</strong></a> is also in need if you want to .</p><h2 id=\"Releasse\"><a href=\"#Releasse\" class=\"headerlink\" title=\"Releasse\"></a>Releasse</h2><ul><li><p>0.1.0</p><ul><li>First release of this package</li></ul></li><li><p>0.1.2</p><ul><li>Added multi-criteria masking</li><li>Added new confidence leve: none</li></ul></li><li><p>0.1.3</p><ul><li>Added <em>cumulative</em> options for multi-criteria masking</li><li>Fixed a default value problem in multi-criteria masking</li></ul></li><li><p>0.1.4</p><ul><li>Removed the dependence of GDAL</li></ul></li><li><p>0.2.0</p><ul><li>Added support for MODIS land products</li></ul></li><li><p>0.2.3</p><ul><li>Restructure package</li></ul></li></ul>","site":{"data":{}},"excerpt":"<p>Pymasker is a python package to generate various masks from the landsat 8 Quality Assessment band and MODIS products.<br>","more":"<br>This project is hosted at <a href=\"https://github.com/haoliangyu/pymasker\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p><h2 id=\"Installation\"><a href=\"#Installation\" class=\"headerlink\" title=\"Installation\"></a>Installation</h2><p>The package can be shipped to your computer using pip.</p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pymasker</span><br></pre></td></tr></table></figure><p>Or just install it with the source code.</p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python setup.py install</span><br></pre></td></tr></table></figure><p>This package depends on <a href=\"http://www.numpy.org/\" target=\"_blank\" rel=\"noopener\"><strong>numpy</strong></a>. If you want to directly load the QA band file, <a href=\"https://pypi.python.org/pypi/GDAL/\" target=\"_blank\" rel=\"noopener\"><strong>GDAL</strong></a> is also in need if you want to .</p><h2 id=\"Releasse\"><a href=\"#Releasse\" class=\"headerlink\" title=\"Releasse\"></a>Releasse</h2><ul><li><p>0.1.0</p><ul><li>First release of this package</li></ul></li><li><p>0.1.2</p><ul><li>Added multi-criteria masking</li><li>Added new confidence leve: none</li></ul></li><li><p>0.1.3</p><ul><li>Added <em>cumulative</em> options for multi-criteria masking</li><li>Fixed a default value problem in multi-criteria masking</li></ul></li><li><p>0.1.4</p><ul><li>Removed the dependence of GDAL</li></ul></li><li><p>0.2.0</p><ul><li>Added support for MODIS land products</li></ul></li><li><p>0.2.3</p><ul><li>Restructure package</li></ul></li></ul>"},{"title":"The Launch of OpenDataDiscovery.org","date":"2016-10-10T04:00:00.000Z","comments":1,"_content":"\nAfter several months' work at my spare time, I finally publish the first version of my side-project [OpenDataDiscovery.org](http://opendatadiscovery.org/). It is a step to answer this very simple question in my mind: **How many open datasets do we have on earth?**\n\n<!-- more -->\n\nI don't remember exactly when I started thinking about this question. It seems to be natural to ask, but very easy to ignore at the era of open data blooming.\n\nJust look around. Every people, every government, every institute is talking about open data and releasing their data. EPA, NOAA, NOAA, and many other research institutes provide similar data from different angles about the same aspect of air pollution. Both USGS and USDA publish their soil survey. Numerous federal and local agencies are building their own data portals. Not to mention many research institutes have been doing that for years.\n\nThe rapidly increasing number of data providers and open data creates a view of prosperity, which is going to create another problem: we are walking out of the data desert and now into a data jungle. When the available data is not as much as today, figuring out what and how data are published is not very difficult as there is a small market. However, within a data jungle, it may be easy to understand the status of data opening at the domain you are familiar with, but difficult to look beyond. It is not just because increasing open data brings increasing information, but there are more things happening outside our individual's knowledge. We tend to be lost in the numerous options of data and miss the whole picture.\n\nTherefore, when I try to answer my initial question, I know there is a lot data at anywhere but cannot figure out even an estimate.\n\nThe methodology to answer this question is not complex. I just need to collect information from all data portals and create the overview of the world of open data. The difficult part is `all data portals`. Fortunately, in the open data industry, there are dominant data portal platform providers, who are willing to open the API for data harvesting. These open API allows developers to collect rich information from each individual portal based on their platform, including dataset number, tag, category, publisher etc.\n\nAll I need is a program that could help me automatically collect information from related portals and provide a summary view. So I develop the application [OpenDataDiscovery.org](http://opendatadiscovery.org/), which runs the server for data collection and presents the map view of all data portals on earth.\n\nToday the OpenDataDiscovery.org has been up and running. It is collecting information for more than 100 CKAN instances ([see the list](http://ckan.org/instances/)) and presents the status for these portals. As it update in a weekly basis, it is able to keep track of the status of worldwide data opening.\n\n{% asset_img map.png This is an example image %}\n\n\nLike a puzzle game, it needs us to put every piece into the frame in order to retrieve the overall view. By continuously adding portals into OpenDataDiscovery.org, it will eventually present a full and live picture of the world of open data. Let's see!\n","source":"_posts/The-Launch-of-OpenDataDiscovery.org.md","raw":"title: The Launch of OpenDataDiscovery.org\ndate: 2016-10-10\ncomments: true\ncategories:\n- GIS\ntags:\n- open data\n- gis\n- OpenDataDiscovery.org\n---\n\nAfter several months' work at my spare time, I finally publish the first version of my side-project [OpenDataDiscovery.org](http://opendatadiscovery.org/). It is a step to answer this very simple question in my mind: **How many open datasets do we have on earth?**\n\n<!-- more -->\n\nI don't remember exactly when I started thinking about this question. It seems to be natural to ask, but very easy to ignore at the era of open data blooming.\n\nJust look around. Every people, every government, every institute is talking about open data and releasing their data. EPA, NOAA, NOAA, and many other research institutes provide similar data from different angles about the same aspect of air pollution. Both USGS and USDA publish their soil survey. Numerous federal and local agencies are building their own data portals. Not to mention many research institutes have been doing that for years.\n\nThe rapidly increasing number of data providers and open data creates a view of prosperity, which is going to create another problem: we are walking out of the data desert and now into a data jungle. When the available data is not as much as today, figuring out what and how data are published is not very difficult as there is a small market. However, within a data jungle, it may be easy to understand the status of data opening at the domain you are familiar with, but difficult to look beyond. It is not just because increasing open data brings increasing information, but there are more things happening outside our individual's knowledge. We tend to be lost in the numerous options of data and miss the whole picture.\n\nTherefore, when I try to answer my initial question, I know there is a lot data at anywhere but cannot figure out even an estimate.\n\nThe methodology to answer this question is not complex. I just need to collect information from all data portals and create the overview of the world of open data. The difficult part is `all data portals`. Fortunately, in the open data industry, there are dominant data portal platform providers, who are willing to open the API for data harvesting. These open API allows developers to collect rich information from each individual portal based on their platform, including dataset number, tag, category, publisher etc.\n\nAll I need is a program that could help me automatically collect information from related portals and provide a summary view. So I develop the application [OpenDataDiscovery.org](http://opendatadiscovery.org/), which runs the server for data collection and presents the map view of all data portals on earth.\n\nToday the OpenDataDiscovery.org has been up and running. It is collecting information for more than 100 CKAN instances ([see the list](http://ckan.org/instances/)) and presents the status for these portals. As it update in a weekly basis, it is able to keep track of the status of worldwide data opening.\n\n{% asset_img map.png This is an example image %}\n\n\nLike a puzzle game, it needs us to put every piece into the frame in order to retrieve the overall view. By continuously adding portals into OpenDataDiscovery.org, it will eventually present a full and live picture of the world of open data. Let's see!\n","slug":"The-Launch-of-OpenDataDiscovery.org","published":1,"updated":"2018-03-03T20:45:36.118Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgrl00198j0vuqb5jdc3","content":"<p>After several months’ work at my spare time, I finally publish the first version of my side-project <a href=\"http://opendatadiscovery.org/\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a>. It is a step to answer this very simple question in my mind: <strong>How many open datasets do we have on earth?</strong></p><a id=\"more\"></a><p>I don’t remember exactly when I started thinking about this question. It seems to be natural to ask, but very easy to ignore at the era of open data blooming.</p><p>Just look around. Every people, every government, every institute is talking about open data and releasing their data. EPA, NOAA, NOAA, and many other research institutes provide similar data from different angles about the same aspect of air pollution. Both USGS and USDA publish their soil survey. Numerous federal and local agencies are building their own data portals. Not to mention many research institutes have been doing that for years.</p><p>The rapidly increasing number of data providers and open data creates a view of prosperity, which is going to create another problem: we are walking out of the data desert and now into a data jungle. When the available data is not as much as today, figuring out what and how data are published is not very difficult as there is a small market. However, within a data jungle, it may be easy to understand the status of data opening at the domain you are familiar with, but difficult to look beyond. It is not just because increasing open data brings increasing information, but there are more things happening outside our individual’s knowledge. We tend to be lost in the numerous options of data and miss the whole picture.</p><p>Therefore, when I try to answer my initial question, I know there is a lot data at anywhere but cannot figure out even an estimate.</p><p>The methodology to answer this question is not complex. I just need to collect information from all data portals and create the overview of the world of open data. The difficult part is <code>all data portals</code>. Fortunately, in the open data industry, there are dominant data portal platform providers, who are willing to open the API for data harvesting. These open API allows developers to collect rich information from each individual portal based on their platform, including dataset number, tag, category, publisher etc.</p><p>All I need is a program that could help me automatically collect information from related portals and provide a summary view. So I develop the application <a href=\"http://opendatadiscovery.org/\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a>, which runs the server for data collection and presents the map view of all data portals on earth.</p><p>Today the OpenDataDiscovery.org has been up and running. It is collecting information for more than 100 CKAN instances (<a href=\"http://ckan.org/instances/\" target=\"_blank\" rel=\"noopener\">see the list</a>) and presents the status for these portals. As it update in a weekly basis, it is able to keep track of the status of worldwide data opening.</p><p>Like a puzzle game, it needs us to put every piece into the frame in order to retrieve the overall view. By continuously adding portals into OpenDataDiscovery.org, it will eventually present a full and live picture of the world of open data. Let’s see!</p>","site":{"data":{}},"excerpt":"<p>After several months’ work at my spare time, I finally publish the first version of my side-project <a href=\"http://opendatadiscovery.org/\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a>. It is a step to answer this very simple question in my mind: <strong>How many open datasets do we have on earth?</strong></p>","more":"<p>I don’t remember exactly when I started thinking about this question. It seems to be natural to ask, but very easy to ignore at the era of open data blooming.</p><p>Just look around. Every people, every government, every institute is talking about open data and releasing their data. EPA, NOAA, NOAA, and many other research institutes provide similar data from different angles about the same aspect of air pollution. Both USGS and USDA publish their soil survey. Numerous federal and local agencies are building their own data portals. Not to mention many research institutes have been doing that for years.</p><p>The rapidly increasing number of data providers and open data creates a view of prosperity, which is going to create another problem: we are walking out of the data desert and now into a data jungle. When the available data is not as much as today, figuring out what and how data are published is not very difficult as there is a small market. However, within a data jungle, it may be easy to understand the status of data opening at the domain you are familiar with, but difficult to look beyond. It is not just because increasing open data brings increasing information, but there are more things happening outside our individual’s knowledge. We tend to be lost in the numerous options of data and miss the whole picture.</p><p>Therefore, when I try to answer my initial question, I know there is a lot data at anywhere but cannot figure out even an estimate.</p><p>The methodology to answer this question is not complex. I just need to collect information from all data portals and create the overview of the world of open data. The difficult part is <code>all data portals</code>. Fortunately, in the open data industry, there are dominant data portal platform providers, who are willing to open the API for data harvesting. These open API allows developers to collect rich information from each individual portal based on their platform, including dataset number, tag, category, publisher etc.</p><p>All I need is a program that could help me automatically collect information from related portals and provide a summary view. So I develop the application <a href=\"http://opendatadiscovery.org/\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a>, which runs the server for data collection and presents the map view of all data portals on earth.</p><p>Today the OpenDataDiscovery.org has been up and running. It is collecting information for more than 100 CKAN instances (<a href=\"http://ckan.org/instances/\" target=\"_blank\" rel=\"noopener\">see the list</a>) and presents the status for these portals. As it update in a weekly basis, it is able to keep track of the status of worldwide data opening.</p><p>Like a puzzle game, it needs us to put every piece into the frame in order to retrieve the overall view. By continuously adding portals into OpenDataDiscovery.org, it will eventually present a full and live picture of the world of open data. Let’s see!</p>"},{"title":"The unofficial documentation for ArcGIS Open Data APIs","date":"2017-02-11T16:48:55.000Z","_content":"\n[ArcGIS Open Data](http://opendata.arcgis.com) is a great network of governmental and institutional open data. While the data portal service runs on APIs, there is no official documentation of public APIs for ArcGIS Open Data. So this post is to provide the unofficial documentation of ArcGIS Open Data APIs, which are discovered in my work (mostly by accident).\n\n<!-- more -->\n\nThis documentation is also published at [GitHub Gist](https://gist.github.com/haoliangyu/0d0abcccfd3b25beb8b7597b4b2fc497);\n\n## Dataset Search API\n\n### Example\n\n```\nhttp://data.portal.com/datasets?q=test\n```\n\n### Parameters\n\n* **q** (string)\n\n  query string for full text search\n\n* **bbox** (unknown)\n\n  boundary box for geographic search\n\n* **required_keywords** (unknown)\n\n  dataset keywords (tags) for search\n\n* **page** (integer)\n\n  current page of results\n\n* **per_page** (integer)\n\n  number of results per page (default: 10)\n\n* **sort_by** (string)\n\n  returned results sorting method:\n\n  * `updated_at` (default)\n  * `relevance`\n\n* **sort_order** (string)\n\n  returned results order:\n\n  * `desc` (default)\n  * `asc`\n\n### Response Example\n\n``` json\n{\n  \"data\": [\n    {\n      \"display_field\": \"FAC_CAT\",\n      \"max_record_count\": 2000,\n      \"record_count\": 11,\n      \"geometry_type\": \"esriGeometryPoint\",\n      \"object_id_field\": \"FID\",\n      \"supported_extensions\": \"\",\n      \"advanced_query_capabilities\": {\n        \"supports_pagination\": true,\n        \"supports_query_related_pagination\": true,\n        \"supports_query_with_distance\": true,\n        \"supports_returning_query_extent\": true,\n        \"supports_statistics\": true,\n        \"supports_order_by\": true,\n        \"supports_distinct\": true,\n        \"supports_query_with_result_type\": true,\n        \"supports_sql_expression\": true,\n        \"supports_advanced_query_related\": true,\n        \"supports_returning_geometry_centroid\": false\n      },\n      \"supports_advanced_queries\": true,\n      \"id\": \"dd62922ee5c14d11a187aaf30052404f_0\",\n      \"landing_page\": \"https://www.arcgis.com/home/item.html?id=dd62922ee5c14d11a187aaf30052404f\",\n      \"description\": \"This feature layer, utilizing data from the U.S. Environmental Protection Agency (EPA), displays regional offices. The EPA began operation on December 2, 1970 and it inherited two regional systems from predecessor agencies. The Federal Water Quality Administration which used a nine region system and the Environmental Health Service which had adopted the ten Standard Federal Regions suggested by the Office of Management and Budget (OMB). In order to facilitate easier operations with local and state governments as well as other federal agencies the EPA chose to adopt the OMB Standard Federal Regions which still exist today.<div><br /></div><div><div><img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/26b532f4bfb14e0eb517c644dcda73c1/data\\\" /><br /></div><div><i>Regional Office locations</i></div><div><br /></div><div>For more information: <a href=\\\"https://www.epa.gov/aboutepa\\\" target=\\\"_blank\\\">About EPA</a></div><div>For feedback, please contact: <a href=\\\"mailto:ArcGIScomNationalMaps@esri.com\\\" target=\\\"_blank\\\">ArcGIScomNationalMaps@esri.com</a></div><div><div><br /></div><div><div>EPA sites of interest<b><br /></b></div><div><b><br /></b></div><div><img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/d543cdf1e9694f5f985eae5b2dcd36f8/data\\\" /> <a href=\\\"https://epa.maps.arcgis.com/home/index.html\\\" target=\\\"_blank\\\">ArcGIS Online Organizational Homepage</a><b><br /></b></div><div><b><br /></b></div><div>Other Federal User Community federally focused content that may interest you</div><div><b><br /></b></div><div><img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/f83c3452ec074ee08c7f04975578c212/data\\\" /> <a href=\\\"http://fedmaps.maps.arcgis.com/home/search.html?q=owner%3AFederal_User_Community%20AND%20tags%3AUS%20EPA&amp;t=content&amp;restrict=false\\\" target=\\\"_blank\\\">U.S. Environmental Protection Agency</a>           <img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/46785cfb399344a6af50d4514d6ef0f9/data\\\" /> <a href=\\\"http://open.fedmaps.opendata.arcgis.com/datasets?q=US+EPA&amp;sort_by=relevance\\\" target=\\\"_blank\\\">Open Data: U.S. EPA</a> </div></div></div></div>\",\n      \"extent\": {\n        \"coordinates\": [\n          [\n            -125.676,\n            24.242\n          ],\n          [\n            -65.559,\n            50.089\n          ]\n        ]\n      },\n      \"fields\": [\n        {\n          \"name\": \"FID\",\n          \"type\": \"esriFieldTypeInteger\",\n          \"alias\": \"FID\",\n          \"domain\": null,\n          \"statistics\": {\n            \"duration\": 0\n          },\n          \"updated_at\": \"2017-02-06T21:06:49.399Z\"\n        }\n      ],\n      \"item_name\": \"EPA Regional Offices\",\n      \"type\": \"ItemLayer\",\n      \"item_type\": \"Feature Layer\",\n      \"license\": \"<p><img src=\\\"http://downloads.esri.com/blogs/arcgisonline/esrilogo_new.png\\\" />This work is licensed under the Esri Master License Agreement.<br /></p><p><a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\">View Summary</a> | <a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\">View Terms of Use</a></p>\",\n      \"name\": \"EPA Regional Offices\",\n      \"owner\": \"Federal_User_Community\",\n      \"tags\": [\n        \"A-16\",\n        \"A16\",\n        \"U.S. Environmental Protection Agency\",\n        \"U.S. EPA\",\n        \"EPA\",\n        \"regional offices\",\n        \"regions\",\n        \"Environmental Protection Agency\",\n        \"places\",\n        \"boundaries\"\n      ],\n      \"thumbnail_url\": \"https://www.arcgis.com/sharing/rest/content/items/dd62922ee5c14d11a187aaf30052404f/info/thumbnail/EPA_-_Regional_Offices_-_screen_capture.png\",\n      \"public\": true,\n      \"created_at\": \"2016-09-02T11:50:55.000Z\",\n      \"updated_at\": \"2017-02-06T21:06:50.911Z\",\n      \"url\": \"https://services2.arcgis.com/FiaPA4ga0iQKduv3/arcgis/rest/services/EPA_RegionalOffices/FeatureServer/0\",\n      \"views\": null,\n      \"quality\": 86,\n      \"coverage\": \"global\",\n      \"current_version\": 10.41,\n      \"comments_enabled\": true,\n      \"service_spatial_reference\": {\n        \"wkid\": 102100,\n        \"latestWkid\": 3857\n      },\n      \"metadata_url\": null,\n      \"org_id\": \"FiaPA4ga0iQKduv3\",\n      \"metadata\": {\n        \"published\": null,\n        \"present\": false,\n        \"url\": null,\n        \"online_resources\": []\n      },\n      \"structured_license\": {\n        \"type\": \"custom\",\n        \"text\": \"This work is licensed under the Esri Master License Agreement.<a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\">View Summary</a> | <a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\">View Terms of Use</a>\"\n      },\n      \"use_standardized_queries\": true,\n      \"sites\": [\n        {\n          \"title\": \"PACI\",\n          \"url\": \"http://paci-esridubaioffice.opendata.arcgis.com\",\n          \"logo\": null\n        }\n      ],\n      \"main_group_title\": \"Open Data - Derived US Independent Establishments and Gov't Corps\",\n      \"main_group_description\": \"<span style='line-height: 24px; background-color: rgb(255, 255, 255);'><font face='Verdana' size='3'>The group contains a set of map services, web maps and map packages that can be used in a web browser or downloaded to your ArcGIS Desktop application.  The maps may be used as base maps and operational layers to support a variety of applications.</font></span>\",\n      \"main_group_thumbnail_url\": null\n    }\n  ],\n  \"metadata\": {\n    \"query_parameters\": {\n      \"bbox\": null,\n      \"page\": 1,\n      \"per_page\": 1,\n      \"q\": \"*\",\n      \"required_keywords\": [],\n      \"sort_by\": \"updated_at\",\n      \"sort_order\": \"desc\"\n    },\n    \"stats\": {\n      \"count\": 1,\n      \"total_count\": 192,\n      \"top_tags\": [\n        { \"name\": \"ocean\", \"count\": 62 }\n      ]\n    }\n  }\n}\n```\n","source":"_posts/The-unofficial-documentation-for-ArcGIS-Open-Data-dataset-search-API.md","raw":"title: The unofficial documentation for ArcGIS Open Data APIs\ndate: 2017-02-11 11:48:55\ncategories:\n- Open Data\ntags:\n- arcgis\n- open data\n---\n\n[ArcGIS Open Data](http://opendata.arcgis.com) is a great network of governmental and institutional open data. While the data portal service runs on APIs, there is no official documentation of public APIs for ArcGIS Open Data. So this post is to provide the unofficial documentation of ArcGIS Open Data APIs, which are discovered in my work (mostly by accident).\n\n<!-- more -->\n\nThis documentation is also published at [GitHub Gist](https://gist.github.com/haoliangyu/0d0abcccfd3b25beb8b7597b4b2fc497);\n\n## Dataset Search API\n\n### Example\n\n```\nhttp://data.portal.com/datasets?q=test\n```\n\n### Parameters\n\n* **q** (string)\n\n  query string for full text search\n\n* **bbox** (unknown)\n\n  boundary box for geographic search\n\n* **required_keywords** (unknown)\n\n  dataset keywords (tags) for search\n\n* **page** (integer)\n\n  current page of results\n\n* **per_page** (integer)\n\n  number of results per page (default: 10)\n\n* **sort_by** (string)\n\n  returned results sorting method:\n\n  * `updated_at` (default)\n  * `relevance`\n\n* **sort_order** (string)\n\n  returned results order:\n\n  * `desc` (default)\n  * `asc`\n\n### Response Example\n\n``` json\n{\n  \"data\": [\n    {\n      \"display_field\": \"FAC_CAT\",\n      \"max_record_count\": 2000,\n      \"record_count\": 11,\n      \"geometry_type\": \"esriGeometryPoint\",\n      \"object_id_field\": \"FID\",\n      \"supported_extensions\": \"\",\n      \"advanced_query_capabilities\": {\n        \"supports_pagination\": true,\n        \"supports_query_related_pagination\": true,\n        \"supports_query_with_distance\": true,\n        \"supports_returning_query_extent\": true,\n        \"supports_statistics\": true,\n        \"supports_order_by\": true,\n        \"supports_distinct\": true,\n        \"supports_query_with_result_type\": true,\n        \"supports_sql_expression\": true,\n        \"supports_advanced_query_related\": true,\n        \"supports_returning_geometry_centroid\": false\n      },\n      \"supports_advanced_queries\": true,\n      \"id\": \"dd62922ee5c14d11a187aaf30052404f_0\",\n      \"landing_page\": \"https://www.arcgis.com/home/item.html?id=dd62922ee5c14d11a187aaf30052404f\",\n      \"description\": \"This feature layer, utilizing data from the U.S. Environmental Protection Agency (EPA), displays regional offices. The EPA began operation on December 2, 1970 and it inherited two regional systems from predecessor agencies. The Federal Water Quality Administration which used a nine region system and the Environmental Health Service which had adopted the ten Standard Federal Regions suggested by the Office of Management and Budget (OMB). In order to facilitate easier operations with local and state governments as well as other federal agencies the EPA chose to adopt the OMB Standard Federal Regions which still exist today.<div><br /></div><div><div><img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/26b532f4bfb14e0eb517c644dcda73c1/data\\\" /><br /></div><div><i>Regional Office locations</i></div><div><br /></div><div>For more information: <a href=\\\"https://www.epa.gov/aboutepa\\\" target=\\\"_blank\\\">About EPA</a></div><div>For feedback, please contact: <a href=\\\"mailto:ArcGIScomNationalMaps@esri.com\\\" target=\\\"_blank\\\">ArcGIScomNationalMaps@esri.com</a></div><div><div><br /></div><div><div>EPA sites of interest<b><br /></b></div><div><b><br /></b></div><div><img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/d543cdf1e9694f5f985eae5b2dcd36f8/data\\\" /> <a href=\\\"https://epa.maps.arcgis.com/home/index.html\\\" target=\\\"_blank\\\">ArcGIS Online Organizational Homepage</a><b><br /></b></div><div><b><br /></b></div><div>Other Federal User Community federally focused content that may interest you</div><div><b><br /></b></div><div><img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/f83c3452ec074ee08c7f04975578c212/data\\\" /> <a href=\\\"http://fedmaps.maps.arcgis.com/home/search.html?q=owner%3AFederal_User_Community%20AND%20tags%3AUS%20EPA&amp;t=content&amp;restrict=false\\\" target=\\\"_blank\\\">U.S. Environmental Protection Agency</a>           <img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/46785cfb399344a6af50d4514d6ef0f9/data\\\" /> <a href=\\\"http://open.fedmaps.opendata.arcgis.com/datasets?q=US+EPA&amp;sort_by=relevance\\\" target=\\\"_blank\\\">Open Data: U.S. EPA</a> </div></div></div></div>\",\n      \"extent\": {\n        \"coordinates\": [\n          [\n            -125.676,\n            24.242\n          ],\n          [\n            -65.559,\n            50.089\n          ]\n        ]\n      },\n      \"fields\": [\n        {\n          \"name\": \"FID\",\n          \"type\": \"esriFieldTypeInteger\",\n          \"alias\": \"FID\",\n          \"domain\": null,\n          \"statistics\": {\n            \"duration\": 0\n          },\n          \"updated_at\": \"2017-02-06T21:06:49.399Z\"\n        }\n      ],\n      \"item_name\": \"EPA Regional Offices\",\n      \"type\": \"ItemLayer\",\n      \"item_type\": \"Feature Layer\",\n      \"license\": \"<p><img src=\\\"http://downloads.esri.com/blogs/arcgisonline/esrilogo_new.png\\\" />This work is licensed under the Esri Master License Agreement.<br /></p><p><a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\">View Summary</a> | <a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\">View Terms of Use</a></p>\",\n      \"name\": \"EPA Regional Offices\",\n      \"owner\": \"Federal_User_Community\",\n      \"tags\": [\n        \"A-16\",\n        \"A16\",\n        \"U.S. Environmental Protection Agency\",\n        \"U.S. EPA\",\n        \"EPA\",\n        \"regional offices\",\n        \"regions\",\n        \"Environmental Protection Agency\",\n        \"places\",\n        \"boundaries\"\n      ],\n      \"thumbnail_url\": \"https://www.arcgis.com/sharing/rest/content/items/dd62922ee5c14d11a187aaf30052404f/info/thumbnail/EPA_-_Regional_Offices_-_screen_capture.png\",\n      \"public\": true,\n      \"created_at\": \"2016-09-02T11:50:55.000Z\",\n      \"updated_at\": \"2017-02-06T21:06:50.911Z\",\n      \"url\": \"https://services2.arcgis.com/FiaPA4ga0iQKduv3/arcgis/rest/services/EPA_RegionalOffices/FeatureServer/0\",\n      \"views\": null,\n      \"quality\": 86,\n      \"coverage\": \"global\",\n      \"current_version\": 10.41,\n      \"comments_enabled\": true,\n      \"service_spatial_reference\": {\n        \"wkid\": 102100,\n        \"latestWkid\": 3857\n      },\n      \"metadata_url\": null,\n      \"org_id\": \"FiaPA4ga0iQKduv3\",\n      \"metadata\": {\n        \"published\": null,\n        \"present\": false,\n        \"url\": null,\n        \"online_resources\": []\n      },\n      \"structured_license\": {\n        \"type\": \"custom\",\n        \"text\": \"This work is licensed under the Esri Master License Agreement.<a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\">View Summary</a> | <a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\">View Terms of Use</a>\"\n      },\n      \"use_standardized_queries\": true,\n      \"sites\": [\n        {\n          \"title\": \"PACI\",\n          \"url\": \"http://paci-esridubaioffice.opendata.arcgis.com\",\n          \"logo\": null\n        }\n      ],\n      \"main_group_title\": \"Open Data - Derived US Independent Establishments and Gov't Corps\",\n      \"main_group_description\": \"<span style='line-height: 24px; background-color: rgb(255, 255, 255);'><font face='Verdana' size='3'>The group contains a set of map services, web maps and map packages that can be used in a web browser or downloaded to your ArcGIS Desktop application.  The maps may be used as base maps and operational layers to support a variety of applications.</font></span>\",\n      \"main_group_thumbnail_url\": null\n    }\n  ],\n  \"metadata\": {\n    \"query_parameters\": {\n      \"bbox\": null,\n      \"page\": 1,\n      \"per_page\": 1,\n      \"q\": \"*\",\n      \"required_keywords\": [],\n      \"sort_by\": \"updated_at\",\n      \"sort_order\": \"desc\"\n    },\n    \"stats\": {\n      \"count\": 1,\n      \"total_count\": 192,\n      \"top_tags\": [\n        { \"name\": \"ocean\", \"count\": 62 }\n      ]\n    }\n  }\n}\n```\n","slug":"The-unofficial-documentation-for-ArcGIS-Open-Data-dataset-search-API","published":1,"updated":"2018-03-03T20:45:36.122Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgrn001c8j0v4uopd4ht","content":"<p><a href=\"http://opendata.arcgis.com\" target=\"_blank\" rel=\"noopener\">ArcGIS Open Data</a> is a great network of governmental and institutional open data. While the data portal service runs on APIs, there is no official documentation of public APIs for ArcGIS Open Data. So this post is to provide the unofficial documentation of ArcGIS Open Data APIs, which are discovered in my work (mostly by accident).</p><a id=\"more\"></a><p>This documentation is also published at <a href=\"https://gist.github.com/haoliangyu/0d0abcccfd3b25beb8b7597b4b2fc497\" target=\"_blank\" rel=\"noopener\">GitHub Gist</a>;</p><h2 id=\"Dataset-Search-API\"><a href=\"#Dataset-Search-API\" class=\"headerlink\" title=\"Dataset Search API\"></a>Dataset Search API</h2><h3 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://data.portal.com/datasets?q=test</span><br></pre></td></tr></table></figure><h3 id=\"Parameters\"><a href=\"#Parameters\" class=\"headerlink\" title=\"Parameters\"></a>Parameters</h3><ul><li><p><strong>q</strong> (string)</p><p>query string for full text search</p></li><li><p><strong>bbox</strong> (unknown)</p><p>boundary box for geographic search</p></li><li><p><strong>required_keywords</strong> (unknown)</p><p>dataset keywords (tags) for search</p></li><li><p><strong>page</strong> (integer)</p><p>current page of results</p></li><li><p><strong>per_page</strong> (integer)</p><p>number of results per page (default: 10)</p></li><li><p><strong>sort_by</strong> (string)</p><p>returned results sorting method:</p><ul><li><code>updated_at</code> (default)</li><li><code>relevance</code></li></ul></li><li><p><strong>sort_order</strong> (string)</p><p>returned results order:</p><ul><li><code>desc</code> (default)</li><li><code>asc</code></li></ul></li></ul><h3 id=\"Response-Example\"><a href=\"#Response-Example\" class=\"headerlink\" title=\"Response Example\"></a>Response Example</h3><figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"data\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"display_field\"</span>: <span class=\"string\">\"FAC_CAT\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"max_record_count\"</span>: <span class=\"number\">2000</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"record_count\"</span>: <span class=\"number\">11</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"geometry_type\"</span>: <span class=\"string\">\"esriGeometryPoint\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"object_id_field\"</span>: <span class=\"string\">\"FID\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"supported_extensions\"</span>: <span class=\"string\">\"\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"advanced_query_capabilities\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"supports_pagination\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_query_related_pagination\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_query_with_distance\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_returning_query_extent\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_statistics\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_order_by\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_distinct\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_query_with_result_type\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_sql_expression\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_advanced_query_related\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_returning_geometry_centroid\"</span>: <span class=\"literal\">false</span></span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"supports_advanced_queries\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"id\"</span>: <span class=\"string\">\"dd62922ee5c14d11a187aaf30052404f_0\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"landing_page\"</span>: <span class=\"string\">\"https://www.arcgis.com/home/item.html?id=dd62922ee5c14d11a187aaf30052404f\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"This feature layer, utilizing data from the U.S. Environmental Protection Agency (EPA), displays regional offices. The EPA began operation on December 2, 1970 and it inherited two regional systems from predecessor agencies. The Federal Water Quality Administration which used a nine region system and the Environmental Health Service which had adopted the ten Standard Federal Regions suggested by the Office of Management and Budget (OMB). In order to facilitate easier operations with local and state governments as well as other federal agencies the EPA chose to adopt the OMB Standard Federal Regions which still exist today.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/26b532f4bfb14e0eb517c644dcda73c1/data\\\" /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;i&gt;Regional Office locations&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;For more information: &lt;a href=\\\"https://www.epa.gov/aboutepa\\\" target=\\\"_blank\\\"&gt;About EPA&lt;/a&gt;&lt;/div&gt;&lt;div&gt;For feedback, please contact: &lt;a href=\\\"mailto:ArcGIScomNationalMaps@esri.com\\\" target=\\\"_blank\\\"&gt;ArcGIScomNationalMaps@esri.com&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;EPA sites of interest&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/d543cdf1e9694f5f985eae5b2dcd36f8/data\\\" /&gt; &lt;a href=\\\"https://epa.maps.arcgis.com/home/index.html\\\" target=\\\"_blank\\\"&gt;ArcGIS Online Organizational Homepage&lt;/a&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;Other Federal User Community federally focused content that may interest you&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/f83c3452ec074ee08c7f04975578c212/data\\\" /&gt; &lt;a href=\\\"http://fedmaps.maps.arcgis.com/home/search.html?q=owner%3AFederal_User_Community%20AND%20tags%3AUS%20EPA&amp;amp;t=content&amp;amp;restrict=false\\\" target=\\\"_blank\\\"&gt;U.S. Environmental Protection Agency&lt;/a&gt;           &lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/46785cfb399344a6af50d4514d6ef0f9/data\\\" /&gt; &lt;a href=\\\"http://open.fedmaps.opendata.arcgis.com/datasets?q=US+EPA&amp;amp;sort_by=relevance\\\" target=\\\"_blank\\\"&gt;Open Data: U.S. EPA&lt;/a&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"extent\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"coordinates\"</span>: [</span><br><span class=\"line\">          [</span><br><span class=\"line\">            <span class=\"number\">-125.676</span>,</span><br><span class=\"line\">            <span class=\"number\">24.242</span></span><br><span class=\"line\">          ],</span><br><span class=\"line\">          [</span><br><span class=\"line\">            <span class=\"number\">-65.559</span>,</span><br><span class=\"line\">            <span class=\"number\">50.089</span></span><br><span class=\"line\">          ]</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"FID\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"esriFieldTypeInteger\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"alias\"</span>: <span class=\"string\">\"FID\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"domain\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"statistics\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"duration\"</span>: <span class=\"number\">0</span></span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          <span class=\"attr\">\"updated_at\"</span>: <span class=\"string\">\"2017-02-06T21:06:49.399Z\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"item_name\"</span>: <span class=\"string\">\"EPA Regional Offices\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"ItemLayer\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"item_type\"</span>: <span class=\"string\">\"Feature Layer\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"license\"</span>: <span class=\"string\">\"&lt;p&gt;&lt;img src=\\\"http://downloads.esri.com/blogs/arcgisonline/esrilogo_new.png\\\" /&gt;This work is licensed under the Esri Master License Agreement.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\"&gt;View Summary&lt;/a&gt; | &lt;a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\"&gt;View Terms of Use&lt;/a&gt;&lt;/p&gt;\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"EPA Regional Offices\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"owner\"</span>: <span class=\"string\">\"Federal_User_Community\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"tags\"</span>: [</span><br><span class=\"line\">        <span class=\"string\">\"A-16\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"A16\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"U.S. Environmental Protection Agency\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"U.S. EPA\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"EPA\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"regional offices\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"regions\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"Environmental Protection Agency\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"places\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"boundaries\"</span></span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"thumbnail_url\"</span>: <span class=\"string\">\"https://www.arcgis.com/sharing/rest/content/items/dd62922ee5c14d11a187aaf30052404f/info/thumbnail/EPA_-_Regional_Offices_-_screen_capture.png\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"public\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"created_at\"</span>: <span class=\"string\">\"2016-09-02T11:50:55.000Z\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"updated_at\"</span>: <span class=\"string\">\"2017-02-06T21:06:50.911Z\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"url\"</span>: <span class=\"string\">\"https://services2.arcgis.com/FiaPA4ga0iQKduv3/arcgis/rest/services/EPA_RegionalOffices/FeatureServer/0\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"views\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"quality\"</span>: <span class=\"number\">86</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"coverage\"</span>: <span class=\"string\">\"global\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"current_version\"</span>: <span class=\"number\">10.41</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"comments_enabled\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"service_spatial_reference\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"wkid\"</span>: <span class=\"number\">102100</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"latestWkid\"</span>: <span class=\"number\">3857</span></span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"metadata_url\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"org_id\"</span>: <span class=\"string\">\"FiaPA4ga0iQKduv3\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"metadata\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"published\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"present\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"url\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"online_resources\"</span>: []</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"structured_license\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"custom\"</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"text\"</span>: <span class=\"string\">\"This work is licensed under the Esri Master License Agreement.&lt;a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\"&gt;View Summary&lt;/a&gt; | &lt;a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\"&gt;View Terms of Use&lt;/a&gt;\"</span></span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"use_standardized_queries\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"sites\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"title\"</span>: <span class=\"string\">\"PACI\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"url\"</span>: <span class=\"string\">\"http://paci-esridubaioffice.opendata.arcgis.com\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"logo\"</span>: <span class=\"literal\">null</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"main_group_title\"</span>: <span class=\"string\">\"Open Data - Derived US Independent Establishments and Gov't Corps\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"main_group_description\"</span>: <span class=\"string\">\"&lt;span style='line-height: 24px; background-color: rgb(255, 255, 255);'&gt;&lt;font face='Verdana' size='3'&gt;The group contains a set of map services, web maps and map packages that can be used in a web browser or downloaded to your ArcGIS Desktop application.  The maps may be used as base maps and operational layers to support a variety of applications.&lt;/font&gt;&lt;/span&gt;\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"main_group_thumbnail_url\"</span>: <span class=\"literal\">null</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  <span class=\"attr\">\"metadata\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query_parameters\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"bbox\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"page\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"per_page\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"q\"</span>: <span class=\"string\">\"*\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"required_keywords\"</span>: [],</span><br><span class=\"line\">      <span class=\"attr\">\"sort_by\"</span>: <span class=\"string\">\"updated_at\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"sort_order\"</span>: <span class=\"string\">\"desc\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"stats\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"count\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"total_count\"</span>: <span class=\"number\">192</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"top_tags\"</span>: [</span><br><span class=\"line\">        &#123; <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"ocean\"</span>, <span class=\"attr\">\"count\"</span>: <span class=\"number\">62</span> &#125;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p><a href=\"http://opendata.arcgis.com\" target=\"_blank\" rel=\"noopener\">ArcGIS Open Data</a> is a great network of governmental and institutional open data. While the data portal service runs on APIs, there is no official documentation of public APIs for ArcGIS Open Data. So this post is to provide the unofficial documentation of ArcGIS Open Data APIs, which are discovered in my work (mostly by accident).</p>","more":"<p>This documentation is also published at <a href=\"https://gist.github.com/haoliangyu/0d0abcccfd3b25beb8b7597b4b2fc497\" target=\"_blank\" rel=\"noopener\">GitHub Gist</a>;</p><h2 id=\"Dataset-Search-API\"><a href=\"#Dataset-Search-API\" class=\"headerlink\" title=\"Dataset Search API\"></a>Dataset Search API</h2><h3 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">http://data.portal.com/datasets?q=test</span><br></pre></td></tr></table></figure><h3 id=\"Parameters\"><a href=\"#Parameters\" class=\"headerlink\" title=\"Parameters\"></a>Parameters</h3><ul><li><p><strong>q</strong> (string)</p><p>query string for full text search</p></li><li><p><strong>bbox</strong> (unknown)</p><p>boundary box for geographic search</p></li><li><p><strong>required_keywords</strong> (unknown)</p><p>dataset keywords (tags) for search</p></li><li><p><strong>page</strong> (integer)</p><p>current page of results</p></li><li><p><strong>per_page</strong> (integer)</p><p>number of results per page (default: 10)</p></li><li><p><strong>sort_by</strong> (string)</p><p>returned results sorting method:</p><ul><li><code>updated_at</code> (default)</li><li><code>relevance</code></li></ul></li><li><p><strong>sort_order</strong> (string)</p><p>returned results order:</p><ul><li><code>desc</code> (default)</li><li><code>asc</code></li></ul></li></ul><h3 id=\"Response-Example\"><a href=\"#Response-Example\" class=\"headerlink\" title=\"Response Example\"></a>Response Example</h3><figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">\"data\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"display_field\"</span>: <span class=\"string\">\"FAC_CAT\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"max_record_count\"</span>: <span class=\"number\">2000</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"record_count\"</span>: <span class=\"number\">11</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"geometry_type\"</span>: <span class=\"string\">\"esriGeometryPoint\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"object_id_field\"</span>: <span class=\"string\">\"FID\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"supported_extensions\"</span>: <span class=\"string\">\"\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"advanced_query_capabilities\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"supports_pagination\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_query_related_pagination\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_query_with_distance\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_returning_query_extent\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_statistics\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_order_by\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_distinct\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_query_with_result_type\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_sql_expression\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_advanced_query_related\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"supports_returning_geometry_centroid\"</span>: <span class=\"literal\">false</span></span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"supports_advanced_queries\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"id\"</span>: <span class=\"string\">\"dd62922ee5c14d11a187aaf30052404f_0\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"landing_page\"</span>: <span class=\"string\">\"https://www.arcgis.com/home/item.html?id=dd62922ee5c14d11a187aaf30052404f\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"This feature layer, utilizing data from the U.S. Environmental Protection Agency (EPA), displays regional offices. The EPA began operation on December 2, 1970 and it inherited two regional systems from predecessor agencies. The Federal Water Quality Administration which used a nine region system and the Environmental Health Service which had adopted the ten Standard Federal Regions suggested by the Office of Management and Budget (OMB). In order to facilitate easier operations with local and state governments as well as other federal agencies the EPA chose to adopt the OMB Standard Federal Regions which still exist today.&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/26b532f4bfb14e0eb517c644dcda73c1/data\\\" /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;i&gt;Regional Office locations&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;For more information: &lt;a href=\\\"https://www.epa.gov/aboutepa\\\" target=\\\"_blank\\\"&gt;About EPA&lt;/a&gt;&lt;/div&gt;&lt;div&gt;For feedback, please contact: &lt;a href=\\\"mailto:ArcGIScomNationalMaps@esri.com\\\" target=\\\"_blank\\\"&gt;ArcGIScomNationalMaps@esri.com&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;EPA sites of interest&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/d543cdf1e9694f5f985eae5b2dcd36f8/data\\\" /&gt; &lt;a href=\\\"https://epa.maps.arcgis.com/home/index.html\\\" target=\\\"_blank\\\"&gt;ArcGIS Online Organizational Homepage&lt;/a&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;Other Federal User Community federally focused content that may interest you&lt;/div&gt;&lt;div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/f83c3452ec074ee08c7f04975578c212/data\\\" /&gt; &lt;a href=\\\"http://fedmaps.maps.arcgis.com/home/search.html?q=owner%3AFederal_User_Community%20AND%20tags%3AUS%20EPA&amp;amp;t=content&amp;amp;restrict=false\\\" target=\\\"_blank\\\"&gt;U.S. Environmental Protection Agency&lt;/a&gt;           &lt;img src=\\\"http://fedmaps.maps.arcgis.com/sharing/rest/content/items/46785cfb399344a6af50d4514d6ef0f9/data\\\" /&gt; &lt;a href=\\\"http://open.fedmaps.opendata.arcgis.com/datasets?q=US+EPA&amp;amp;sort_by=relevance\\\" target=\\\"_blank\\\"&gt;Open Data: U.S. EPA&lt;/a&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"extent\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"coordinates\"</span>: [</span><br><span class=\"line\">          [</span><br><span class=\"line\">            <span class=\"number\">-125.676</span>,</span><br><span class=\"line\">            <span class=\"number\">24.242</span></span><br><span class=\"line\">          ],</span><br><span class=\"line\">          [</span><br><span class=\"line\">            <span class=\"number\">-65.559</span>,</span><br><span class=\"line\">            <span class=\"number\">50.089</span></span><br><span class=\"line\">          ]</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"fields\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"FID\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"esriFieldTypeInteger\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"alias\"</span>: <span class=\"string\">\"FID\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"domain\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"statistics\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"attr\">\"duration\"</span>: <span class=\"number\">0</span></span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          <span class=\"attr\">\"updated_at\"</span>: <span class=\"string\">\"2017-02-06T21:06:49.399Z\"</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"item_name\"</span>: <span class=\"string\">\"EPA Regional Offices\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"ItemLayer\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"item_type\"</span>: <span class=\"string\">\"Feature Layer\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"license\"</span>: <span class=\"string\">\"&lt;p&gt;&lt;img src=\\\"http://downloads.esri.com/blogs/arcgisonline/esrilogo_new.png\\\" /&gt;This work is licensed under the Esri Master License Agreement.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\"&gt;View Summary&lt;/a&gt; | &lt;a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\"&gt;View Terms of Use&lt;/a&gt;&lt;/p&gt;\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"EPA Regional Offices\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"owner\"</span>: <span class=\"string\">\"Federal_User_Community\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"tags\"</span>: [</span><br><span class=\"line\">        <span class=\"string\">\"A-16\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"A16\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"U.S. Environmental Protection Agency\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"U.S. EPA\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"EPA\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"regional offices\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"regions\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"Environmental Protection Agency\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"places\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"boundaries\"</span></span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"thumbnail_url\"</span>: <span class=\"string\">\"https://www.arcgis.com/sharing/rest/content/items/dd62922ee5c14d11a187aaf30052404f/info/thumbnail/EPA_-_Regional_Offices_-_screen_capture.png\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"public\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"created_at\"</span>: <span class=\"string\">\"2016-09-02T11:50:55.000Z\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"updated_at\"</span>: <span class=\"string\">\"2017-02-06T21:06:50.911Z\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"url\"</span>: <span class=\"string\">\"https://services2.arcgis.com/FiaPA4ga0iQKduv3/arcgis/rest/services/EPA_RegionalOffices/FeatureServer/0\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"views\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"quality\"</span>: <span class=\"number\">86</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"coverage\"</span>: <span class=\"string\">\"global\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"current_version\"</span>: <span class=\"number\">10.41</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"comments_enabled\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"service_spatial_reference\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"wkid\"</span>: <span class=\"number\">102100</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"latestWkid\"</span>: <span class=\"number\">3857</span></span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"metadata_url\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"org_id\"</span>: <span class=\"string\">\"FiaPA4ga0iQKduv3\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"metadata\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"published\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"present\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"url\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"online_resources\"</span>: []</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"structured_license\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"attr\">\"type\"</span>: <span class=\"string\">\"custom\"</span>,</span><br><span class=\"line\">        <span class=\"attr\">\"text\"</span>: <span class=\"string\">\"This work is licensed under the Esri Master License Agreement.&lt;a href=\\\"http://links.esri.com/tou_summary\\\" target=\\\"_blank\\\"&gt;View Summary&lt;/a&gt; | &lt;a href=\\\"http://links.esri.com/agol_tou\\\" target=\\\"_blank\\\"&gt;View Terms of Use&lt;/a&gt;\"</span></span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      <span class=\"attr\">\"use_standardized_queries\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"sites\"</span>: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          <span class=\"attr\">\"title\"</span>: <span class=\"string\">\"PACI\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"url\"</span>: <span class=\"string\">\"http://paci-esridubaioffice.opendata.arcgis.com\"</span>,</span><br><span class=\"line\">          <span class=\"attr\">\"logo\"</span>: <span class=\"literal\">null</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      <span class=\"attr\">\"main_group_title\"</span>: <span class=\"string\">\"Open Data - Derived US Independent Establishments and Gov't Corps\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"main_group_description\"</span>: <span class=\"string\">\"&lt;span style='line-height: 24px; background-color: rgb(255, 255, 255);'&gt;&lt;font face='Verdana' size='3'&gt;The group contains a set of map services, web maps and map packages that can be used in a web browser or downloaded to your ArcGIS Desktop application.  The maps may be used as base maps and operational layers to support a variety of applications.&lt;/font&gt;&lt;/span&gt;\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"main_group_thumbnail_url\"</span>: <span class=\"literal\">null</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  <span class=\"attr\">\"metadata\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">\"query_parameters\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"bbox\"</span>: <span class=\"literal\">null</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"page\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"per_page\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"q\"</span>: <span class=\"string\">\"*\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"required_keywords\"</span>: [],</span><br><span class=\"line\">      <span class=\"attr\">\"sort_by\"</span>: <span class=\"string\">\"updated_at\"</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"sort_order\"</span>: <span class=\"string\">\"desc\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"attr\">\"stats\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"attr\">\"count\"</span>: <span class=\"number\">1</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"total_count\"</span>: <span class=\"number\">192</span>,</span><br><span class=\"line\">      <span class=\"attr\">\"top_tags\"</span>: [</span><br><span class=\"line\">        &#123; <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"ocean\"</span>, <span class=\"attr\">\"count\"</span>: <span class=\"number\">62</span> &#125;</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Using an untyped Leaflet plugin in your TypeScript project","date":"2017-01-25T05:00:00.000Z","_content":"\n[Leaflet](http://leafletjs.com/) has a prosperous ecosystem with [hundreds of plugins](http://leafletjs.com/plugins.html). Most of them are not typed for TypeScript, however, with a minimal setup, you are able to use these plugins in your TypeScript mapping project.\n\n<!-- more -->\n\nSince TypeScript is definitely typed, a simple workaround is to provide a minimal type declaration file that can expose the plugin functions in the `L` namespace.\n\nFor example, I would like to display a large GeoJSON file at the browser using the [vector tile](https://www.mapbox.com/vector-tiles/) technique. I can do it in JavaScript with the following code:\n\n``` javascript\n// Get the GeoJSON somewhere\nlet geojson = getGeoJSON();\n\n// Slice the GeoJSON into vector tiles on-the-fly with L.vectorGrid.slicer()\nlet layer = L.vectorGrid.slicer(geojson, {});\n\n// Add the tile layer on the map\nlayer.addTo(map);\n```\n\nThe vector tile plugin [Leaflet.VectorGrid](https://github.com/Leaflet/Leaflet.VectorGrid) isn't officially typed and you are not able to directly use this plugin because the compiler doesn't know its existence. So we just need to declare it with a `leaflet.vectorgrid.d.ts` file\n\n``` typescript\n// in the global namesapce \"L\"\ndeclare namespace L {\n\n  // there is a child namespace \"vectorGrid\"\n  namespace vectorGrid {\n\n    // which has a function call \"slicer\" that takes data and optional\n    // configurations. To make it simple, we don't specify the input\n    // and output types.\n    export function slicer(data: any, options?: any): any;\n  }\n}\n```\n\nThen we are able to use the function in TypeScript\n\n``` typescript\n/// <reference path=\"leaflet.vectorgrid.d.ts\"/>\n\nimport 'leaflet';\nimport 'leaflet.vectorgrid';\n\nlet geojson = getGeoJSON();\nlet layer = L.vectorGrid.slicer(geojson)\n\nlayer.addTo(map);\n```\n\nHere we go!\n\nIf we want to use more, we could continue to populate the type declaration file and maybe contribute it to the community when it becomes more complete.\n\nFor a fully functional exampe, see [angular2-leaflet-starter](https://github.com/haoliangyu/angular2-leaflet-starter).\n","source":"_posts/Using-an-untyped-Leaflet-plugin-in-your-TypeSccript-project.md","raw":"title: Using an untyped Leaflet plugin in your TypeScript project\ndate: 2017-01-25\ncategories:\n- GIS\ntags:\n- leaflet\n-\ttypescript\n---\n\n[Leaflet](http://leafletjs.com/) has a prosperous ecosystem with [hundreds of plugins](http://leafletjs.com/plugins.html). Most of them are not typed for TypeScript, however, with a minimal setup, you are able to use these plugins in your TypeScript mapping project.\n\n<!-- more -->\n\nSince TypeScript is definitely typed, a simple workaround is to provide a minimal type declaration file that can expose the plugin functions in the `L` namespace.\n\nFor example, I would like to display a large GeoJSON file at the browser using the [vector tile](https://www.mapbox.com/vector-tiles/) technique. I can do it in JavaScript with the following code:\n\n``` javascript\n// Get the GeoJSON somewhere\nlet geojson = getGeoJSON();\n\n// Slice the GeoJSON into vector tiles on-the-fly with L.vectorGrid.slicer()\nlet layer = L.vectorGrid.slicer(geojson, {});\n\n// Add the tile layer on the map\nlayer.addTo(map);\n```\n\nThe vector tile plugin [Leaflet.VectorGrid](https://github.com/Leaflet/Leaflet.VectorGrid) isn't officially typed and you are not able to directly use this plugin because the compiler doesn't know its existence. So we just need to declare it with a `leaflet.vectorgrid.d.ts` file\n\n``` typescript\n// in the global namesapce \"L\"\ndeclare namespace L {\n\n  // there is a child namespace \"vectorGrid\"\n  namespace vectorGrid {\n\n    // which has a function call \"slicer\" that takes data and optional\n    // configurations. To make it simple, we don't specify the input\n    // and output types.\n    export function slicer(data: any, options?: any): any;\n  }\n}\n```\n\nThen we are able to use the function in TypeScript\n\n``` typescript\n/// <reference path=\"leaflet.vectorgrid.d.ts\"/>\n\nimport 'leaflet';\nimport 'leaflet.vectorgrid';\n\nlet geojson = getGeoJSON();\nlet layer = L.vectorGrid.slicer(geojson)\n\nlayer.addTo(map);\n```\n\nHere we go!\n\nIf we want to use more, we could continue to populate the type declaration file and maybe contribute it to the community when it becomes more complete.\n\nFor a fully functional exampe, see [angular2-leaflet-starter](https://github.com/haoliangyu/angular2-leaflet-starter).\n","slug":"Using-an-untyped-Leaflet-plugin-in-your-TypeSccript-project","published":1,"updated":"2018-03-03T20:45:36.122Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgrp001e8j0vezuv16to","content":"<p><a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> has a prosperous ecosystem with <a href=\"http://leafletjs.com/plugins.html\" target=\"_blank\" rel=\"noopener\">hundreds of plugins</a>. Most of them are not typed for TypeScript, however, with a minimal setup, you are able to use these plugins in your TypeScript mapping project.</p><a id=\"more\"></a><p>Since TypeScript is definitely typed, a simple workaround is to provide a minimal type declaration file that can expose the plugin functions in the <code>L</code> namespace.</p><p>For example, I would like to display a large GeoJSON file at the browser using the <a href=\"https://www.mapbox.com/vector-tiles/\" target=\"_blank\" rel=\"noopener\">vector tile</a> technique. I can do it in JavaScript with the following code:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Get the GeoJSON somewhere</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> geojson = getGeoJSON();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Slice the GeoJSON into vector tiles on-the-fly with L.vectorGrid.slicer()</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> layer = L.vectorGrid.slicer(geojson, &#123;&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Add the tile layer on the map</span></span><br><span class=\"line\">layer.addTo(map);</span><br></pre></td></tr></table></figure><p>The vector tile plugin <a href=\"https://github.com/Leaflet/Leaflet.VectorGrid\" target=\"_blank\" rel=\"noopener\">Leaflet.VectorGrid</a> isn’t officially typed and you are not able to directly use this plugin because the compiler doesn’t know its existence. So we just need to declare it with a <code>leaflet.vectorgrid.d.ts</code> file</p><figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// in the global namesapce \"L\"</span></span><br><span class=\"line\"><span class=\"keyword\">declare</span> <span class=\"keyword\">namespace</span> L &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// there is a child namespace \"vectorGrid\"</span></span><br><span class=\"line\">  <span class=\"keyword\">namespace</span> vectorGrid &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// which has a function call \"slicer\" that takes data and optional</span></span><br><span class=\"line\">    <span class=\"comment\">// configurations. To make it simple, we don't specify the input</span></span><br><span class=\"line\">    <span class=\"comment\">// and output types.</span></span><br><span class=\"line\">    <span class=\"keyword\">export</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">slicer</span>(<span class=\"params\">data: <span class=\"built_in\">any</span>, options?: <span class=\"built_in\">any</span></span>): <span class=\"title\">any</span></span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p>Then we are able to use the function in TypeScript</p><figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/// &lt;reference path=\"leaflet.vectorgrid.d.ts\"/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">'leaflet'</span>;</span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">'leaflet.vectorgrid'</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">let</span> geojson = getGeoJSON();</span><br><span class=\"line\"><span class=\"keyword\">let</span> layer = L.vectorGrid.slicer(geojson)</span><br><span class=\"line\"></span><br><span class=\"line\">layer.addTo(map);</span><br></pre></td></tr></table></figure><p>Here we go!</p><p>If we want to use more, we could continue to populate the type declaration file and maybe contribute it to the community when it becomes more complete.</p><p>For a fully functional exampe, see <a href=\"https://github.com/haoliangyu/angular2-leaflet-starter\" target=\"_blank\" rel=\"noopener\">angular2-leaflet-starter</a>.</p>","site":{"data":{}},"excerpt":"<p><a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> has a prosperous ecosystem with <a href=\"http://leafletjs.com/plugins.html\" target=\"_blank\" rel=\"noopener\">hundreds of plugins</a>. Most of them are not typed for TypeScript, however, with a minimal setup, you are able to use these plugins in your TypeScript mapping project.</p>","more":"<p>Since TypeScript is definitely typed, a simple workaround is to provide a minimal type declaration file that can expose the plugin functions in the <code>L</code> namespace.</p><p>For example, I would like to display a large GeoJSON file at the browser using the <a href=\"https://www.mapbox.com/vector-tiles/\" target=\"_blank\" rel=\"noopener\">vector tile</a> technique. I can do it in JavaScript with the following code:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Get the GeoJSON somewhere</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> geojson = getGeoJSON();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Slice the GeoJSON into vector tiles on-the-fly with L.vectorGrid.slicer()</span></span><br><span class=\"line\"><span class=\"keyword\">let</span> layer = L.vectorGrid.slicer(geojson, &#123;&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Add the tile layer on the map</span></span><br><span class=\"line\">layer.addTo(map);</span><br></pre></td></tr></table></figure><p>The vector tile plugin <a href=\"https://github.com/Leaflet/Leaflet.VectorGrid\" target=\"_blank\" rel=\"noopener\">Leaflet.VectorGrid</a> isn’t officially typed and you are not able to directly use this plugin because the compiler doesn’t know its existence. So we just need to declare it with a <code>leaflet.vectorgrid.d.ts</code> file</p><figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// in the global namesapce \"L\"</span></span><br><span class=\"line\"><span class=\"keyword\">declare</span> <span class=\"keyword\">namespace</span> L &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// there is a child namespace \"vectorGrid\"</span></span><br><span class=\"line\">  <span class=\"keyword\">namespace</span> vectorGrid &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// which has a function call \"slicer\" that takes data and optional</span></span><br><span class=\"line\">    <span class=\"comment\">// configurations. To make it simple, we don't specify the input</span></span><br><span class=\"line\">    <span class=\"comment\">// and output types.</span></span><br><span class=\"line\">    <span class=\"keyword\">export</span> <span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">slicer</span>(<span class=\"params\">data: <span class=\"built_in\">any</span>, options?: <span class=\"built_in\">any</span></span>): <span class=\"title\">any</span></span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><p>Then we are able to use the function in TypeScript</p><figure class=\"highlight typescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/// &lt;reference path=\"leaflet.vectorgrid.d.ts\"/&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">'leaflet'</span>;</span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">'leaflet.vectorgrid'</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">let</span> geojson = getGeoJSON();</span><br><span class=\"line\"><span class=\"keyword\">let</span> layer = L.vectorGrid.slicer(geojson)</span><br><span class=\"line\"></span><br><span class=\"line\">layer.addTo(map);</span><br></pre></td></tr></table></figure><p>Here we go!</p><p>If we want to use more, we could continue to populate the type declaration file and maybe contribute it to the community when it becomes more complete.</p><p>For a fully functional exampe, see <a href=\"https://github.com/haoliangyu/angular2-leaflet-starter\" target=\"_blank\" rel=\"noopener\">angular2-leaflet-starter</a>.</p>"},{"title":"Work, Life, 2016","date":"2016-12-31T05:00:00.000Z","_content":"\n2016 is a big year for me.\n\n<!-- more -->\n\nThis is the first year after my graduation. I moved away from the university and settled down at downtown to start my new life. Being a web developer in a small startup is very different from being a student in school. In school there are always paths to follow: the spring and fall curriculum, the study plan of the course, the mentorship of the professor. In a startup, things are less organized and more dynamic. I make my work plan, develop at both ends of our application, help GIS Analysts in the company to automate data pipeline, discuss new features with clients, lead internal code safari, and experiment new technologies for our platform. Every day is a new and challenging day. That's very exciting.\n\nOf course challenges mean a lot of work and the trial to keep up with this fast-peace industry means even more. I become a full-time developer. I mean full-time as day and night.\n\n {% asset_img github-commits.png GitHub Commits %}\n\nMy colleague said I was having two jobs: one at the daytime working in the office, and another at the nighttime working at home. That's true, though the nighttime job is not billable and sometimes more challenging than the daytime one.\n\nOne cruel fact of this industry is that the concepts, trends, and technologies can be changed in just 2 or 3 years. It's harder when you are not in a CS major (yeah I am the old-class geographer!). At 2016 I took numerous hours to stay with the leading wave of techs:\n\n  * Learn how to write in[JavaScript ES6](https://github.com/lukehoban/es6features#readme)\n  * Learn how to develop application with [Angular 2](https://angular.io/) and [TypeScript](https://www.typescriptlang.org/)\n  * Play with [Bootstrap](http://getbootstrap.com/) and [Material Design](https://material.angularjs.org/latest/)\n  * Understand [vector tile](https://en.wikipedia.org/wiki/Vector_tiles) and figure out the way to generate it and use it with [Leaflet](http://leafletjs.com/) / [Mapbox GL](https://github.com/mapbox/mapbox-gl-js)\n  * Get deeper with DevOps tools like [Vagrant](https://www.vagrantup.com/), [Docker](https://www.docker.com/),and [NGNIX](https://www.nginx.com/)\n  * Get familar with AWS EC2 and AutoScale service\n\nI also spent much time on [data structures](https://github.com/haoliangyu/basic-data-structure) and [algorithms](https://github.com/haoliangyu) in order to be a qualified software engineer in the future.\n\nBut on the other hand, the software industry is warm as we believe in open source and knowledge sharing. [GitHub](https://github.com), [StackOverflow](http://stackoverflow.com/), [The Spatial Community Slack Channel](http://thespatialcommunity.org/), and many other tech blogs have been my primary learning sources. I am glad that I was introduced into the rapidly developing world of open source GIS. Their generous sharing has been so beneficial to my work and side-projects.\n\nWith the hope of helping the future newbee, I started to publish open source projects with the highest quality I could pursue. This is my nighttime job :-P. So far, I have done\n\n* 9 npm modules ([see here](https://www.npmjs.com/~haoliang))\n* 2 Angular 2 mapping project demo with [Leaflet](https://github.com/haoliangyu/angular2-leaflet-starter) or [Mapbox GL](https://github.com/haoliangyu/angular2-mapboxgl-starter)\n* 1 fully operating website ([OpenDataDiscovery.org](http://opendatadiscovery.org/#map-page))\n* 29 pull requests to community projects\n\nI have got the opportunity to learn and test new knowledge that I don't use in my daytime job. As a benefit, I can move ahead the company and be able to introduce what I learn into the development practice in NBT Solutions.\n\nAmong all of these, I would like to highlight the [Open Data Discovery](https://github.com/haoliangyu/OpenDataDiscovery.org) project, the monster consuming one third of my spare time!\n\n{% asset_img odd-commits.png ODD Commits %}\n\nLike all the others who start their side projects, all I wanted to do initially was simply to make an open data map about [data.gov](https://www.data.gov/). But it opened a world much border than I expect to me and there were so many to explore. This website ends up\n\n* supporting 3 major open data portal platforms: [CKAN](http://ckan.org/), [DKAN](http://www.nucivic.com/dkan/), and [Socrata](http://socrata.com/)\n* tracking more than 300 open data portals worldwide\n* using two AWS EC2 servers for website hosting and vector tile generation\n* storing ~1 million rows of data, which is open to download\n\nand more is under development. Scaling up a project feels great and the [feedback](https://discuss.newbeeokfn.org/t/project-to-monitor-the-status-of-open-data-portals/3927) looks great too.\n\nAfter doing this amount of work, it make me feels I am no longer a newbee knowing nothing. I am confident to walk out and reach out. In 2016 I attended two conferences, 2016 SIG/GIS Conference and 2016 NYS Geosptial Summit. I co-founded the [MaptimeBUF](http://maptime.io/buffalo/), a local meetup for open source GIS, and gave the openning talk [Introduce to OpenStreetMap](https://github.com/MaptimeBUF/intro-to-osm). In December, I gave another talk, [Make an Interactive Map with Leaflet](https://github.com/haoliangyu/intro-to-leaflet), at the local JavaScript meetup [MaptimeBUF](https://www.meetup.com/Buffalojs/).\n\nI spent my vocation at Washington DC and Ottawa, the two beautiful and historical capitals, and finished my city trip at northeast America. I watched my fist NFL game and the first star war movie. I started skiing as the winter came and got myself on more difficult trails :-)\n\nFinally I got the working VISA. Good luck 2016.\n\n{% asset_img trait.jpg trait %}\n","source":"_posts/Work-Life-2016.md","raw":"title: Work, Life, 2016\ndate: 2016-12-31\ncategories:\n- Life\n---\n\n2016 is a big year for me.\n\n<!-- more -->\n\nThis is the first year after my graduation. I moved away from the university and settled down at downtown to start my new life. Being a web developer in a small startup is very different from being a student in school. In school there are always paths to follow: the spring and fall curriculum, the study plan of the course, the mentorship of the professor. In a startup, things are less organized and more dynamic. I make my work plan, develop at both ends of our application, help GIS Analysts in the company to automate data pipeline, discuss new features with clients, lead internal code safari, and experiment new technologies for our platform. Every day is a new and challenging day. That's very exciting.\n\nOf course challenges mean a lot of work and the trial to keep up with this fast-peace industry means even more. I become a full-time developer. I mean full-time as day and night.\n\n {% asset_img github-commits.png GitHub Commits %}\n\nMy colleague said I was having two jobs: one at the daytime working in the office, and another at the nighttime working at home. That's true, though the nighttime job is not billable and sometimes more challenging than the daytime one.\n\nOne cruel fact of this industry is that the concepts, trends, and technologies can be changed in just 2 or 3 years. It's harder when you are not in a CS major (yeah I am the old-class geographer!). At 2016 I took numerous hours to stay with the leading wave of techs:\n\n  * Learn how to write in[JavaScript ES6](https://github.com/lukehoban/es6features#readme)\n  * Learn how to develop application with [Angular 2](https://angular.io/) and [TypeScript](https://www.typescriptlang.org/)\n  * Play with [Bootstrap](http://getbootstrap.com/) and [Material Design](https://material.angularjs.org/latest/)\n  * Understand [vector tile](https://en.wikipedia.org/wiki/Vector_tiles) and figure out the way to generate it and use it with [Leaflet](http://leafletjs.com/) / [Mapbox GL](https://github.com/mapbox/mapbox-gl-js)\n  * Get deeper with DevOps tools like [Vagrant](https://www.vagrantup.com/), [Docker](https://www.docker.com/),and [NGNIX](https://www.nginx.com/)\n  * Get familar with AWS EC2 and AutoScale service\n\nI also spent much time on [data structures](https://github.com/haoliangyu/basic-data-structure) and [algorithms](https://github.com/haoliangyu) in order to be a qualified software engineer in the future.\n\nBut on the other hand, the software industry is warm as we believe in open source and knowledge sharing. [GitHub](https://github.com), [StackOverflow](http://stackoverflow.com/), [The Spatial Community Slack Channel](http://thespatialcommunity.org/), and many other tech blogs have been my primary learning sources. I am glad that I was introduced into the rapidly developing world of open source GIS. Their generous sharing has been so beneficial to my work and side-projects.\n\nWith the hope of helping the future newbee, I started to publish open source projects with the highest quality I could pursue. This is my nighttime job :-P. So far, I have done\n\n* 9 npm modules ([see here](https://www.npmjs.com/~haoliang))\n* 2 Angular 2 mapping project demo with [Leaflet](https://github.com/haoliangyu/angular2-leaflet-starter) or [Mapbox GL](https://github.com/haoliangyu/angular2-mapboxgl-starter)\n* 1 fully operating website ([OpenDataDiscovery.org](http://opendatadiscovery.org/#map-page))\n* 29 pull requests to community projects\n\nI have got the opportunity to learn and test new knowledge that I don't use in my daytime job. As a benefit, I can move ahead the company and be able to introduce what I learn into the development practice in NBT Solutions.\n\nAmong all of these, I would like to highlight the [Open Data Discovery](https://github.com/haoliangyu/OpenDataDiscovery.org) project, the monster consuming one third of my spare time!\n\n{% asset_img odd-commits.png ODD Commits %}\n\nLike all the others who start their side projects, all I wanted to do initially was simply to make an open data map about [data.gov](https://www.data.gov/). But it opened a world much border than I expect to me and there were so many to explore. This website ends up\n\n* supporting 3 major open data portal platforms: [CKAN](http://ckan.org/), [DKAN](http://www.nucivic.com/dkan/), and [Socrata](http://socrata.com/)\n* tracking more than 300 open data portals worldwide\n* using two AWS EC2 servers for website hosting and vector tile generation\n* storing ~1 million rows of data, which is open to download\n\nand more is under development. Scaling up a project feels great and the [feedback](https://discuss.newbeeokfn.org/t/project-to-monitor-the-status-of-open-data-portals/3927) looks great too.\n\nAfter doing this amount of work, it make me feels I am no longer a newbee knowing nothing. I am confident to walk out and reach out. In 2016 I attended two conferences, 2016 SIG/GIS Conference and 2016 NYS Geosptial Summit. I co-founded the [MaptimeBUF](http://maptime.io/buffalo/), a local meetup for open source GIS, and gave the openning talk [Introduce to OpenStreetMap](https://github.com/MaptimeBUF/intro-to-osm). In December, I gave another talk, [Make an Interactive Map with Leaflet](https://github.com/haoliangyu/intro-to-leaflet), at the local JavaScript meetup [MaptimeBUF](https://www.meetup.com/Buffalojs/).\n\nI spent my vocation at Washington DC and Ottawa, the two beautiful and historical capitals, and finished my city trip at northeast America. I watched my fist NFL game and the first star war movie. I started skiing as the winter came and got myself on more difficult trails :-)\n\nFinally I got the working VISA. Good luck 2016.\n\n{% asset_img trait.jpg trait %}\n","slug":"Work-Life-2016","published":1,"updated":"2018-03-03T20:45:36.122Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjf5jlgrq001i8j0vx97lkdr0","content":"<p>2016 is a big year for me.</p><a id=\"more\"></a><p>This is the first year after my graduation. I moved away from the university and settled down at downtown to start my new life. Being a web developer in a small startup is very different from being a student in school. In school there are always paths to follow: the spring and fall curriculum, the study plan of the course, the mentorship of the professor. In a startup, things are less organized and more dynamic. I make my work plan, develop at both ends of our application, help GIS Analysts in the company to automate data pipeline, discuss new features with clients, lead internal code safari, and experiment new technologies for our platform. Every day is a new and challenging day. That’s very exciting.</p><p>Of course challenges mean a lot of work and the trial to keep up with this fast-peace industry means even more. I become a full-time developer. I mean full-time as day and night.</p><p>My colleague said I was having two jobs: one at the daytime working in the office, and another at the nighttime working at home. That’s true, though the nighttime job is not billable and sometimes more challenging than the daytime one.</p><p>One cruel fact of this industry is that the concepts, trends, and technologies can be changed in just 2 or 3 years. It’s harder when you are not in a CS major (yeah I am the old-class geographer!). At 2016 I took numerous hours to stay with the leading wave of techs:</p><ul><li>Learn how to write in<a href=\"https://github.com/lukehoban/es6features#readme\" target=\"_blank\" rel=\"noopener\">JavaScript ES6</a></li><li>Learn how to develop application with <a href=\"https://angular.io/\" target=\"_blank\" rel=\"noopener\">Angular 2</a> and <a href=\"https://www.typescriptlang.org/\" target=\"_blank\" rel=\"noopener\">TypeScript</a></li><li>Play with <a href=\"http://getbootstrap.com/\" target=\"_blank\" rel=\"noopener\">Bootstrap</a> and <a href=\"https://material.angularjs.org/latest/\" target=\"_blank\" rel=\"noopener\">Material Design</a></li><li>Understand <a href=\"https://en.wikipedia.org/wiki/Vector_tiles\" target=\"_blank\" rel=\"noopener\">vector tile</a> and figure out the way to generate it and use it with <a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> / <a href=\"https://github.com/mapbox/mapbox-gl-js\" target=\"_blank\" rel=\"noopener\">Mapbox GL</a></li><li>Get deeper with DevOps tools like <a href=\"https://www.vagrantup.com/\" target=\"_blank\" rel=\"noopener\">Vagrant</a>, <a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"noopener\">Docker</a>,and <a href=\"https://www.nginx.com/\" target=\"_blank\" rel=\"noopener\">NGNIX</a></li><li>Get familar with AWS EC2 and AutoScale service</li></ul><p>I also spent much time on <a href=\"https://github.com/haoliangyu/basic-data-structure\" target=\"_blank\" rel=\"noopener\">data structures</a> and <a href=\"https://github.com/haoliangyu\" target=\"_blank\" rel=\"noopener\">algorithms</a> in order to be a qualified software engineer in the future.</p><p>But on the other hand, the software industry is warm as we believe in open source and knowledge sharing. <a href=\"https://github.com\" target=\"_blank\" rel=\"noopener\">GitHub</a>, <a href=\"http://stackoverflow.com/\" target=\"_blank\" rel=\"noopener\">StackOverflow</a>, <a href=\"http://thespatialcommunity.org/\" target=\"_blank\" rel=\"noopener\">The Spatial Community Slack Channel</a>, and many other tech blogs have been my primary learning sources. I am glad that I was introduced into the rapidly developing world of open source GIS. Their generous sharing has been so beneficial to my work and side-projects.</p><p>With the hope of helping the future newbee, I started to publish open source projects with the highest quality I could pursue. This is my nighttime job :-P. So far, I have done</p><ul><li>9 npm modules (<a href=\"https://www.npmjs.com/~haoliang\" target=\"_blank\" rel=\"noopener\">see here</a>)</li><li>2 Angular 2 mapping project demo with <a href=\"https://github.com/haoliangyu/angular2-leaflet-starter\" target=\"_blank\" rel=\"noopener\">Leaflet</a> or <a href=\"https://github.com/haoliangyu/angular2-mapboxgl-starter\" target=\"_blank\" rel=\"noopener\">Mapbox GL</a></li><li>1 fully operating website (<a href=\"http://opendatadiscovery.org/#map-page\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a>)</li><li>29 pull requests to community projects</li></ul><p>I have got the opportunity to learn and test new knowledge that I don’t use in my daytime job. As a benefit, I can move ahead the company and be able to introduce what I learn into the development practice in NBT Solutions.</p><p>Among all of these, I would like to highlight the <a href=\"https://github.com/haoliangyu/OpenDataDiscovery.org\" target=\"_blank\" rel=\"noopener\">Open Data Discovery</a> project, the monster consuming one third of my spare time!</p><p>Like all the others who start their side projects, all I wanted to do initially was simply to make an open data map about <a href=\"https://www.data.gov/\" target=\"_blank\" rel=\"noopener\">data.gov</a>. But it opened a world much border than I expect to me and there were so many to explore. This website ends up</p><ul><li>supporting 3 major open data portal platforms: <a href=\"http://ckan.org/\" target=\"_blank\" rel=\"noopener\">CKAN</a>, <a href=\"http://www.nucivic.com/dkan/\" target=\"_blank\" rel=\"noopener\">DKAN</a>, and <a href=\"http://socrata.com/\" target=\"_blank\" rel=\"noopener\">Socrata</a></li><li>tracking more than 300 open data portals worldwide</li><li>using two AWS EC2 servers for website hosting and vector tile generation</li><li>storing ~1 million rows of data, which is open to download</li></ul><p>and more is under development. Scaling up a project feels great and the <a href=\"https://discuss.newbeeokfn.org/t/project-to-monitor-the-status-of-open-data-portals/3927\" target=\"_blank\" rel=\"noopener\">feedback</a> looks great too.</p><p>After doing this amount of work, it make me feels I am no longer a newbee knowing nothing. I am confident to walk out and reach out. In 2016 I attended two conferences, 2016 SIG/GIS Conference and 2016 NYS Geosptial Summit. I co-founded the <a href=\"http://maptime.io/buffalo/\" target=\"_blank\" rel=\"noopener\">MaptimeBUF</a>, a local meetup for open source GIS, and gave the openning talk <a href=\"https://github.com/MaptimeBUF/intro-to-osm\" target=\"_blank\" rel=\"noopener\">Introduce to OpenStreetMap</a>. In December, I gave another talk, <a href=\"https://github.com/haoliangyu/intro-to-leaflet\" target=\"_blank\" rel=\"noopener\">Make an Interactive Map with Leaflet</a>, at the local JavaScript meetup <a href=\"https://www.meetup.com/Buffalojs/\" target=\"_blank\" rel=\"noopener\">MaptimeBUF</a>.</p><p>I spent my vocation at Washington DC and Ottawa, the two beautiful and historical capitals, and finished my city trip at northeast America. I watched my fist NFL game and the first star war movie. I started skiing as the winter came and got myself on more difficult trails :-)</p><p>Finally I got the working VISA. Good luck 2016.</p>","site":{"data":{}},"excerpt":"<p>2016 is a big year for me.</p>","more":"<p>This is the first year after my graduation. I moved away from the university and settled down at downtown to start my new life. Being a web developer in a small startup is very different from being a student in school. In school there are always paths to follow: the spring and fall curriculum, the study plan of the course, the mentorship of the professor. In a startup, things are less organized and more dynamic. I make my work plan, develop at both ends of our application, help GIS Analysts in the company to automate data pipeline, discuss new features with clients, lead internal code safari, and experiment new technologies for our platform. Every day is a new and challenging day. That’s very exciting.</p><p>Of course challenges mean a lot of work and the trial to keep up with this fast-peace industry means even more. I become a full-time developer. I mean full-time as day and night.</p><p>My colleague said I was having two jobs: one at the daytime working in the office, and another at the nighttime working at home. That’s true, though the nighttime job is not billable and sometimes more challenging than the daytime one.</p><p>One cruel fact of this industry is that the concepts, trends, and technologies can be changed in just 2 or 3 years. It’s harder when you are not in a CS major (yeah I am the old-class geographer!). At 2016 I took numerous hours to stay with the leading wave of techs:</p><ul><li>Learn how to write in<a href=\"https://github.com/lukehoban/es6features#readme\" target=\"_blank\" rel=\"noopener\">JavaScript ES6</a></li><li>Learn how to develop application with <a href=\"https://angular.io/\" target=\"_blank\" rel=\"noopener\">Angular 2</a> and <a href=\"https://www.typescriptlang.org/\" target=\"_blank\" rel=\"noopener\">TypeScript</a></li><li>Play with <a href=\"http://getbootstrap.com/\" target=\"_blank\" rel=\"noopener\">Bootstrap</a> and <a href=\"https://material.angularjs.org/latest/\" target=\"_blank\" rel=\"noopener\">Material Design</a></li><li>Understand <a href=\"https://en.wikipedia.org/wiki/Vector_tiles\" target=\"_blank\" rel=\"noopener\">vector tile</a> and figure out the way to generate it and use it with <a href=\"http://leafletjs.com/\" target=\"_blank\" rel=\"noopener\">Leaflet</a> / <a href=\"https://github.com/mapbox/mapbox-gl-js\" target=\"_blank\" rel=\"noopener\">Mapbox GL</a></li><li>Get deeper with DevOps tools like <a href=\"https://www.vagrantup.com/\" target=\"_blank\" rel=\"noopener\">Vagrant</a>, <a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"noopener\">Docker</a>,and <a href=\"https://www.nginx.com/\" target=\"_blank\" rel=\"noopener\">NGNIX</a></li><li>Get familar with AWS EC2 and AutoScale service</li></ul><p>I also spent much time on <a href=\"https://github.com/haoliangyu/basic-data-structure\" target=\"_blank\" rel=\"noopener\">data structures</a> and <a href=\"https://github.com/haoliangyu\" target=\"_blank\" rel=\"noopener\">algorithms</a> in order to be a qualified software engineer in the future.</p><p>But on the other hand, the software industry is warm as we believe in open source and knowledge sharing. <a href=\"https://github.com\" target=\"_blank\" rel=\"noopener\">GitHub</a>, <a href=\"http://stackoverflow.com/\" target=\"_blank\" rel=\"noopener\">StackOverflow</a>, <a href=\"http://thespatialcommunity.org/\" target=\"_blank\" rel=\"noopener\">The Spatial Community Slack Channel</a>, and many other tech blogs have been my primary learning sources. I am glad that I was introduced into the rapidly developing world of open source GIS. Their generous sharing has been so beneficial to my work and side-projects.</p><p>With the hope of helping the future newbee, I started to publish open source projects with the highest quality I could pursue. This is my nighttime job :-P. So far, I have done</p><ul><li>9 npm modules (<a href=\"https://www.npmjs.com/~haoliang\" target=\"_blank\" rel=\"noopener\">see here</a>)</li><li>2 Angular 2 mapping project demo with <a href=\"https://github.com/haoliangyu/angular2-leaflet-starter\" target=\"_blank\" rel=\"noopener\">Leaflet</a> or <a href=\"https://github.com/haoliangyu/angular2-mapboxgl-starter\" target=\"_blank\" rel=\"noopener\">Mapbox GL</a></li><li>1 fully operating website (<a href=\"http://opendatadiscovery.org/#map-page\" target=\"_blank\" rel=\"noopener\">OpenDataDiscovery.org</a>)</li><li>29 pull requests to community projects</li></ul><p>I have got the opportunity to learn and test new knowledge that I don’t use in my daytime job. As a benefit, I can move ahead the company and be able to introduce what I learn into the development practice in NBT Solutions.</p><p>Among all of these, I would like to highlight the <a href=\"https://github.com/haoliangyu/OpenDataDiscovery.org\" target=\"_blank\" rel=\"noopener\">Open Data Discovery</a> project, the monster consuming one third of my spare time!</p><p>Like all the others who start their side projects, all I wanted to do initially was simply to make an open data map about <a href=\"https://www.data.gov/\" target=\"_blank\" rel=\"noopener\">data.gov</a>. But it opened a world much border than I expect to me and there were so many to explore. This website ends up</p><ul><li>supporting 3 major open data portal platforms: <a href=\"http://ckan.org/\" target=\"_blank\" rel=\"noopener\">CKAN</a>, <a href=\"http://www.nucivic.com/dkan/\" target=\"_blank\" rel=\"noopener\">DKAN</a>, and <a href=\"http://socrata.com/\" target=\"_blank\" rel=\"noopener\">Socrata</a></li><li>tracking more than 300 open data portals worldwide</li><li>using two AWS EC2 servers for website hosting and vector tile generation</li><li>storing ~1 million rows of data, which is open to download</li></ul><p>and more is under development. Scaling up a project feels great and the <a href=\"https://discuss.newbeeokfn.org/t/project-to-monitor-the-status-of-open-data-portals/3927\" target=\"_blank\" rel=\"noopener\">feedback</a> looks great too.</p><p>After doing this amount of work, it make me feels I am no longer a newbee knowing nothing. I am confident to walk out and reach out. In 2016 I attended two conferences, 2016 SIG/GIS Conference and 2016 NYS Geosptial Summit. I co-founded the <a href=\"http://maptime.io/buffalo/\" target=\"_blank\" rel=\"noopener\">MaptimeBUF</a>, a local meetup for open source GIS, and gave the openning talk <a href=\"https://github.com/MaptimeBUF/intro-to-osm\" target=\"_blank\" rel=\"noopener\">Introduce to OpenStreetMap</a>. In December, I gave another talk, <a href=\"https://github.com/haoliangyu/intro-to-leaflet\" target=\"_blank\" rel=\"noopener\">Make an Interactive Map with Leaflet</a>, at the local JavaScript meetup <a href=\"https://www.meetup.com/Buffalojs/\" target=\"_blank\" rel=\"noopener\">MaptimeBUF</a>.</p><p>I spent my vocation at Washington DC and Ottawa, the two beautiful and historical capitals, and finished my city trip at northeast America. I watched my fist NFL game and the first star war movie. I started skiing as the winter came and got myself on more difficult trails :-)</p><p>Finally I got the working VISA. Good luck 2016.</p>"},{"title":"Yet another way to edit your raster layer in ArcMap - Paint on it!","date":"2015-03-12T01:44:53.000Z","comments":1,"_content":"\nI am glad to announce that the project ArcMap Raster Edit Suite (ARES) has proceed to its second major version 0.2.0! A completely new toolbar **Raster Painter** is added into the add-in. Many people have realized that editing pixels using tools in Raster Editor may be labor intensive, especially when editing large number of pixels. This toolbar is here to provide an ultimately flexible solution to edit pixels, by painting new values on it. The editing style is design to be similar to draw image and picture. You can find similar toolbars in ArcMap like ArcScan and Raster Painting, but they are not designed for raster data modification. Of course, a very close analogy is Paint on Window.\n<!-- more -->\n{% asset_img WinPaint.png This is an example image %}\n\n## Raster Painter Toolbar\n\n---\n\nThe ARES installation package could be downloaded at the [**GitHub project page**](https://github.com/haoliangyu/ares).\n\nAfter installing the ARES Add-In, a new toolbar **Raster Painter** will be added into ArcMap.\n\n{% asset_img RasterPainter.png This is an example image %}\n\nIn the initial release, the tool includes two basic tools:\n\n* {% asset_img FreehandPaintTool.png This is an example image %} **Freehand Paint**\t-\tprovide a freehand painting on the raster layer\n\n* {% asset_img EraseTool.png This is an example image %} **Erase**\t-\tErase unsaved painted pixels from cache\n\nThis toolbar aims at maximizing the flexibility, not the accuracy (e.g. editing pixels at specific rows and columns). If the accuracy is your need, please have a look at another toolbar [**Raster Editor**](https://github.com/haoliangyu/ares).\n\n## Painting on the layer\n\n---\n\nPainting on a raster layer in ArcMap is just like painting a picture with Paint or PhotoShop. The major difference is just you are painting values, instead of colors, on the raster layer. You can do it just with a few steps.\n\n* **Start Painting Section**. You can only paint on a raster layer for one time. If you have several layers in ArcMap, you will select one for painting in the selection window.\n\n{% asset_img StartPainting.png This is an example image %}\n\n* **Add Values for Painting**. Click the *Add Values* button on the *Raster Paint* window, in order to add values that you want to paint on the layer.\n\n{% asset_img AddValues.png This is an example image %}\n\nA random color will be assigned to each added value. You can change the color by right clicking the color column on the value list.\n\nIf you want to delete values from the list, just click the *Delete Values* button.\n\nIf you want to add new values that does not exist on the layer, click *Add New Values...* button on the *Options* Menus. However, you are not able to add any value violating the pixel type of the layer (e.g. 257 for a 8-bit unsigned integer layer).\n\n* **Painting Values**. After selecting a value on the *Raster Paint* window, you can paint the value on the layer using the *Freehand Paint* tool.\n\n**While painting, please keep you mouse move smoothly and steadily.**\n\n{% asset_img Painting.png This is an example image %}\n\nPainted values are symbolized with yellow frame so that you are not going to miss them.\n\n* **Erase Painted Values**. If you want to remove values you paint, just use the *Erase* tool to remove them.\n\n{% asset_img Erase.png This is an example image %}\n\nNoted that the *Erase* tool can only remove painted values on the layer. If you want to erase existing values on the layer, you could simply paint the NoData value on pixels.\n\n* **Save Painted Values**. You can save painted values to the original file using the *Save Paints* button, or to a new file using the *Save Paints As* button.\n\n{% asset_img Save.png This is an example image %}\n\n* **Stop Painting Section**\n\nNow you have your raster layer edited. Isn't it simple and quick :)\n\n## What is next?\n\n---\n\nThe initial release only provides the most basic functionality. More advanced and handy tools are under development:\n\n* Draw polyline/polygon/Circle/Rectangle\n\n* Draw in selection region\n\n* Fill polygon\n\n* Painting history (e.g. undo and redo)\n\nI hope I can finish these updates soon. If you have any idea about the new functionality, don't hesitate to give me a comment :)\n\n## Special Thanks\n\n---\n\nI would like to thank Xuan Wang, Hancheng Nie and Jiang Qing for contributing their codes to this project. And I would like to thank all people who support and encourage me to continue this project.\n\n{% asset_img ArcPaint.png This is an example image %}\n","source":"_posts/Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it.md","raw":"title: Yet another way to edit your raster layer in ArcMap - Paint on it!\ndate: 2015-03-11 21:44:53\ncomments: true\ncategories:\n- GIS\ntags:\n- gis\n- arcgis\n---\n\nI am glad to announce that the project ArcMap Raster Edit Suite (ARES) has proceed to its second major version 0.2.0! A completely new toolbar **Raster Painter** is added into the add-in. Many people have realized that editing pixels using tools in Raster Editor may be labor intensive, especially when editing large number of pixels. This toolbar is here to provide an ultimately flexible solution to edit pixels, by painting new values on it. The editing style is design to be similar to draw image and picture. You can find similar toolbars in ArcMap like ArcScan and Raster Painting, but they are not designed for raster data modification. Of course, a very close analogy is Paint on Window.\n<!-- more -->\n{% asset_img WinPaint.png This is an example image %}\n\n## Raster Painter Toolbar\n\n---\n\nThe ARES installation package could be downloaded at the [**GitHub project page**](https://github.com/haoliangyu/ares).\n\nAfter installing the ARES Add-In, a new toolbar **Raster Painter** will be added into ArcMap.\n\n{% asset_img RasterPainter.png This is an example image %}\n\nIn the initial release, the tool includes two basic tools:\n\n* {% asset_img FreehandPaintTool.png This is an example image %} **Freehand Paint**\t-\tprovide a freehand painting on the raster layer\n\n* {% asset_img EraseTool.png This is an example image %} **Erase**\t-\tErase unsaved painted pixels from cache\n\nThis toolbar aims at maximizing the flexibility, not the accuracy (e.g. editing pixels at specific rows and columns). If the accuracy is your need, please have a look at another toolbar [**Raster Editor**](https://github.com/haoliangyu/ares).\n\n## Painting on the layer\n\n---\n\nPainting on a raster layer in ArcMap is just like painting a picture with Paint or PhotoShop. The major difference is just you are painting values, instead of colors, on the raster layer. You can do it just with a few steps.\n\n* **Start Painting Section**. You can only paint on a raster layer for one time. If you have several layers in ArcMap, you will select one for painting in the selection window.\n\n{% asset_img StartPainting.png This is an example image %}\n\n* **Add Values for Painting**. Click the *Add Values* button on the *Raster Paint* window, in order to add values that you want to paint on the layer.\n\n{% asset_img AddValues.png This is an example image %}\n\nA random color will be assigned to each added value. You can change the color by right clicking the color column on the value list.\n\nIf you want to delete values from the list, just click the *Delete Values* button.\n\nIf you want to add new values that does not exist on the layer, click *Add New Values...* button on the *Options* Menus. However, you are not able to add any value violating the pixel type of the layer (e.g. 257 for a 8-bit unsigned integer layer).\n\n* **Painting Values**. After selecting a value on the *Raster Paint* window, you can paint the value on the layer using the *Freehand Paint* tool.\n\n**While painting, please keep you mouse move smoothly and steadily.**\n\n{% asset_img Painting.png This is an example image %}\n\nPainted values are symbolized with yellow frame so that you are not going to miss them.\n\n* **Erase Painted Values**. If you want to remove values you paint, just use the *Erase* tool to remove them.\n\n{% asset_img Erase.png This is an example image %}\n\nNoted that the *Erase* tool can only remove painted values on the layer. If you want to erase existing values on the layer, you could simply paint the NoData value on pixels.\n\n* **Save Painted Values**. You can save painted values to the original file using the *Save Paints* button, or to a new file using the *Save Paints As* button.\n\n{% asset_img Save.png This is an example image %}\n\n* **Stop Painting Section**\n\nNow you have your raster layer edited. Isn't it simple and quick :)\n\n## What is next?\n\n---\n\nThe initial release only provides the most basic functionality. More advanced and handy tools are under development:\n\n* Draw polyline/polygon/Circle/Rectangle\n\n* Draw in selection region\n\n* Fill polygon\n\n* Painting history (e.g. undo and redo)\n\nI hope I can finish these updates soon. If you have any idea about the new functionality, don't hesitate to give me a comment :)\n\n## Special Thanks\n\n---\n\nI would like to thank Xuan Wang, Hancheng Nie and Jiang Qing for contributing their codes to this project. And I would like to thank all people who support and encourage me to continue this project.\n\n{% asset_img ArcPaint.png This is an example image %}\n","slug":"Yet-another-way-to-edit-your-raster-layer-in-ArcMap-Paint-on-it","published":1,"updated":"2018-03-03T20:45:36.134Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgrs001l8j0v4vvrxx74","content":"<p>I am glad to announce that the project ArcMap Raster Edit Suite (ARES) has proceed to its second major version 0.2.0! A completely new toolbar <strong>Raster Painter</strong> is added into the add-in. Many people have realized that editing pixels using tools in Raster Editor may be labor intensive, especially when editing large number of pixels. This toolbar is here to provide an ultimately flexible solution to edit pixels, by painting new values on it. The editing style is design to be similar to draw image and picture. You can find similar toolbars in ArcMap like ArcScan and Raster Painting, but they are not designed for raster data modification. Of course, a very close analogy is Paint on Window.<br><a id=\"more\"></a><br></p><h2 id=\"Raster-Painter-Toolbar\"><a href=\"#Raster-Painter-Toolbar\" class=\"headerlink\" title=\"Raster Painter Toolbar\"></a>Raster Painter Toolbar</h2><hr><p>The ARES installation package could be downloaded at the <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\"><strong>GitHub project page</strong></a>.</p><p>After installing the ARES Add-In, a new toolbar <strong>Raster Painter</strong> will be added into ArcMap.</p><p>In the initial release, the tool includes two basic tools:</p><ul><li><p><strong>Freehand Paint</strong> - provide a freehand painting on the raster layer</p></li><li><p><strong>Erase</strong> - Erase unsaved painted pixels from cache</p></li></ul><p>This toolbar aims at maximizing the flexibility, not the accuracy (e.g. editing pixels at specific rows and columns). If the accuracy is your need, please have a look at another toolbar <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\"><strong>Raster Editor</strong></a>.</p><h2 id=\"Painting-on-the-layer\"><a href=\"#Painting-on-the-layer\" class=\"headerlink\" title=\"Painting on the layer\"></a>Painting on the layer</h2><hr><p>Painting on a raster layer in ArcMap is just like painting a picture with Paint or PhotoShop. The major difference is just you are painting values, instead of colors, on the raster layer. You can do it just with a few steps.</p><ul><li><strong>Start Painting Section</strong>. You can only paint on a raster layer for one time. If you have several layers in ArcMap, you will select one for painting in the selection window.</li></ul><ul><li><strong>Add Values for Painting</strong>. Click the <em>Add Values</em> button on the <em>Raster Paint</em> window, in order to add values that you want to paint on the layer.</li></ul><p>A random color will be assigned to each added value. You can change the color by right clicking the color column on the value list.</p><p>If you want to delete values from the list, just click the <em>Delete Values</em> button.</p><p>If you want to add new values that does not exist on the layer, click <em>Add New Values…</em> button on the <em>Options</em> Menus. However, you are not able to add any value violating the pixel type of the layer (e.g. 257 for a 8-bit unsigned integer layer).</p><ul><li><strong>Painting Values</strong>. After selecting a value on the <em>Raster Paint</em> window, you can paint the value on the layer using the <em>Freehand Paint</em> tool.</li></ul><p><strong>While painting, please keep you mouse move smoothly and steadily.</strong></p><p>Painted values are symbolized with yellow frame so that you are not going to miss them.</p><ul><li><strong>Erase Painted Values</strong>. If you want to remove values you paint, just use the <em>Erase</em> tool to remove them.</li></ul><p>Noted that the <em>Erase</em> tool can only remove painted values on the layer. If you want to erase existing values on the layer, you could simply paint the NoData value on pixels.</p><ul><li><strong>Save Painted Values</strong>. You can save painted values to the original file using the <em>Save Paints</em> button, or to a new file using the <em>Save Paints As</em> button.</li></ul><ul><li><strong>Stop Painting Section</strong></li></ul><p>Now you have your raster layer edited. Isn’t it simple and quick :)</p><h2 id=\"What-is-next\"><a href=\"#What-is-next\" class=\"headerlink\" title=\"What is next?\"></a>What is next?</h2><hr><p>The initial release only provides the most basic functionality. More advanced and handy tools are under development:</p><ul><li><p>Draw polyline/polygon/Circle/Rectangle</p></li><li><p>Draw in selection region</p></li><li><p>Fill polygon</p></li><li><p>Painting history (e.g. undo and redo)</p></li></ul><p>I hope I can finish these updates soon. If you have any idea about the new functionality, don’t hesitate to give me a comment :)</p><h2 id=\"Special-Thanks\"><a href=\"#Special-Thanks\" class=\"headerlink\" title=\"Special Thanks\"></a>Special Thanks</h2><hr><p>I would like to thank Xuan Wang, Hancheng Nie and Jiang Qing for contributing their codes to this project. And I would like to thank all people who support and encourage me to continue this project.</p>","site":{"data":{}},"excerpt":"<p>I am glad to announce that the project ArcMap Raster Edit Suite (ARES) has proceed to its second major version 0.2.0! A completely new toolbar <strong>Raster Painter</strong> is added into the add-in. Many people have realized that editing pixels using tools in Raster Editor may be labor intensive, especially when editing large number of pixels. This toolbar is here to provide an ultimately flexible solution to edit pixels, by painting new values on it. The editing style is design to be similar to draw image and picture. You can find similar toolbars in ArcMap like ArcScan and Raster Painting, but they are not designed for raster data modification. Of course, a very close analogy is Paint on Window.<br>","more":"<br></p><h2 id=\"Raster-Painter-Toolbar\"><a href=\"#Raster-Painter-Toolbar\" class=\"headerlink\" title=\"Raster Painter Toolbar\"></a>Raster Painter Toolbar</h2><hr><p>The ARES installation package could be downloaded at the <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\"><strong>GitHub project page</strong></a>.</p><p>After installing the ARES Add-In, a new toolbar <strong>Raster Painter</strong> will be added into ArcMap.</p><p>In the initial release, the tool includes two basic tools:</p><ul><li><p><strong>Freehand Paint</strong> - provide a freehand painting on the raster layer</p></li><li><p><strong>Erase</strong> - Erase unsaved painted pixels from cache</p></li></ul><p>This toolbar aims at maximizing the flexibility, not the accuracy (e.g. editing pixels at specific rows and columns). If the accuracy is your need, please have a look at another toolbar <a href=\"https://github.com/haoliangyu/ares\" target=\"_blank\" rel=\"noopener\"><strong>Raster Editor</strong></a>.</p><h2 id=\"Painting-on-the-layer\"><a href=\"#Painting-on-the-layer\" class=\"headerlink\" title=\"Painting on the layer\"></a>Painting on the layer</h2><hr><p>Painting on a raster layer in ArcMap is just like painting a picture with Paint or PhotoShop. The major difference is just you are painting values, instead of colors, on the raster layer. You can do it just with a few steps.</p><ul><li><strong>Start Painting Section</strong>. You can only paint on a raster layer for one time. If you have several layers in ArcMap, you will select one for painting in the selection window.</li></ul><ul><li><strong>Add Values for Painting</strong>. Click the <em>Add Values</em> button on the <em>Raster Paint</em> window, in order to add values that you want to paint on the layer.</li></ul><p>A random color will be assigned to each added value. You can change the color by right clicking the color column on the value list.</p><p>If you want to delete values from the list, just click the <em>Delete Values</em> button.</p><p>If you want to add new values that does not exist on the layer, click <em>Add New Values…</em> button on the <em>Options</em> Menus. However, you are not able to add any value violating the pixel type of the layer (e.g. 257 for a 8-bit unsigned integer layer).</p><ul><li><strong>Painting Values</strong>. After selecting a value on the <em>Raster Paint</em> window, you can paint the value on the layer using the <em>Freehand Paint</em> tool.</li></ul><p><strong>While painting, please keep you mouse move smoothly and steadily.</strong></p><p>Painted values are symbolized with yellow frame so that you are not going to miss them.</p><ul><li><strong>Erase Painted Values</strong>. If you want to remove values you paint, just use the <em>Erase</em> tool to remove them.</li></ul><p>Noted that the <em>Erase</em> tool can only remove painted values on the layer. If you want to erase existing values on the layer, you could simply paint the NoData value on pixels.</p><ul><li><strong>Save Painted Values</strong>. You can save painted values to the original file using the <em>Save Paints</em> button, or to a new file using the <em>Save Paints As</em> button.</li></ul><ul><li><strong>Stop Painting Section</strong></li></ul><p>Now you have your raster layer edited. Isn’t it simple and quick :)</p><h2 id=\"What-is-next\"><a href=\"#What-is-next\" class=\"headerlink\" title=\"What is next?\"></a>What is next?</h2><hr><p>The initial release only provides the most basic functionality. More advanced and handy tools are under development:</p><ul><li><p>Draw polyline/polygon/Circle/Rectangle</p></li><li><p>Draw in selection region</p></li><li><p>Fill polygon</p></li><li><p>Painting history (e.g. undo and redo)</p></li></ul><p>I hope I can finish these updates soon. If you have any idea about the new functionality, don’t hesitate to give me a comment :)</p><h2 id=\"Special-Thanks\"><a href=\"#Special-Thanks\" class=\"headerlink\" title=\"Special Thanks\"></a>Special Thanks</h2><hr><p>I would like to thank Xuan Wang, Hancheng Nie and Jiang Qing for contributing their codes to this project. And I would like to thank all people who support and encourage me to continue this project.</p>"},{"title":"geojson-multiply: a simple package to pack single tyle geojson features","date":"2016-05-07T04:00:00.000Z","comments":1,"_content":"\nSome PostGIS functions only accept multi type geometry, so I write a simple geojson utility package to help me aggregate geojson features.\n\n<!-- more -->\n\nThe basic purpose of `geojson-multiply` is to generate a `MutliPoint`/`MultiLineString`/`MultiPolygon` geojson feature from many `Point`/`LineString`/`Polygon` geojson features. So this package provides a function\n\n```\nmultiply(geojsons[, options])\n```\n\nWhere the `geojsons` could be a geojson feature, an array of geojson features, or a geojson feature collection\n\nNot just the coordinates, the `multiply()` also supports the aggregation of properties. Its `options` parameter accepts two input:\n\n* `properties` - the default properties of result geojson\n\n* `onEachFeature` - a function to aggregate properties. It has four parameters:\n\n  * `properties` - the result geojson's properties\n\n  * `featureProp` - input feature geojson's properties\n\n  * `index` - input feature geojson's index in the array\n\n  * `geojsons` - geojson array.\n\nIt takes the form of [Array.reduce()](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce) and make the aggregation pretty straightforward:\n\n```javascript\nvar multiply = require('geojson-multiply');\n\nvar geojsonA = {\n  type: 'Feature',\n  geometry: { type: 'Point', coordinates: [12, 43] },\n  properties: { count: 5 }\n};\n\nvar geojsonB = {\n  type: 'Feature',\n  geometry: { type: 'Point', coordinates: [13, 34] },\n  properties: { count: 5 }\n};\n\nvar onEachFeature = function(properties, featureProp) {\n  properties.count += featureProp.count;\n  return properties;\n};\n\nvar result = multiply([geojsonA, geojsonB], {\n  properties: { count: 0 },\n  onEachFeature: onEachFeature\n});\n\n/**\nThe reuslt geojson should be\n{\n  type: 'Feature'\n  geometry: {\n    type: 'MultiPoint',\n    coordinates: [[12, 43], [14, 34]]\n  },\n  properties: {\n    count: 10\n  }\n}\n*/\n```\n\nThis package has been published at [npm](https://www.npmjs.com/package/geojson-multiply). If you think it's helpful, just install and try!\n\n```\nnpm install geojson-multiply --save\n```\n","source":"_posts/geojson-multiply-a-simple-library-to-pack-single-type-geojson-features.md","raw":"title: 'geojson-multiply: a simple package to pack single tyle geojson features'\ndate: 2016-05-07\ncomments: true\ncategories:\n- GIS\ntags:\n- javascript\n- geojson\n---\n\nSome PostGIS functions only accept multi type geometry, so I write a simple geojson utility package to help me aggregate geojson features.\n\n<!-- more -->\n\nThe basic purpose of `geojson-multiply` is to generate a `MutliPoint`/`MultiLineString`/`MultiPolygon` geojson feature from many `Point`/`LineString`/`Polygon` geojson features. So this package provides a function\n\n```\nmultiply(geojsons[, options])\n```\n\nWhere the `geojsons` could be a geojson feature, an array of geojson features, or a geojson feature collection\n\nNot just the coordinates, the `multiply()` also supports the aggregation of properties. Its `options` parameter accepts two input:\n\n* `properties` - the default properties of result geojson\n\n* `onEachFeature` - a function to aggregate properties. It has four parameters:\n\n  * `properties` - the result geojson's properties\n\n  * `featureProp` - input feature geojson's properties\n\n  * `index` - input feature geojson's index in the array\n\n  * `geojsons` - geojson array.\n\nIt takes the form of [Array.reduce()](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce) and make the aggregation pretty straightforward:\n\n```javascript\nvar multiply = require('geojson-multiply');\n\nvar geojsonA = {\n  type: 'Feature',\n  geometry: { type: 'Point', coordinates: [12, 43] },\n  properties: { count: 5 }\n};\n\nvar geojsonB = {\n  type: 'Feature',\n  geometry: { type: 'Point', coordinates: [13, 34] },\n  properties: { count: 5 }\n};\n\nvar onEachFeature = function(properties, featureProp) {\n  properties.count += featureProp.count;\n  return properties;\n};\n\nvar result = multiply([geojsonA, geojsonB], {\n  properties: { count: 0 },\n  onEachFeature: onEachFeature\n});\n\n/**\nThe reuslt geojson should be\n{\n  type: 'Feature'\n  geometry: {\n    type: 'MultiPoint',\n    coordinates: [[12, 43], [14, 34]]\n  },\n  properties: {\n    count: 10\n  }\n}\n*/\n```\n\nThis package has been published at [npm](https://www.npmjs.com/package/geojson-multiply). If you think it's helpful, just install and try!\n\n```\nnpm install geojson-multiply --save\n```\n","slug":"geojson-multiply-a-simple-library-to-pack-single-type-geojson-features","published":1,"updated":"2018-03-03T20:45:36.138Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgrt001o8j0vz56tum0z","content":"<p>Some PostGIS functions only accept multi type geometry, so I write a simple geojson utility package to help me aggregate geojson features.</p><a id=\"more\"></a><p>The basic purpose of <code>geojson-multiply</code> is to generate a <code>MutliPoint</code>/<code>MultiLineString</code>/<code>MultiPolygon</code> geojson feature from many <code>Point</code>/<code>LineString</code>/<code>Polygon</code> geojson features. So this package provides a function</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">multiply(geojsons[, options])</span><br></pre></td></tr></table></figure><p>Where the <code>geojsons</code> could be a geojson feature, an array of geojson features, or a geojson feature collection</p><p>Not just the coordinates, the <code>multiply()</code> also supports the aggregation of properties. Its <code>options</code> parameter accepts two input:</p><ul><li><p><code>properties</code> - the default properties of result geojson</p></li><li><p><code>onEachFeature</code> - a function to aggregate properties. It has four parameters:</p><ul><li><p><code>properties</code> - the result geojson’s properties</p></li><li><p><code>featureProp</code> - input feature geojson’s properties</p></li><li><p><code>index</code> - input feature geojson’s index in the array</p></li><li><p><code>geojsons</code> - geojson array.</p></li></ul></li></ul><p>It takes the form of <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce\" target=\"_blank\" rel=\"noopener\">Array.reduce()</a> and make the aggregation pretty straightforward:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> multiply = <span class=\"built_in\">require</span>(<span class=\"string\">'geojson-multiply'</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> geojsonA = &#123;</span><br><span class=\"line\">  type: <span class=\"string\">'Feature'</span>,</span><br><span class=\"line\">  geometry: &#123; <span class=\"attr\">type</span>: <span class=\"string\">'Point'</span>, <span class=\"attr\">coordinates</span>: [<span class=\"number\">12</span>, <span class=\"number\">43</span>] &#125;,</span><br><span class=\"line\">  properties: &#123; <span class=\"attr\">count</span>: <span class=\"number\">5</span> &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> geojsonB = &#123;</span><br><span class=\"line\">  type: <span class=\"string\">'Feature'</span>,</span><br><span class=\"line\">  geometry: &#123; <span class=\"attr\">type</span>: <span class=\"string\">'Point'</span>, <span class=\"attr\">coordinates</span>: [<span class=\"number\">13</span>, <span class=\"number\">34</span>] &#125;,</span><br><span class=\"line\">  properties: &#123; <span class=\"attr\">count</span>: <span class=\"number\">5</span> &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> onEachFeature = <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">properties, featureProp</span>) </span>&#123;</span><br><span class=\"line\">  properties.count += featureProp.count;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> properties;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> result = multiply([geojsonA, geojsonB], &#123;</span><br><span class=\"line\">  properties: &#123; <span class=\"attr\">count</span>: <span class=\"number\">0</span> &#125;,</span><br><span class=\"line\">  onEachFeature: onEachFeature</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">The reuslt geojson should be</span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">  type: 'Feature'</span></span><br><span class=\"line\"><span class=\"comment\">  geometry: &#123;</span></span><br><span class=\"line\"><span class=\"comment\">    type: 'MultiPoint',</span></span><br><span class=\"line\"><span class=\"comment\">    coordinates: [[12, 43], [14, 34]]</span></span><br><span class=\"line\"><span class=\"comment\">  &#125;,</span></span><br><span class=\"line\"><span class=\"comment\">  properties: &#123;</span></span><br><span class=\"line\"><span class=\"comment\">    count: 10</span></span><br><span class=\"line\"><span class=\"comment\">  &#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br></pre></td></tr></table></figure><p>This package has been published at <a href=\"https://www.npmjs.com/package/geojson-multiply\" target=\"_blank\" rel=\"noopener\">npm</a>. If you think it’s helpful, just install and try!</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install geojson-multiply --save</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>Some PostGIS functions only accept multi type geometry, so I write a simple geojson utility package to help me aggregate geojson features.</p>","more":"<p>The basic purpose of <code>geojson-multiply</code> is to generate a <code>MutliPoint</code>/<code>MultiLineString</code>/<code>MultiPolygon</code> geojson feature from many <code>Point</code>/<code>LineString</code>/<code>Polygon</code> geojson features. So this package provides a function</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">multiply(geojsons[, options])</span><br></pre></td></tr></table></figure><p>Where the <code>geojsons</code> could be a geojson feature, an array of geojson features, or a geojson feature collection</p><p>Not just the coordinates, the <code>multiply()</code> also supports the aggregation of properties. Its <code>options</code> parameter accepts two input:</p><ul><li><p><code>properties</code> - the default properties of result geojson</p></li><li><p><code>onEachFeature</code> - a function to aggregate properties. It has four parameters:</p><ul><li><p><code>properties</code> - the result geojson’s properties</p></li><li><p><code>featureProp</code> - input feature geojson’s properties</p></li><li><p><code>index</code> - input feature geojson’s index in the array</p></li><li><p><code>geojsons</code> - geojson array.</p></li></ul></li></ul><p>It takes the form of <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce\" target=\"_blank\" rel=\"noopener\">Array.reduce()</a> and make the aggregation pretty straightforward:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> multiply = <span class=\"built_in\">require</span>(<span class=\"string\">'geojson-multiply'</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> geojsonA = &#123;</span><br><span class=\"line\">  type: <span class=\"string\">'Feature'</span>,</span><br><span class=\"line\">  geometry: &#123; <span class=\"attr\">type</span>: <span class=\"string\">'Point'</span>, <span class=\"attr\">coordinates</span>: [<span class=\"number\">12</span>, <span class=\"number\">43</span>] &#125;,</span><br><span class=\"line\">  properties: &#123; <span class=\"attr\">count</span>: <span class=\"number\">5</span> &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> geojsonB = &#123;</span><br><span class=\"line\">  type: <span class=\"string\">'Feature'</span>,</span><br><span class=\"line\">  geometry: &#123; <span class=\"attr\">type</span>: <span class=\"string\">'Point'</span>, <span class=\"attr\">coordinates</span>: [<span class=\"number\">13</span>, <span class=\"number\">34</span>] &#125;,</span><br><span class=\"line\">  properties: &#123; <span class=\"attr\">count</span>: <span class=\"number\">5</span> &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> onEachFeature = <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">properties, featureProp</span>) </span>&#123;</span><br><span class=\"line\">  properties.count += featureProp.count;</span><br><span class=\"line\">  <span class=\"keyword\">return</span> properties;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> result = multiply([geojsonA, geojsonB], &#123;</span><br><span class=\"line\">  properties: &#123; <span class=\"attr\">count</span>: <span class=\"number\">0</span> &#125;,</span><br><span class=\"line\">  onEachFeature: onEachFeature</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">The reuslt geojson should be</span></span><br><span class=\"line\"><span class=\"comment\">&#123;</span></span><br><span class=\"line\"><span class=\"comment\">  type: 'Feature'</span></span><br><span class=\"line\"><span class=\"comment\">  geometry: &#123;</span></span><br><span class=\"line\"><span class=\"comment\">    type: 'MultiPoint',</span></span><br><span class=\"line\"><span class=\"comment\">    coordinates: [[12, 43], [14, 34]]</span></span><br><span class=\"line\"><span class=\"comment\">  &#125;,</span></span><br><span class=\"line\"><span class=\"comment\">  properties: &#123;</span></span><br><span class=\"line\"><span class=\"comment\">    count: 10</span></span><br><span class=\"line\"><span class=\"comment\">  &#125;</span></span><br><span class=\"line\"><span class=\"comment\">&#125;</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br></pre></td></tr></table></figure><p>This package has been published at <a href=\"https://www.npmjs.com/package/geojson-multiply\" target=\"_blank\" rel=\"noopener\">npm</a>. If you think it’s helpful, just install and try!</p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install geojson-multiply --save</span><br></pre></td></tr></table></figure>"},{"title":"gtran: a promised, consistent, user-friendly GeoJson conversion package","date":"2016-02-25T05:00:00.000Z","comments":1,"_content":"\nDo you still feel inconvenient when converting GeoJson to other data formats in Node.js?\n\n<!-- more -->\n\nGeoJson is one of simplest geographic data format. If we search for data conversion packages at [npm.org](https://www.npmjs.com/), there will be a long list packages: [shapefile](https://www.npmjs.com/package/shapefile) for shapefile, [tokml](https://www.npmjs.com/package/tokml) for kml, [geojson2dcsv](https://www.npmjs.com/package/geojson2dsv) for csv, [osm-and-geojson](https://www.npmjs.com/package/osm-and-geojson) for osm package, [geojson2](https://www.npmjs.com/package/geojson2) for multiple formats, [org2org](https://www.npmjs.com/package/ogr2ogr) and [gdal](https://www.npmjs.com/package/gdal) as data solutions... However, I still felt very inconvenient when I developed a GeoJson handling module a few months ago.\n\n# Why inconvenient?\n\nFrom my point of view, there are a few problems:\n\n* Most packages are designed for one specific data format.\n\n* Each package is written in a style different from the other.\n\n* Some packages require external libraries,like [gdal](http://www.gdal.org/), which aren't npm-able.\n\n* Most package aren't asynchronous or promised. (maybe just a personal problem)\n\nAs a result, in order to make them work together, one will need to learn how to use these diverse packages, customize code to handle their diverse input/output, and write some comments for the future project maintainer.\n\nWell, it's not very fun.\n\n# Gtran: the solution\n\nThe programmer's way to handle unhappiness is to write something that make him happy :) What I want is a package with following features:\n\n* Able to work with multiple formats\n\n* Consistent and simple: functions and their input/output\n\n* Completely npm-able\n\n* Asynchronous\n\nAnd here comes **[gtran](https://www.npmjs.com/package/gtran)**.\n\n# What does gtran do?\n\n**gtran** wraps several existing npm packages to provide\n\n* from/to conversion of multiple formats: .shp, .kml, .kmz, .csv, and TopoJson.\n\n* consistent functions: from\\[format name\\]() and to\\[format name\\]()\n\n* simple input/output: geojson or file name\n\n* asynchronous ability with your favorite promise library ([bluebird](https://www.npmjs.com/package/bluebird), [promise](https://www.npmjs.com/package/promise), [Q](https://www.npmjs.com/package/q), or [native](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)).\n\n* minimal installation: each format support is provide by a child package gtran-xxx.\n\nIt could be installed with `npm install gtran`.\n\n# How could it be used?\n\nA complete use guide could be found at the [GitHub repo](https://github.com/haoliangyu/gtran) and here is a small use case:\n\n``` JavaScript\nvar gtran = require('gtran');\n\n# Specify the promise library if necessary\ngtran.setPromiseLib(require('bluebird'));\n\n# Read shapefile\ngtran.fromShp('source.shp')\n.then(function(object) {\n    var geojson = object;\n});\n\n# Save geojson into shapefile\ngtran.toShp(geojson, 'point.shp')\n.then(function(fileNames) {\n    console.log('SHP files have been saved at:' + fileNames.toString());\n});\n\n# Read csv file\n# Assume the test.csv has two columns: latitude and longitude\ngtran.fromCSV('source.csv', {\n    mapping: { x: 'longitude', y: 'latitude' }\n})\n.then(function(object) {\n    var geojson = object;\n});\n\n# Save geojson into a csv file\ngtran.toCSV(geojson, 'point.csv')\n.then(function(fileName) {\n    console.log('CSV file has been saved at:' + fileName);\n});\n```\n\nHope you enjoy it. If you find a bug or want a new feature, just create an [issue](https://github.com/haoliangyu/gtran/issues) and I will appreciate it :-)\n","source":"_posts/gtran-a-promised-consistent-user-friendly-GeoJson-conversion-package.md","raw":"title: 'gtran: a promised, consistent, user-friendly GeoJson conversion package'\ndate: 2016-02-25\ncomments: true\ncategories:\n- Project\ntags:\n- gis\n- project\n- javascript\n---\n\nDo you still feel inconvenient when converting GeoJson to other data formats in Node.js?\n\n<!-- more -->\n\nGeoJson is one of simplest geographic data format. If we search for data conversion packages at [npm.org](https://www.npmjs.com/), there will be a long list packages: [shapefile](https://www.npmjs.com/package/shapefile) for shapefile, [tokml](https://www.npmjs.com/package/tokml) for kml, [geojson2dcsv](https://www.npmjs.com/package/geojson2dsv) for csv, [osm-and-geojson](https://www.npmjs.com/package/osm-and-geojson) for osm package, [geojson2](https://www.npmjs.com/package/geojson2) for multiple formats, [org2org](https://www.npmjs.com/package/ogr2ogr) and [gdal](https://www.npmjs.com/package/gdal) as data solutions... However, I still felt very inconvenient when I developed a GeoJson handling module a few months ago.\n\n# Why inconvenient?\n\nFrom my point of view, there are a few problems:\n\n* Most packages are designed for one specific data format.\n\n* Each package is written in a style different from the other.\n\n* Some packages require external libraries,like [gdal](http://www.gdal.org/), which aren't npm-able.\n\n* Most package aren't asynchronous or promised. (maybe just a personal problem)\n\nAs a result, in order to make them work together, one will need to learn how to use these diverse packages, customize code to handle their diverse input/output, and write some comments for the future project maintainer.\n\nWell, it's not very fun.\n\n# Gtran: the solution\n\nThe programmer's way to handle unhappiness is to write something that make him happy :) What I want is a package with following features:\n\n* Able to work with multiple formats\n\n* Consistent and simple: functions and their input/output\n\n* Completely npm-able\n\n* Asynchronous\n\nAnd here comes **[gtran](https://www.npmjs.com/package/gtran)**.\n\n# What does gtran do?\n\n**gtran** wraps several existing npm packages to provide\n\n* from/to conversion of multiple formats: .shp, .kml, .kmz, .csv, and TopoJson.\n\n* consistent functions: from\\[format name\\]() and to\\[format name\\]()\n\n* simple input/output: geojson or file name\n\n* asynchronous ability with your favorite promise library ([bluebird](https://www.npmjs.com/package/bluebird), [promise](https://www.npmjs.com/package/promise), [Q](https://www.npmjs.com/package/q), or [native](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)).\n\n* minimal installation: each format support is provide by a child package gtran-xxx.\n\nIt could be installed with `npm install gtran`.\n\n# How could it be used?\n\nA complete use guide could be found at the [GitHub repo](https://github.com/haoliangyu/gtran) and here is a small use case:\n\n``` JavaScript\nvar gtran = require('gtran');\n\n# Specify the promise library if necessary\ngtran.setPromiseLib(require('bluebird'));\n\n# Read shapefile\ngtran.fromShp('source.shp')\n.then(function(object) {\n    var geojson = object;\n});\n\n# Save geojson into shapefile\ngtran.toShp(geojson, 'point.shp')\n.then(function(fileNames) {\n    console.log('SHP files have been saved at:' + fileNames.toString());\n});\n\n# Read csv file\n# Assume the test.csv has two columns: latitude and longitude\ngtran.fromCSV('source.csv', {\n    mapping: { x: 'longitude', y: 'latitude' }\n})\n.then(function(object) {\n    var geojson = object;\n});\n\n# Save geojson into a csv file\ngtran.toCSV(geojson, 'point.csv')\n.then(function(fileName) {\n    console.log('CSV file has been saved at:' + fileName);\n});\n```\n\nHope you enjoy it. If you find a bug or want a new feature, just create an [issue](https://github.com/haoliangyu/gtran/issues) and I will appreciate it :-)\n","slug":"gtran-a-promised-consistent-user-friendly-GeoJson-conversion-package","published":1,"updated":"2018-03-03T20:45:36.138Z","layout":"post","photos":[],"link":"","_id":"cjf5jlgrw001t8j0vujufjg0x","content":"<p>Do you still feel inconvenient when converting GeoJson to other data formats in Node.js?</p><a id=\"more\"></a><p>GeoJson is one of simplest geographic data format. If we search for data conversion packages at <a href=\"https://www.npmjs.com/\" target=\"_blank\" rel=\"noopener\">npm.org</a>, there will be a long list packages: <a href=\"https://www.npmjs.com/package/shapefile\" target=\"_blank\" rel=\"noopener\">shapefile</a> for shapefile, <a href=\"https://www.npmjs.com/package/tokml\" target=\"_blank\" rel=\"noopener\">tokml</a> for kml, <a href=\"https://www.npmjs.com/package/geojson2dsv\" target=\"_blank\" rel=\"noopener\">geojson2dcsv</a> for csv, <a href=\"https://www.npmjs.com/package/osm-and-geojson\" target=\"_blank\" rel=\"noopener\">osm-and-geojson</a> for osm package, <a href=\"https://www.npmjs.com/package/geojson2\" target=\"_blank\" rel=\"noopener\">geojson2</a> for multiple formats, <a href=\"https://www.npmjs.com/package/ogr2ogr\" target=\"_blank\" rel=\"noopener\">org2org</a> and <a href=\"https://www.npmjs.com/package/gdal\" target=\"_blank\" rel=\"noopener\">gdal</a> as data solutions… However, I still felt very inconvenient when I developed a GeoJson handling module a few months ago.</p><h1 id=\"Why-inconvenient\"><a href=\"#Why-inconvenient\" class=\"headerlink\" title=\"Why inconvenient?\"></a>Why inconvenient?</h1><p>From my point of view, there are a few problems:</p><ul><li><p>Most packages are designed for one specific data format.</p></li><li><p>Each package is written in a style different from the other.</p></li><li><p>Some packages require external libraries,like <a href=\"http://www.gdal.org/\" target=\"_blank\" rel=\"noopener\">gdal</a>, which aren’t npm-able.</p></li><li><p>Most package aren’t asynchronous or promised. (maybe just a personal problem)</p></li></ul><p>As a result, in order to make them work together, one will need to learn how to use these diverse packages, customize code to handle their diverse input/output, and write some comments for the future project maintainer.</p><p>Well, it’s not very fun.</p><h1 id=\"Gtran-the-solution\"><a href=\"#Gtran-the-solution\" class=\"headerlink\" title=\"Gtran: the solution\"></a>Gtran: the solution</h1><p>The programmer’s way to handle unhappiness is to write something that make him happy :) What I want is a package with following features:</p><ul><li><p>Able to work with multiple formats</p></li><li><p>Consistent and simple: functions and their input/output</p></li><li><p>Completely npm-able</p></li><li><p>Asynchronous</p></li></ul><p>And here comes <strong><a href=\"https://www.npmjs.com/package/gtran\" target=\"_blank\" rel=\"noopener\">gtran</a></strong>.</p><h1 id=\"What-does-gtran-do\"><a href=\"#What-does-gtran-do\" class=\"headerlink\" title=\"What does gtran do?\"></a>What does gtran do?</h1><p><strong>gtran</strong> wraps several existing npm packages to provide</p><ul><li><p>from/to conversion of multiple formats: .shp, .kml, .kmz, .csv, and TopoJson.</p></li><li><p>consistent functions: from[format name]() and to[format name]()</p></li><li><p>simple input/output: geojson or file name</p></li><li><p>asynchronous ability with your favorite promise library (<a href=\"https://www.npmjs.com/package/bluebird\" target=\"_blank\" rel=\"noopener\">bluebird</a>, <a href=\"https://www.npmjs.com/package/promise\" target=\"_blank\" rel=\"noopener\">promise</a>, <a href=\"https://www.npmjs.com/package/q\" target=\"_blank\" rel=\"noopener\">Q</a>, or <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise\" target=\"_blank\" rel=\"noopener\">native</a>).</p></li><li><p>minimal installation: each format support is provide by a child package gtran-xxx.</p></li></ul><p>It could be installed with <code>npm install gtran</code>.</p><h1 id=\"How-could-it-be-used\"><a href=\"#How-could-it-be-used\" class=\"headerlink\" title=\"How could it be used?\"></a>How could it be used?</h1><p>A complete use guide could be found at the <a href=\"https://github.com/haoliangyu/gtran\" target=\"_blank\" rel=\"noopener\">GitHub repo</a> and here is a small use case:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> gtran = <span class=\"built_in\">require</span>(<span class=\"string\">'gtran'</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"># Specify the promise library if necessary</span><br><span class=\"line\">gtran.setPromiseLib(<span class=\"built_in\">require</span>(<span class=\"string\">'bluebird'</span>));</span><br><span class=\"line\"></span><br><span class=\"line\"># Read shapefile</span><br><span class=\"line\">gtran.fromShp(<span class=\"string\">'source.shp'</span>)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">object</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> geojson = object;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"># Save geojson into shapefile</span><br><span class=\"line\">gtran.toShp(geojson, <span class=\"string\">'point.shp'</span>)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">fileNames</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">'SHP files have been saved at:'</span> + fileNames.toString());</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"># Read csv file</span><br><span class=\"line\"># Assume the test.csv has two columns: latitude and longitude</span><br><span class=\"line\">gtran.fromCSV(<span class=\"string\">'source.csv'</span>, &#123;</span><br><span class=\"line\">    mapping: &#123; <span class=\"attr\">x</span>: <span class=\"string\">'longitude'</span>, <span class=\"attr\">y</span>: <span class=\"string\">'latitude'</span> &#125;</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">object</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> geojson = object;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"># Save geojson into a csv file</span><br><span class=\"line\">gtran.toCSV(geojson, <span class=\"string\">'point.csv'</span>)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">fileName</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">'CSV file has been saved at:'</span> + fileName);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure><p>Hope you enjoy it. If you find a bug or want a new feature, just create an <a href=\"https://github.com/haoliangyu/gtran/issues\" target=\"_blank\" rel=\"noopener\">issue</a> and I will appreciate it :-)</p>","site":{"data":{}},"excerpt":"<p>Do you still feel inconvenient when converting GeoJson to other data formats in Node.js?</p>","more":"<p>GeoJson is one of simplest geographic data format. If we search for data conversion packages at <a href=\"https://www.npmjs.com/\" target=\"_blank\" rel=\"noopener\">npm.org</a>, there will be a long list packages: <a href=\"https://www.npmjs.com/package/shapefile\" target=\"_blank\" rel=\"noopener\">shapefile</a> for shapefile, <a href=\"https://www.npmjs.com/package/tokml\" target=\"_blank\" rel=\"noopener\">tokml</a> for kml, <a href=\"https://www.npmjs.com/package/geojson2dsv\" target=\"_blank\" rel=\"noopener\">geojson2dcsv</a> for csv, <a href=\"https://www.npmjs.com/package/osm-and-geojson\" target=\"_blank\" rel=\"noopener\">osm-and-geojson</a> for osm package, <a href=\"https://www.npmjs.com/package/geojson2\" target=\"_blank\" rel=\"noopener\">geojson2</a> for multiple formats, <a href=\"https://www.npmjs.com/package/ogr2ogr\" target=\"_blank\" rel=\"noopener\">org2org</a> and <a href=\"https://www.npmjs.com/package/gdal\" target=\"_blank\" rel=\"noopener\">gdal</a> as data solutions… However, I still felt very inconvenient when I developed a GeoJson handling module a few months ago.</p><h1 id=\"Why-inconvenient\"><a href=\"#Why-inconvenient\" class=\"headerlink\" title=\"Why inconvenient?\"></a>Why inconvenient?</h1><p>From my point of view, there are a few problems:</p><ul><li><p>Most packages are designed for one specific data format.</p></li><li><p>Each package is written in a style different from the other.</p></li><li><p>Some packages require external libraries,like <a href=\"http://www.gdal.org/\" target=\"_blank\" rel=\"noopener\">gdal</a>, which aren’t npm-able.</p></li><li><p>Most package aren’t asynchronous or promised. (maybe just a personal problem)</p></li></ul><p>As a result, in order to make them work together, one will need to learn how to use these diverse packages, customize code to handle their diverse input/output, and write some comments for the future project maintainer.</p><p>Well, it’s not very fun.</p><h1 id=\"Gtran-the-solution\"><a href=\"#Gtran-the-solution\" class=\"headerlink\" title=\"Gtran: the solution\"></a>Gtran: the solution</h1><p>The programmer’s way to handle unhappiness is to write something that make him happy :) What I want is a package with following features:</p><ul><li><p>Able to work with multiple formats</p></li><li><p>Consistent and simple: functions and their input/output</p></li><li><p>Completely npm-able</p></li><li><p>Asynchronous</p></li></ul><p>And here comes <strong><a href=\"https://www.npmjs.com/package/gtran\" target=\"_blank\" rel=\"noopener\">gtran</a></strong>.</p><h1 id=\"What-does-gtran-do\"><a href=\"#What-does-gtran-do\" class=\"headerlink\" title=\"What does gtran do?\"></a>What does gtran do?</h1><p><strong>gtran</strong> wraps several existing npm packages to provide</p><ul><li><p>from/to conversion of multiple formats: .shp, .kml, .kmz, .csv, and TopoJson.</p></li><li><p>consistent functions: from[format name]() and to[format name]()</p></li><li><p>simple input/output: geojson or file name</p></li><li><p>asynchronous ability with your favorite promise library (<a href=\"https://www.npmjs.com/package/bluebird\" target=\"_blank\" rel=\"noopener\">bluebird</a>, <a href=\"https://www.npmjs.com/package/promise\" target=\"_blank\" rel=\"noopener\">promise</a>, <a href=\"https://www.npmjs.com/package/q\" target=\"_blank\" rel=\"noopener\">Q</a>, or <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise\" target=\"_blank\" rel=\"noopener\">native</a>).</p></li><li><p>minimal installation: each format support is provide by a child package gtran-xxx.</p></li></ul><p>It could be installed with <code>npm install gtran</code>.</p><h1 id=\"How-could-it-be-used\"><a href=\"#How-could-it-be-used\" class=\"headerlink\" title=\"How could it be used?\"></a>How could it be used?</h1><p>A complete use guide could be found at the <a href=\"https://github.com/haoliangyu/gtran\" target=\"_blank\" rel=\"noopener\">GitHub repo</a> and here is a small use case:</p><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> gtran = <span class=\"built_in\">require</span>(<span class=\"string\">'gtran'</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"># Specify the promise library if necessary</span><br><span class=\"line\">gtran.setPromiseLib(<span class=\"built_in\">require</span>(<span class=\"string\">'bluebird'</span>));</span><br><span class=\"line\"></span><br><span class=\"line\"># Read shapefile</span><br><span class=\"line\">gtran.fromShp(<span class=\"string\">'source.shp'</span>)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">object</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> geojson = object;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"># Save geojson into shapefile</span><br><span class=\"line\">gtran.toShp(geojson, <span class=\"string\">'point.shp'</span>)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">fileNames</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">'SHP files have been saved at:'</span> + fileNames.toString());</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"># Read csv file</span><br><span class=\"line\"># Assume the test.csv has two columns: latitude and longitude</span><br><span class=\"line\">gtran.fromCSV(<span class=\"string\">'source.csv'</span>, &#123;</span><br><span class=\"line\">    mapping: &#123; <span class=\"attr\">x</span>: <span class=\"string\">'longitude'</span>, <span class=\"attr\">y</span>: <span class=\"string\">'latitude'</span> &#125;</span><br><span class=\"line\">&#125;)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">object</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> geojson = object;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\"># Save geojson into a csv file</span><br><span class=\"line\">gtran.toCSV(geojson, <span class=\"string\">'point.csv'</span>)</span><br><span class=\"line\">.then(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">fileName</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"string\">'CSV file has been saved at:'</span> + fileName);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure><p>Hope you enjoy it. If you find a bug or want a new feature, just create an <a href=\"https://github.com/haoliangyu/gtran/issues\" target=\"_blank\" rel=\"noopener\">issue</a> and I will appreciate it :-)</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjf5jlgqj00008j0v59nqxa19","category_id":"cjf5jlgqs00048j0v6n9ezop9","_id":"cjf5jlgr2000e8j0vlz1175s0"},{"post_id":"cjf5jlgqz000c8j0v5575jex4","category_id":"cjf5jlgqs00048j0v6n9ezop9","_id":"cjf5jlgr8000k8j0v4wosc13y"},{"post_id":"cjf5jlgr1000d8j0vuygjfi7v","category_id":"cjf5jlgqs00048j0v6n9ezop9","_id":"cjf5jlgrc000q8j0vhe19ax85"},{"post_id":"cjf5jlgr3000h8j0v5hh3c2gb","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrd000t8j0v2n876s08"},{"post_id":"cjf5jlgqx00098j0vfa7mshph","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgre000v8j0vu9vywgeb"},{"post_id":"cjf5jlgr7000j8j0vaa3tvxgf","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrg000x8j0vk2zpa4j2"},{"post_id":"cjf5jlgr9000n8j0vg422qhhk","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgri00118j0v70bl3bno"},{"post_id":"cjf5jlgrb000p8j0v71ta8wda","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrj00148j0v9pw0i7oy"},{"post_id":"cjf5jlgrc000s8j0vutpnk92z","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrl00188j0vrkgg8owg"},{"post_id":"cjf5jlgrd000u8j0vie984jn3","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrm001a8j0vao3fha8o"},{"post_id":"cjf5jlgrf000w8j0vog18mq22","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgro001d8j0v00jnbhfj"},{"post_id":"cjf5jlgrh00108j0v6dbknhks","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrq001f8j0vk84vtylq"},{"post_id":"cjf5jlgri00138j0vye3gz2un","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrr001j8j0v3gih0hwy"},{"post_id":"cjf5jlgrk00178j0va9sl9xpx","category_id":"cjf5jlgqs00048j0v6n9ezop9","_id":"cjf5jlgrt001m8j0vuhjpweib"},{"post_id":"cjf5jlgrl00198j0vuqb5jdc3","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrv001q8j0vo6uodd0w"},{"post_id":"cjf5jlgrp001e8j0vezuv16to","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgrx001u8j0vvx85xisb"},{"post_id":"cjf5jlgrs001l8j0v4vvrxx74","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgry001w8j0v04vodex4"},{"post_id":"cjf5jlgrn001c8j0v4uopd4ht","category_id":"cjf5jlgrq001g8j0vy0nrdwr6","_id":"cjf5jlgs0001z8j0vn3ltnx67"},{"post_id":"cjf5jlgrt001o8j0vz56tum0z","category_id":"cjf5jlgr3000f8j0vka48e7fs","_id":"cjf5jlgs000218j0vvorqfdbt"},{"post_id":"cjf5jlgrw001t8j0vujufjg0x","category_id":"cjf5jlgqs00048j0v6n9ezop9","_id":"cjf5jlgs100248j0vtxwdlew2"},{"post_id":"cjf5jlgrq001i8j0vx97lkdr0","category_id":"cjf5jlgru001p8j0v18m29hiv","_id":"cjf5jlgs100268j0vzsodydki"}],"PostTag":[{"post_id":"cjf5jlgqj00008j0v59nqxa19","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgr6000i8j0vkn086pu1"},{"post_id":"cjf5jlgqj00008j0v59nqxa19","tag_id":"cjf5jlgqz000b8j0vwkp9fb8e","_id":"cjf5jlgr8000l8j0vtwlp5nx7"},{"post_id":"cjf5jlgqx00098j0vfa7mshph","tag_id":"cjf5jlgrg000y8j0vvgf4adnz","_id":"cjf5jlgrs001k8j0vo0pur4dd"},{"post_id":"cjf5jlgqx00098j0vfa7mshph","tag_id":"cjf5jlgrj00158j0vnz60hg97","_id":"cjf5jlgrt001n8j0v30v4tmql"},{"post_id":"cjf5jlgqx00098j0vfa7mshph","tag_id":"cjf5jlgrn001b8j0v6bx4ngou","_id":"cjf5jlgrw001s8j0v8stph3ep"},{"post_id":"cjf5jlgrp001e8j0vezuv16to","tag_id":"cjf5jlgrj00158j0vnz60hg97","_id":"cjf5jlgry001v8j0vmyzjv0sk"},{"post_id":"cjf5jlgrp001e8j0vezuv16to","tag_id":"cjf5jlgrn001b8j0v6bx4ngou","_id":"cjf5jlgrz001y8j0vaobn605r"},{"post_id":"cjf5jlgqz000c8j0v5575jex4","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgs000208j0vfb4b321w"},{"post_id":"cjf5jlgqz000c8j0v5575jex4","tag_id":"cjf5jlgrq001h8j0vooie4h0e","_id":"cjf5jlgs000238j0vbmkg8x4l"},{"post_id":"cjf5jlgr1000d8j0vuygjfi7v","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgs100258j0vrskyqcp2"},{"post_id":"cjf5jlgr1000d8j0vuygjfi7v","tag_id":"cjf5jlgrv001r8j0vsgnxawwg","_id":"cjf5jlgs100278j0vw2rsz7n5"},{"post_id":"cjf5jlgr1000d8j0vuygjfi7v","tag_id":"cjf5jlgry001x8j0vvcxue5vw","_id":"cjf5jlgs100298j0vqelnb1kn"},{"post_id":"cjf5jlgr3000h8j0v5hh3c2gb","tag_id":"cjf5jlgs000228j0vdmnrguay","_id":"cjf5jlgs2002a8j0vd9or9339"},{"post_id":"cjf5jlgr3000h8j0v5hh3c2gb","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgs2002c8j0v6oqw61wp"},{"post_id":"cjf5jlgr3000h8j0v5hh3c2gb","tag_id":"cjf5jlgqz000b8j0vwkp9fb8e","_id":"cjf5jlgs2002d8j0vykv6vgdx"},{"post_id":"cjf5jlgr7000j8j0vaa3tvxgf","tag_id":"cjf5jlgs100288j0vkdyk21dv","_id":"cjf5jlgs2002f8j0vzv4umm83"},{"post_id":"cjf5jlgr9000n8j0vg422qhhk","tag_id":"cjf5jlgs2002b8j0vtn7aspvs","_id":"cjf5jlgs5002h8j0vf8f7ibxq"},{"post_id":"cjf5jlgr9000n8j0vg422qhhk","tag_id":"cjf5jlgs2002e8j0vdsjkbwd9","_id":"cjf5jlgs5002i8j0vop8p2yu9"},{"post_id":"cjf5jlgrb000p8j0v71ta8wda","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgs5002k8j0v1zrxfnzx"},{"post_id":"cjf5jlgrb000p8j0v71ta8wda","tag_id":"cjf5jlgry001x8j0vvcxue5vw","_id":"cjf5jlgs6002l8j0vg5dj01lh"},{"post_id":"cjf5jlgrc000s8j0vutpnk92z","tag_id":"cjf5jlgs5002j8j0vx28hu5og","_id":"cjf5jlgs7002p8j0voo1rxrqy"},{"post_id":"cjf5jlgrc000s8j0vutpnk92z","tag_id":"cjf5jlgs100288j0vkdyk21dv","_id":"cjf5jlgs7002q8j0vx47gctc5"},{"post_id":"cjf5jlgrc000s8j0vutpnk92z","tag_id":"cjf5jlgry001x8j0vvcxue5vw","_id":"cjf5jlgs8002s8j0vnosdwrry"},{"post_id":"cjf5jlgrd000u8j0vie984jn3","tag_id":"cjf5jlgrj00158j0vnz60hg97","_id":"cjf5jlgs9002u8j0vktmsoxg5"},{"post_id":"cjf5jlgrd000u8j0vie984jn3","tag_id":"cjf5jlgrn001b8j0v6bx4ngou","_id":"cjf5jlgs9002v8j0vz5a4imuy"},{"post_id":"cjf5jlgrf000w8j0vog18mq22","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgs9002x8j0v1teen6k9"},{"post_id":"cjf5jlgrf000w8j0vog18mq22","tag_id":"cjf5jlgs000228j0vdmnrguay","_id":"cjf5jlgs9002y8j0vte7gzgpg"},{"post_id":"cjf5jlgrh00108j0v6dbknhks","tag_id":"cjf5jlgs100288j0vkdyk21dv","_id":"cjf5jlgsb00328j0v50ow505p"},{"post_id":"cjf5jlgrh00108j0v6dbknhks","tag_id":"cjf5jlgsa002z8j0vadb72z19","_id":"cjf5jlgsb00338j0vwjdsjjtm"},{"post_id":"cjf5jlgrh00108j0v6dbknhks","tag_id":"cjf5jlgsa00308j0vunhdznlb","_id":"cjf5jlgsc00358j0vu7a3lz2o"},{"post_id":"cjf5jlgri00138j0vye3gz2un","tag_id":"cjf5jlgs100288j0vkdyk21dv","_id":"cjf5jlgsd00388j0vqnff7pw2"},{"post_id":"cjf5jlgri00138j0vye3gz2un","tag_id":"cjf5jlgs5002j8j0vx28hu5og","_id":"cjf5jlgsd00398j0vgldq903m"},{"post_id":"cjf5jlgri00138j0vye3gz2un","tag_id":"cjf5jlgsa00308j0vunhdznlb","_id":"cjf5jlgse003b8j0v7bj1gbel"},{"post_id":"cjf5jlgrk00178j0va9sl9xpx","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgse003d8j0vnlxdymn4"},{"post_id":"cjf5jlgrk00178j0va9sl9xpx","tag_id":"cjf5jlgrv001r8j0vsgnxawwg","_id":"cjf5jlgse003e8j0v8d6hll3j"},{"post_id":"cjf5jlgrk00178j0va9sl9xpx","tag_id":"cjf5jlgsa00308j0vunhdznlb","_id":"cjf5jlgsf003g8j0v5lhld8a0"},{"post_id":"cjf5jlgrl00198j0vuqb5jdc3","tag_id":"cjf5jlgs000228j0vdmnrguay","_id":"cjf5jlgsg003h8j0vy3eylado"},{"post_id":"cjf5jlgrl00198j0vuqb5jdc3","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgsh003j8j0vmb1wwxvr"},{"post_id":"cjf5jlgrl00198j0vuqb5jdc3","tag_id":"cjf5jlgqz000b8j0vwkp9fb8e","_id":"cjf5jlgsh003k8j0ve04w4p8y"},{"post_id":"cjf5jlgrn001c8j0v4uopd4ht","tag_id":"cjf5jlgry001x8j0vvcxue5vw","_id":"cjf5jlgsi003m8j0vgeqmgon8"},{"post_id":"cjf5jlgrn001c8j0v4uopd4ht","tag_id":"cjf5jlgs000228j0vdmnrguay","_id":"cjf5jlgsi003n8j0vklk9vzx6"},{"post_id":"cjf5jlgrs001l8j0v4vvrxx74","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgsj003p8j0vskis5qjw"},{"post_id":"cjf5jlgrs001l8j0v4vvrxx74","tag_id":"cjf5jlgry001x8j0vvcxue5vw","_id":"cjf5jlgsj003q8j0vc55v2g7z"},{"post_id":"cjf5jlgrt001o8j0vz56tum0z","tag_id":"cjf5jlgsi003o8j0vexl4pb5e","_id":"cjf5jlgsk003s8j0vt9u3ebu6"},{"post_id":"cjf5jlgrt001o8j0vz56tum0z","tag_id":"cjf5jlgrg000y8j0vvgf4adnz","_id":"cjf5jlgsk003t8j0vhfa8mdgi"},{"post_id":"cjf5jlgrw001t8j0vujufjg0x","tag_id":"cjf5jlgqt00058j0veq41elg8","_id":"cjf5jlgsk003u8j0vdllzcp7z"},{"post_id":"cjf5jlgrw001t8j0vujufjg0x","tag_id":"cjf5jlgrv001r8j0vsgnxawwg","_id":"cjf5jlgsl003v8j0vihkk4cik"},{"post_id":"cjf5jlgrw001t8j0vujufjg0x","tag_id":"cjf5jlgsi003o8j0vexl4pb5e","_id":"cjf5jlgsl003w8j0vns7kkzsq"}],"Tag":[{"name":"gis","_id":"cjf5jlgqt00058j0veq41elg8"},{"name":"OpenDataDiscovery.org","_id":"cjf5jlgqz000b8j0vwkp9fb8e"},{"name":"aws","_id":"cjf5jlgr3000g8j0vautvoe5w"},{"name":"ci","_id":"cjf5jlgr8000m8j0v2zxqxiwe"},{"name":"deloyment","_id":"cjf5jlgrc000r8j0vmdc8nmbs"},{"name":"geojson","_id":"cjf5jlgrg000y8j0vvgf4adnz"},{"name":"leaflet","_id":"cjf5jlgrj00158j0vnz60hg97"},{"name":"typescript","_id":"cjf5jlgrn001b8j0v6bx4ngou"},{"name":"openstreetmap","_id":"cjf5jlgrq001h8j0vooie4h0e"},{"name":"project","_id":"cjf5jlgrv001r8j0vsgnxawwg"},{"name":"arcgis","_id":"cjf5jlgry001x8j0vvcxue5vw"},{"name":"open data","_id":"cjf5jlgs000228j0vdmnrguay"},{"name":"remote sensing","_id":"cjf5jlgs100288j0vkdyk21dv"},{"name":"arcobject","_id":"cjf5jlgs2002b8j0vtn7aspvs"},{"name":"C#","_id":"cjf5jlgs2002e8j0vdsjkbwd9"},{"name":"landsat","_id":"cjf5jlgs5002j8j0vx28hu5og"},{"name":"modis","_id":"cjf5jlgsa002z8j0vadb72z19"},{"name":"python","_id":"cjf5jlgsa00308j0vunhdznlb"},{"name":"javascript","_id":"cjf5jlgsi003o8j0vexl4pb5e"}]}}